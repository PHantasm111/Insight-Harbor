-- MySQL dump 10.13  Distrib 8.0.37, for Win64 (x86_64)
--
-- Host: 127.0.0.1    Database: web-db
-- ------------------------------------------------------
-- Server version	8.0.37

/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!50503 SET NAMES utf8mb4 */;
/*!40103 SET @OLD_TIME_ZONE=@@TIME_ZONE */;
/*!40103 SET TIME_ZONE='+00:00' */;
/*!40014 SET @OLD_UNIQUE_CHECKS=@@UNIQUE_CHECKS, UNIQUE_CHECKS=0 */;
/*!40014 SET @OLD_FOREIGN_KEY_CHECKS=@@FOREIGN_KEY_CHECKS, FOREIGN_KEY_CHECKS=0 */;
/*!40101 SET @OLD_SQL_MODE=@@SQL_MODE, SQL_MODE='NO_AUTO_VALUE_ON_ZERO' */;
/*!40111 SET @OLD_SQL_NOTES=@@SQL_NOTES, SQL_NOTES=0 */;

--
-- Table structure for table `belongto`
--

DROP TABLE IF EXISTS `belongto`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `belongto` (
  `Id_t` int NOT NULL,
  `Id_eco` int NOT NULL,
  PRIMARY KEY (`Id_t`,`Id_eco`),
  KEY `Id_eco` (`Id_eco`),
  CONSTRAINT `belongto_ibfk_1` FOREIGN KEY (`Id_t`) REFERENCES `tools` (`Id_t`),
  CONSTRAINT `belongto_ibfk_2` FOREIGN KEY (`Id_eco`) REFERENCES `ecosystem` (`Id_eco`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `belongto`
--

LOCK TABLES `belongto` WRITE;
/*!40000 ALTER TABLE `belongto` DISABLE KEYS */;
INSERT INTO `belongto` (`Id_t`, `Id_eco`) VALUES (26,1),(36,1),(37,1),(24,2),(16,3),(21,3),(29,3),(30,3),(18,4),(22,4),(31,4),(32,4),(33,4),(19,5),(23,5),(5,6),(7,6),(20,7),(5,8);
/*!40000 ALTER TABLE `belongto` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `build`
--

DROP TABLE IF EXISTS `build`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `build` (
  `UserID` int NOT NULL,
  `Id_R` int NOT NULL,
  `Date_created` timestamp NOT NULL,
  `Status` enum('saved','finished','valid') DEFAULT 'saved',
  `AllQuestionsData` json DEFAULT NULL,
  `CurrentId` int DEFAULT NULL,
  `ResultStore` json DEFAULT NULL,
  `SourceAndTargetList` json DEFAULT NULL,
  `timer` int DEFAULT NULL,
  `architectureCloud` json DEFAULT NULL,
  `deployMode` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`UserID`,`Id_R`,`Date_created`),
  KEY `Id_R` (`Id_R`),
  KEY `build___ibfk_3` (`Date_created`),
  CONSTRAINT `build___ibfk_3` FOREIGN KEY (`Date_created`) REFERENCES `calendar` (`Date_created`),
  CONSTRAINT `build_ibfk_1` FOREIGN KEY (`UserID`) REFERENCES `users` (`UserID`),
  CONSTRAINT `build_ibfk_2` FOREIGN KEY (`Id_R`) REFERENCES `datalake` (`Id_R`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `build`
--

LOCK TABLES `build` WRITE;
/*!40000 ALTER TABLE `build` DISABLE KEYS */;
INSERT INTO `build` (`UserID`, `Id_R`, `Date_created`, `Status`, `AllQuestionsData`, `CurrentId`, `ResultStore`, `SourceAndTargetList`, `timer`, `architectureCloud`, `deployMode`) VALUES (11,11,'2024-10-24 13:53:11','saved','[{\"choices\": {\"c1\": \"On-premises\"}, \"questionId\": 1, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"On-premises\"}], \"questionContent\": \"Where do you want to deploy your data lake ?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"No\", \"c2\": \"A little bit (medium budget)\", \"c3\": \"Yes\"}, \"questionId\": 4, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"A little bit (medium budget)\"}], \"questionContent\": \"Do you want to use paid software?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Streaming\", \"c2\": \"Batch\", \"c3\": \"Hybrid\"}, \"questionId\": 5, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Streaming\"}], \"questionContent\": \"How do you expect to ingest data?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Offline analysis\", \"c2\": \"Real-time analysis\"}, \"questionId\": 16, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Real-time analysis\"}], \"questionContent\": \"Do you want to perform offline analysis or real-time analysis?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}, \"questionId\": 6, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"DataSet(Demi-structured)\"}], \"questionContent\": \"From which source do you plan to ingest data? (Select all that apply)\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Filesystem\", \"thirdSelectValue\": \"HDFS\", \"secondSelectValue\": \"Distributed_fs\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 9, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Do you have other data sources and data stores to choose from?\", \"targetListHasValue\": true}]',20,'[]','[{\"step\": 2, \"source\": \"DataSet(Demi-structured)\", \"target\": \"HDFS\", \"sourceIndex\": 4, \"targetIndex\": 5, \"sourceStreaming\": 1}]',NULL,NULL,NULL),(11,20,'2024-10-24 14:21:03','valid','[{\"choices\": {\"c1\": \"On-premises\"}, \"questionId\": 1, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"On-premises\"}], \"questionContent\": \"Where do you want to deploy your data lake ?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"No\", \"c2\": \"A little bit (medium budget)\", \"c3\": \"Yes\"}, \"questionId\": 4, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"A little bit (medium budget)\"}], \"questionContent\": \"Do you want to use paid software?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Streaming\", \"c2\": \"Batch\", \"c3\": \"Hybrid\"}, \"questionId\": 5, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Streaming\"}], \"questionContent\": \"How do you expect to ingest data?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Offline analysis\", \"c2\": \"Real-time analysis\"}, \"questionId\": 16, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Real-time analysis\"}], \"questionContent\": \"Do you want to perform offline analysis or real-time analysis?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}, \"questionId\": 6, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Logs\"}], \"questionContent\": \"From which source do you plan to ingest data? (Select all that apply)\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Database\", \"thirdSelectValue\": \"Nosql\", \"fourthSelectValue\": \"InfluxDB\", \"secondSelectValue\": \"Centralized_db\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 9, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Do you have other data sources and data stores to choose from?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 20, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Do you need real-time processing?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 21, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Is low latency your primary concern?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 22, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Will you be doing complex data analysis work in the future? (ML/DL)\", \"targetListHasValue\": true}]',NULL,'{\"2\": [{\"Id_t\": \"27\", \"count\": 1, \"name_t\": \"Apache Storm\"}, {\"Id_t\": \"24\", \"count\": 1, \"name_t\": \"Apache Spark\"}, {\"Id_t\": \"25\", \"count\": 1, \"name_t\": \"Apache Flink\"}]}','[{\"step\": 2, \"source\": \"Logs\", \"target\": \"InfluxDB\", \"sourceIndex\": 4, \"targetIndex\": 5, \"sourceStreaming\": 1}]',NULL,NULL,NULL),(11,22,'2024-10-24 14:25:02','valid','[{\"choices\": {\"c1\": \"On-premises\"}, \"questionId\": 1, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"On-premises\"}], \"questionContent\": \"Where do you want to deploy your data lake ?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"No\", \"c2\": \"A little bit (medium budget)\", \"c3\": \"Yes\"}, \"questionId\": 4, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"No\"}], \"questionContent\": \"Do you want to use paid software?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Streaming\", \"c2\": \"Batch\", \"c3\": \"Hybrid\"}, \"questionId\": 5, \"questionType\": \"single_choice\", \"userSelections\": [{\"c3\": \"Hybrid\"}], \"questionContent\": \"How do you expect to ingest data?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Offline analysis\", \"c2\": \"Real-time analysis\"}, \"questionId\": 16, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Real-time analysis\"}], \"questionContent\": \"Do you want to perform offline analysis or real-time analysis?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}, \"questionId\": 32, \"questionType\": \"single_choice\", \"userSelections\": [{\"firstSelectValue\": \"Database\", \"secondSelectValue\": \"NoSQL Database\"}], \"questionContent\": \"What data sources do you want for batch ingested data?\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Filesystem\", \"thirdSelectValue\": \"HDFS\", \"secondSelectValue\": \"Distributed_fs\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 9, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Do you have other data sources and data stores to choose from?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}, \"questionId\": 32, \"questionType\": \"single_choice\", \"userSelections\": [{\"firstSelectValue\": \"DataSet(Demi-structured)\"}], \"questionContent\": \"What data sources do you want for batch ingested data?\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Database\", \"thirdSelectValue\": \"Dis_Nosql\", \"fourthSelectValue\": \"Dis_MongoDB\", \"secondSelectValue\": \"Distributed_db\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 9, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Do you have other data sources and data stores to choose from?\", \"targetListHasValue\": true}, {\"choices\": {}, \"questionId\": 10, \"questionType\": \"multiple_choice\", \"userSelections\": [{\"HDFS\": \"NoSQL Database\"}, {\"Dis_MongoDB\": \"DataSet(Demi-structured)\"}], \"questionContent\": \"Please select the data sources you want to process together or individually\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Filesystem\", \"thirdSelectValue\": \"HDFS\", \"secondSelectValue\": \"Distributed_fs\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": false}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 11, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Do you consider expanding to stream processing tasks in the future?\", \"targetListHasValue\": true}, {\"choices\": {}, \"questionId\": 12, \"questionType\": \"multiple_choice\", \"userSelections\": [{\"HDFS\": [\"HDFS\", \"Dis_MongoDB\"]}], \"questionContent\": \"From which data sources do you want to analyze data?\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Filesystem\", \"thirdSelectValue\": \"HDFS\", \"secondSelectValue\": \"Distributed_fs\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": false}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 13, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Do you want to use SQL-like analysis tools?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 14, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Do you have requirements for the speed of data analysis?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"OLAP\", \"c2\": \"Visualization\", \"c3\": \"ML/DL\"}, \"questionId\": 15, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"OLAP\"}], \"questionContent\": \"What type of data analysis do you want to perform?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}, \"questionId\": 33, \"questionType\": \"single_choice\", \"userSelections\": [{\"firstSelectValue\": \"Logs\"}], \"questionContent\": \"What data sources do you want for streaming ingested data?\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Filesystem\", \"thirdSelectValue\": \"HDFS\", \"secondSelectValue\": \"Distributed_fs\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": false}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 9, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Do you have other data sources and data stores to choose from?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 20, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Do you need real-time processing?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 21, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Is low latency your primary concern?\", \"targetListHasValue\": true}]',NULL,'{\"1\": [{\"Id_t\": \"3\", \"name_t\": \"Apache Kafka\", \"totalScore\": 2, \"appearances\": 2, \"averageRank\": 1}, {\"Id_t\": \"8\", \"name_t\": \"Telegraf\", \"totalScore\": 2, \"appearances\": 1, \"averageRank\": 2}, {\"Id_t\": \"5\", \"name_t\": \"Logstash\", \"totalScore\": 3, \"appearances\": 1, \"averageRank\": 3}, {\"Id_t\": \"1\", \"name_t\": \"Apache NIFI\", \"totalScore\": 7, \"appearances\": 2, \"averageRank\": 3.5}, {\"Id_t\": \"6\", \"name_t\": \"Fluentd\", \"totalScore\": 4, \"appearances\": 1, \"averageRank\": 4}, {\"Id_t\": \"2\", \"name_t\": \"Apache Flume\", \"totalScore\": 6, \"appearances\": 1, \"averageRank\": 6}], \"2\": [{\"Id_t\": \"24\", \"count\": 1, \"name_t\": \"Apache Spark\"}, {\"Id_t\": \"25\", \"count\": 1, \"name_t\": \"Apache Flink\"}], \"3\": [{\"Id_t\": \"35\", \"count\": 1, \"name_t\": \"Apache Drill\"}, {\"Id_t\": \"36\", \"count\": 1, \"name_t\": \"Apache Hive\"}]}','[{\"step\": 1, \"source\": \"NoSQL Database\", \"target\": \"HDFS\", \"ingestType\": \"Batch\", \"sourceIndex\": 4, \"targetIndex\": 5}, {\"step\": 1, \"source\": \"DataSet(Demi-structured)\", \"target\": \"Dis_MongoDB\", \"ingestType\": \"Batch\", \"sourceIndex\": 7, \"targetIndex\": 8}, {\"step\": 2, \"source\": [\"HDFS\", \"Dis_MongoDB\"], \"target\": \"HDFS\", \"sourceIndex\": 10, \"targetIndex\": 11}, {\"step\": 3, \"source\": [[\"HDFS\"]], \"target\": \"HDFS\", \"sourceIndex\": 13, \"targetIndex\": 14}, {\"step\": 1, \"source\": \"Logs\", \"target\": \"HDFS\", \"ingestType\": \"Streaming\", \"sourceIndex\": 18, \"targetIndex\": 19, \"sourceStreaming\": 1}]',NULL,NULL,NULL),(11,23,'2024-10-25 07:56:07','valid','[{\"choices\": {\"c1\": \"On-premises\"}, \"questionId\": 1, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"On-premises\"}], \"questionContent\": \"Where do you want to deploy your data lake ?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"No\", \"c2\": \"A little bit (medium budget)\", \"c3\": \"Yes\"}, \"questionId\": 4, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"No\"}], \"questionContent\": \"Do you want to use paid software?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Streaming\", \"c2\": \"Batch\", \"c3\": \"Hybrid\"}, \"questionId\": 5, \"questionType\": \"single_choice\", \"userSelections\": [{\"c3\": \"Hybrid\"}], \"questionContent\": \"How do you expect to ingest data?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Offline analysis\", \"c2\": \"Real-time analysis\"}, \"questionId\": 16, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Real-time analysis\"}], \"questionContent\": \"Do you want to perform offline analysis or real-time analysis?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}, \"questionId\": 32, \"questionType\": \"single_choice\", \"userSelections\": [{\"firstSelectValue\": \"DataSet(Demi-structured)\"}], \"questionContent\": \"What data sources do you want for batch ingested data?\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Filesystem\", \"thirdSelectValue\": \"HDFS\", \"secondSelectValue\": \"Distributed_fs\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 9, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Do you have other data sources and data stores to choose from?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}, \"questionId\": 32, \"questionType\": \"single_choice\", \"userSelections\": [{\"firstSelectValue\": \"DataSet(Demi-structured)\"}], \"questionContent\": \"What data sources do you want for batch ingested data?\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Database\", \"thirdSelectValue\": \"Dis_Nosql\", \"fourthSelectValue\": \"Dis_MongoDB\", \"secondSelectValue\": \"Distributed_db\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 9, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Do you have other data sources and data stores to choose from?\", \"targetListHasValue\": true}, {\"choices\": {}, \"questionId\": 10, \"questionType\": \"multiple_choice\", \"userSelections\": [{\"HDFS\": \"DataSet(Demi-structured)\"}, {\"Dis_MongoDB\": \"DataSet(Demi-structured)\"}], \"questionContent\": \"Please select the data sources you want to process together or individually\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Database\", \"thirdSelectValue\": \"Dis_Nosql\", \"fourthSelectValue\": \"Dis_MongoDB\", \"secondSelectValue\": \"Distributed_db\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": false}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 11, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Do you consider expanding to stream processing tasks in the future?\", \"targetListHasValue\": true}, {\"choices\": {}, \"questionId\": 12, \"questionType\": \"multiple_choice\", \"userSelections\": [{\"Dis_MongoDB\": [\"HDFS\", \"Dis_MongoDB\"]}], \"questionContent\": \"From which data sources do you want to analyze data?\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Filesystem\", \"thirdSelectValue\": \"HDFS\", \"secondSelectValue\": \"Distributed_fs\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": false}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 13, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Do you want to use SQL-like analysis tools?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 14, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Do you have requirements for the speed of data analysis?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"OLAP\", \"c2\": \"Visualization\", \"c3\": \"ML/DL\"}, \"questionId\": 15, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Visualization\"}], \"questionContent\": \"What type of data analysis do you want to perform?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}, \"questionId\": 33, \"questionType\": \"single_choice\", \"userSelections\": [{\"firstSelectValue\": \"Http API\"}], \"questionContent\": \"What data sources do you want for streaming ingested data?\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Database\", \"thirdSelectValue\": \"Dis_Relational\", \"fourthSelectValue\": \"MySQL Cluster (NDB Cluster)\", \"secondSelectValue\": \"Distributed_db\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": false}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 9, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Do you have other data sources and data stores to choose from?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 20, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Do you need real-time processing?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 21, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Is low latency your primary concern?\", \"targetListHasValue\": true}]',NULL,'{\"1\": [{\"Id_t\": \"3\", \"name_t\": \"Apache Kafka\", \"totalScore\": 2, \"appearances\": 2, \"averageRank\": 1}, {\"Id_t\": \"8\", \"name_t\": \"Telegraf\", \"totalScore\": 2, \"appearances\": 1, \"averageRank\": 2}, {\"Id_t\": \"5\", \"name_t\": \"Logstash\", \"totalScore\": 5, \"appearances\": 2, \"averageRank\": 2.5}, {\"Id_t\": \"6\", \"name_t\": \"Fluentd\", \"totalScore\": 7, \"appearances\": 2, \"averageRank\": 3.5}, {\"Id_t\": \"1\", \"name_t\": \"Apache NIFI\", \"totalScore\": 9, \"appearances\": 2, \"averageRank\": 4.5}, {\"Id_t\": \"2\", \"name_t\": \"Apache Flume\", \"totalScore\": 11, \"appearances\": 2, \"averageRank\": 5.5}], \"2\": [{\"Id_t\": \"24\", \"count\": 1, \"name_t\": \"Apache Spark\"}, {\"Id_t\": \"25\", \"count\": 1, \"name_t\": \"Apache Flink\"}], \"3\": [{\"Id_t\": \"35\", \"count\": 1, \"name_t\": \"Apache Drill\"}]}','[{\"step\": 1, \"source\": \"DataSet(Demi-structured)\", \"target\": \"HDFS\", \"ingestType\": \"Batch\", \"sourceIndex\": 4, \"targetIndex\": 5}, {\"step\": 1, \"source\": \"DataSet(Demi-structured)\", \"target\": \"Dis_MongoDB\", \"ingestType\": \"Batch\", \"sourceIndex\": 7, \"targetIndex\": 8}, {\"step\": 2, \"source\": [\"HDFS\", \"Dis_MongoDB\"], \"target\": \"Dis_MongoDB\", \"sourceIndex\": 10, \"targetIndex\": 11}, {\"step\": 3, \"source\": [[\"Dis_MongoDB\"]], \"target\": \"HDFS\", \"sourceIndex\": 13, \"targetIndex\": 14}, {\"step\": 1, \"source\": \"Http API\", \"target\": \"MySQL Cluster (NDB Cluster)\", \"ingestType\": \"Streaming\", \"sourceIndex\": 18, \"targetIndex\": 19, \"sourceStreaming\": 1}]',77,NULL,NULL),(11,24,'2024-10-25 09:26:58','finished','[{\"choices\": {\"c1\": \"On-premises\"}, \"questionId\": 1, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"On-premises\"}], \"questionContent\": \"Where do you want to deploy your data lake ?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"No\", \"c2\": \"A little bit (medium budget)\", \"c3\": \"Yes\"}, \"questionId\": 4, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"A little bit (medium budget)\"}], \"questionContent\": \"Do you want to use paid software?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Streaming\", \"c2\": \"Batch\", \"c3\": \"Hybrid\"}, \"questionId\": 5, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Streaming\"}], \"questionContent\": \"How do you expect to ingest data?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Offline analysis\", \"c2\": \"Real-time analysis\"}, \"questionId\": 16, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Real-time analysis\"}], \"questionContent\": \"Do you want to perform offline analysis or real-time analysis?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}, \"questionId\": 6, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Logs\"}], \"questionContent\": \"From which source do you plan to ingest data? (Select all that apply)\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Filesystem\", \"thirdSelectValue\": \"HDFS\", \"secondSelectValue\": \"Distributed_fs\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 9, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Do you have other data sources and data stores to choose from?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 20, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Do you need real-time processing?\", \"targetListHasValue\": true}]',NULL,'{\"2\": [{\"Id_t\": \"24\", \"count\": 1, \"name_t\": \"Apache Spark\"}, {\"Id_t\": \"25\", \"count\": 1, \"name_t\": \"Apache Flink\"}, {\"Id_t\": \"27\", \"count\": 1, \"name_t\": \"Apache Storm\"}, {\"Id_t\": \"28\", \"count\": 1, \"name_t\": \"Apache Samza\"}]}','[{\"step\": 2, \"source\": \"Logs\", \"target\": \"HDFS\", \"sourceIndex\": 4, \"targetIndex\": 5, \"sourceStreaming\": 1}]',19,NULL,NULL),(17,25,'2024-11-20 18:48:04','saved','[{\"choices\": {\"c1\": \"On-premises\", \"c2\": \"On cloud\"}, \"questionId\": 1, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"On cloud\"}], \"questionContent\": \"Where do you want to deploy your data lake ?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"AWS Services\", \"c2\": \"Microsoft Azure Services\", \"c3\": \"Google Cloud Services\"}, \"questionId\": 30, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"AWS Services\"}], \"questionContent\": \"Please select the cloud service provider you would like to use?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Database snapshots or static files (CSV/JSON/Parquet, etc.) - Batch\", \"c2\": \"Real-time event streams (sensor data, logs, etc.) - Streaming\", \"c3\": \"Both - Hybrid\"}, \"questionId\": 36, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Real-time event streams (sensor data, logs, etc.) - Streaming\"}], \"questionContent\": \"Where does your data lake data come from?\", \"targetListHasValue\": true}]',38,'[]','[]',NULL,NULL,NULL),(17,26,'2024-11-20 18:57:57','valid','[{\"choices\": {\"c1\": \"On-premises\", \"c2\": \"On cloud\"}, \"questionId\": 1, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"On-premises\"}], \"questionContent\": \"Where do you want to deploy your data lake ?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"No\", \"c2\": \"A little bit (medium budget)\", \"c3\": \"Yes\"}, \"questionId\": 4, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"No\"}], \"questionContent\": \"Do you want to use paid software?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Streaming\", \"c2\": \"Batch\", \"c3\": \"Hybrid\"}, \"questionId\": 5, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Streaming\"}], \"questionContent\": \"How do you expect to ingest data?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Offline analysis\", \"c2\": \"Real-time analysis\"}, \"questionId\": 16, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Real-time analysis\"}], \"questionContent\": \"Do you want to perform offline analysis or real-time analysis?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}, \"questionId\": 6, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Logs\"}], \"questionContent\": \"From which source do you plan to ingest data? (Select all that apply)\", \"targetListHasValue\": true}, {\"choices\": {\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}, \"questionId\": 7, \"questionType\": \"select\", \"userSelections\": [{\"firstSelectValue\": \"Filesystem\", \"thirdSelectValue\": \"HDFS\", \"secondSelectValue\": \"Distributed_fs\"}], \"questionContent\": \"What data lake storage unit do you want?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 9, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"No\"}], \"questionContent\": \"Do you have other data sources and data stores to choose from?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 20, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Do you need real-time processing?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Yes\", \"c2\": \"No\"}, \"questionId\": 21, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Yes\"}], \"questionContent\": \"Is low latency your primary concern?\", \"targetListHasValue\": true}]',NULL,'{\"2\": [{\"Id_t\": \"25\", \"count\": 1, \"name_t\": \"Apache Flink\"}, {\"Id_t\": \"27\", \"count\": 1, \"name_t\": \"Apache Storm\"}, {\"Id_t\": \"28\", \"count\": 1, \"name_t\": \"Apache Samza\"}, {\"Id_t\": \"24\", \"count\": 1, \"name_t\": \"Apache Spark\"}]}','[{\"step\": 2, \"source\": \"Logs\", \"target\": \"HDFS\", \"sourceIndex\": 4, \"targetIndex\": 5, \"sourceStreaming\": 1}]',27,NULL,NULL),(17,27,'2024-11-21 00:22:34','finished','[{\"choices\": {\"c1\": \"On-premises\", \"c2\": \"On cloud\"}, \"questionId\": 1, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"On cloud\"}], \"questionContent\": \"Where do you want to deploy your data lake ?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"AWS Services\", \"c2\": \"Microsoft Azure Services\", \"c3\": \"Google Cloud Services\"}, \"questionId\": 30, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Microsoft Azure Services\"}], \"questionContent\": \"Please select the cloud service provider you would like to use?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Database snapshots or static files (CSV/JSON/Parquet, etc.) - Batch\", \"c2\": \"Real-time event streams (sensor data, logs, etc.) - Streaming\", \"c3\": \"Both - Hybrid\"}, \"questionId\": 36, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Real-time event streams (sensor data, logs, etc.) - Streaming\"}], \"questionContent\": \"Where does your data lake data come from?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"High (PB level)\", \"c2\": \"Medium (<=TB level)\"}, \"questionId\": 38, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Medium (<=TB level)\"}], \"questionContent\": \"What is your data volume?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"High latency tolerance (minutes to hours)\", \"c2\": \"Requires near real-time response (seconds)\"}, \"questionId\": 40, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"High latency tolerance (minutes to hours)\"}], \"questionContent\": \"What are your streaming data processing requirements?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Mainly simple cleaning, transformation, and partitioning.\", \"c2\": \"Requires complex ETL logic and multi-stage calculations.\", \"c3\": \"Involves real-time calculations and complex analysis (such as aggregation, anomaly detection)\"}, \"questionId\": 41, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Requires complex ETL logic and multi-stage calculations.\"}], \"questionContent\": \"What is the demand for data processing complexity?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"The query frequency is low, mainly offline analysis (daily or weekly).\", \"c2\": \"Frequent queries, requiring quasi-real-time or real-time analysis results.\"}, \"questionId\": 42, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Frequent queries, requiring quasi-real-time or real-time analysis results.\"}], \"questionContent\": \"What are the query frequency and real-time requirements?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Prefer low cost, and the O&M complexity is acceptable\", \"c2\": \"Prefer easy maintenance, even if the cost is higher, it is acceptable.\"}, \"questionId\": 43, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Prefer easy maintenance, even if the cost is higher, it is acceptable.\"}], \"questionContent\": \"What are the O&M and cost priorities of the data lake?\", \"targetListHasValue\": true}]',NULL,NULL,NULL,13,'{\"query\": \"Azure Synapse Analytics (dedicated mode)\", \"source\": \"streaming\", \"storage\": \"Azure Data Lake Storage\", \"ingestion\": [\"Event Hubs\", \"IoT Hub\"], \"processing\": [{\"complex\": \"HDInsight\"}], \"description\": \"Azure offers powerful integration with enterprise data and analytics solutions.\"}','Cloud'),(17,28,'2024-11-21 00:35:21','finished','[{\"choices\": {\"c1\": \"On-premises\", \"c2\": \"On cloud\"}, \"questionId\": 1, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"On cloud\"}], \"questionContent\": \"Where do you want to deploy your data lake ?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"AWS Services\", \"c2\": \"Microsoft Azure Services\", \"c3\": \"Google Cloud Services\"}, \"questionId\": 30, \"questionType\": \"single_choice\", \"userSelections\": [{\"c3\": \"Google Cloud Services\"}], \"questionContent\": \"Please select the cloud service provider you would like to use?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Database snapshots or static files (CSV/JSON/Parquet, etc.) - Batch\", \"c2\": \"Real-time event streams (sensor data, logs, etc.) - Streaming\", \"c3\": \"Both - Hybrid\"}, \"questionId\": 36, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Database snapshots or static files (CSV/JSON/Parquet, etc.) - Batch\"}], \"questionContent\": \"Where does your data lake data come from?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"High (PB level)\", \"c2\": \"Medium (<=TB level)\"}, \"questionId\": 38, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"High (PB level)\"}], \"questionContent\": \"What is your data volume?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"High latency tolerance (minutes to hours)\", \"c2\": \"Requires near real-time response (seconds)\"}, \"questionId\": 40, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Requires near real-time response (seconds)\"}], \"questionContent\": \"What are your streaming data processing requirements?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Mainly simple cleaning, transformation, and partitioning.\", \"c2\": \"Requires complex ETL logic and multi-stage calculations.\", \"c3\": \"Involves real-time calculations and complex analysis (such as aggregation, anomaly detection)\"}, \"questionId\": 41, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Requires complex ETL logic and multi-stage calculations.\"}], \"questionContent\": \"What is the demand for data processing complexity?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"The query frequency is low, mainly offline analysis (daily or weekly).\", \"c2\": \"Frequent queries, requiring quasi-real-time or real-time analysis results.\"}, \"questionId\": 42, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"The query frequency is low, mainly offline analysis (daily or weekly).\"}], \"questionContent\": \"What are the query frequency and real-time requirements?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Prefer low cost, and the O&M complexity is acceptable\", \"c2\": \"Prefer easy maintenance, even if the cost is higher, it is acceptable.\"}, \"questionId\": 43, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Prefer easy maintenance, even if the cost is higher, it is acceptable.\"}], \"questionContent\": \"What are the O&M and cost priorities of the data lake?\", \"targetListHasValue\": true}]',NULL,NULL,NULL,47,'{\"query\": \"BigQuery\", \"source\": \"batch\", \"storage\": \"Cloud Storage\", \"ingestion\": [\"Cloud Dataflow\", \"Transfer Appliance\"], \"processing\": [{\"complex\": \"Dataproc\"}], \"description\": \"GCP specializes in seamless integration and analytics tools like BigQuery.\"}','Cloud'),(17,29,'2024-11-21 00:40:10','finished','[{\"choices\": {\"c1\": \"On-premises\", \"c2\": \"On cloud\"}, \"questionId\": 1, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"On cloud\"}], \"questionContent\": \"Where do you want to deploy your data lake ?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"AWS Services\", \"c2\": \"Microsoft Azure Services\", \"c3\": \"Google Cloud Services\"}, \"questionId\": 30, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Microsoft Azure Services\"}], \"questionContent\": \"Please select the cloud service provider you would like to use?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Database snapshots or static files (CSV/JSON/Parquet, etc.) - Batch\", \"c2\": \"Real-time event streams (sensor data, logs, etc.) - Streaming\", \"c3\": \"Both - Hybrid\"}, \"questionId\": 36, \"questionType\": \"single_choice\", \"userSelections\": [{\"c3\": \"Both - Hybrid\"}], \"questionContent\": \"Where does your data lake data come from?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"High (PB level)\", \"c2\": \"Medium (<=TB level)\"}, \"questionId\": 38, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"High (PB level)\"}], \"questionContent\": \"What is your data volume?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"High latency tolerance (minutes to hours)\", \"c2\": \"Requires near real-time response (seconds)\"}, \"questionId\": 40, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Requires near real-time response (seconds)\"}], \"questionContent\": \"What are your streaming data processing requirements?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Mainly simple cleaning, transformation, and partitioning.\", \"c2\": \"Requires complex ETL logic and multi-stage calculations.\", \"c3\": \"Involves real-time calculations and complex analysis (such as aggregation, anomaly detection)\"}, \"questionId\": 41, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Requires complex ETL logic and multi-stage calculations.\"}], \"questionContent\": \"What is the demand for data processing complexity?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"The query frequency is low, mainly offline analysis (daily or weekly).\", \"c2\": \"Frequent queries, requiring quasi-real-time or real-time analysis results.\"}, \"questionId\": 42, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Frequent queries, requiring quasi-real-time or real-time analysis results.\"}], \"questionContent\": \"What are the query frequency and real-time requirements?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Prefer low cost, and the O&M complexity is acceptable\", \"c2\": \"Prefer easy maintenance, even if the cost is higher, it is acceptable.\"}, \"questionId\": 43, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"Prefer easy maintenance, even if the cost is higher, it is acceptable.\"}], \"questionContent\": \"What are the O&M and cost priorities of the data lake?\", \"targetListHasValue\": true}]',NULL,NULL,NULL,17,'{\"query\": \"Azure Synapse Analytics (dedicated mode)\", \"source\": \"hybrid\", \"storage\": \"Azure Data Lake Storage\", \"ingestion\": [\"Azure Data Factory\", \"Azure Import/Export\", \"Event Hubs\", \"IoT Hub\"], \"processing\": [{\"complex\": \"HDInsight\"}, {\"realTime\": \"Stream Analytics\"}], \"description\": \"Azure offers powerful integration with enterprise data and analytics solutions.\"}','Cloud'),(17,30,'2024-11-21 15:27:33','finished','[{\"choices\": {\"c1\": \"On-premises\", \"c2\": \"On cloud\"}, \"questionId\": 1, \"questionType\": \"single_choice\", \"userSelections\": [{\"c2\": \"On cloud\"}], \"questionContent\": \"Where do you want to deploy your data lake ?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"AWS Services\", \"c2\": \"Microsoft Azure Services\", \"c3\": \"Google Cloud Services\"}, \"questionId\": 30, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"AWS Services\"}], \"questionContent\": \"Please select the cloud service provider you would like to use?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Database snapshots or static files (CSV/JSON/Parquet, etc.) - Batch\", \"c2\": \"Real-time event streams (sensor data, logs, etc.) - Streaming\", \"c3\": \"Both - Hybrid\"}, \"questionId\": 36, \"questionType\": \"single_choice\", \"userSelections\": [{\"c3\": \"Both - Hybrid\"}], \"questionContent\": \"Where does your data lake data come from?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"High (PB level)\", \"c2\": \"Medium (<=TB level)\"}, \"questionId\": 38, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"High (PB level)\"}], \"questionContent\": \"What is your data volume?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"High latency tolerance (minutes to hours)\", \"c2\": \"Requires near real-time response (seconds)\"}, \"questionId\": 40, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"High latency tolerance (minutes to hours)\"}], \"questionContent\": \"What are your streaming data processing requirements?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Mainly simple cleaning, transformation, and partitioning.\", \"c2\": \"Requires complex ETL logic and multi-stage calculations.\", \"c3\": \"Involves real-time calculations and complex analysis (such as aggregation, anomaly detection)\"}, \"questionId\": 41, \"questionType\": \"single_choice\", \"userSelections\": [{\"c3\": \"Involves real-time calculations and complex analysis (such as aggregation, anomaly detection)\"}], \"questionContent\": \"What is the demand for data processing complexity?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"The query frequency is low, mainly offline analysis (daily or weekly).\", \"c2\": \"Frequent queries, requiring quasi-real-time or real-time analysis results.\"}, \"questionId\": 42, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"The query frequency is low, mainly offline analysis (daily or weekly).\"}], \"questionContent\": \"What are the query frequency and real-time requirements?\", \"targetListHasValue\": true}, {\"choices\": {\"c1\": \"Prefer low cost, and the O&M complexity is acceptable\", \"c2\": \"Prefer easy maintenance, even if the cost is higher, it is acceptable.\"}, \"questionId\": 43, \"questionType\": \"single_choice\", \"userSelections\": [{\"c1\": \"Prefer low cost, and the O&M complexity is acceptable\"}], \"questionContent\": \"What are the O&M and cost priorities of the data lake?\", \"targetListHasValue\": true}]',NULL,NULL,NULL,120,'{\"query\": \"Athena\", \"source\": \"hybrid\", \"storage\": \"Amazon S3\", \"ingestion\": [\"AWS Glue\", \"AWS DataSync\", \"Amazon Kinesis Data Streams\", \"Amazon MSK\"], \"processing\": [{\"complex\": \"Amazon EMR\"}, {\"realTime\": \"Kinesis Data Analytics or MSK + Flink\"}], \"description\": \"AWS provides robust and scalable tools for data lakes.\"}','Cloud');
/*!40000 ALTER TABLE `build` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `calendar`
--

DROP TABLE IF EXISTS `calendar`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `calendar` (
  `Date_created` timestamp NOT NULL DEFAULT (now()),
  PRIMARY KEY (`Date_created`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `calendar`
--

LOCK TABLES `calendar` WRITE;
/*!40000 ALTER TABLE `calendar` DISABLE KEYS */;
INSERT INTO `calendar` (`Date_created`) VALUES ('2024-09-24 09:27:07'),('2024-09-24 09:48:09'),('2024-09-24 12:06:34'),('2024-09-24 12:07:11'),('2024-09-24 12:10:13'),('2024-09-24 12:10:56'),('2024-09-24 12:13:53'),('2024-09-24 12:14:54'),('2024-09-24 12:18:43'),('2024-09-24 14:46:56'),('2024-09-30 08:12:25'),('2024-09-30 08:23:45'),('2024-09-30 08:27:34'),('2024-09-30 12:40:08'),('2024-09-30 14:18:04'),('2024-10-17 09:21:47'),('2024-10-21 09:14:04'),('2024-10-21 12:44:09'),('2024-10-21 14:03:55'),('2024-10-22 22:00:07'),('2024-10-23 09:53:41'),('2024-10-23 12:36:48'),('2024-10-23 14:01:55'),('2024-10-23 14:08:08'),('2024-10-23 14:09:56'),('2024-10-23 14:13:07'),('2024-10-24 13:25:24'),('2024-10-24 13:25:41'),('2024-10-24 13:26:37'),('2024-10-24 13:53:11'),('2024-10-24 14:21:03'),('2024-10-24 14:24:51'),('2024-10-24 14:25:02'),('2024-10-25 07:56:07'),('2024-10-25 09:26:58'),('2024-11-20 18:48:04'),('2024-11-20 18:57:57'),('2024-11-21 00:22:34'),('2024-11-21 00:35:21'),('2024-11-21 00:40:10'),('2024-11-21 15:27:33');
/*!40000 ALTER TABLE `calendar` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `contain`
--

DROP TABLE IF EXISTS `contain`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `contain` (
  `Id_R` int NOT NULL,
  `Id_zone` int NOT NULL,
  PRIMARY KEY (`Id_R`,`Id_zone`),
  KEY `Id_zone` (`Id_zone`),
  CONSTRAINT `contain_ibfk_1` FOREIGN KEY (`Id_R`) REFERENCES `datalake` (`Id_R`),
  CONSTRAINT `contain_ibfk_2` FOREIGN KEY (`Id_zone`) REFERENCES `zone` (`Id_zone`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `contain`
--

LOCK TABLES `contain` WRITE;
/*!40000 ALTER TABLE `contain` DISABLE KEYS */;
INSERT INTO `contain` (`Id_R`, `Id_zone`) VALUES (22,1),(23,1),(28,1),(29,1),(30,1),(20,2),(22,2),(23,2),(24,2),(26,2),(27,2),(28,2),(29,2),(30,2),(20,3),(22,3),(23,3),(24,3),(26,3),(27,3),(28,3),(29,3),(30,3);
/*!40000 ALTER TABLE `contain` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `datalake`
--

DROP TABLE IF EXISTS `datalake`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `datalake` (
  `Id_R` int NOT NULL AUTO_INCREMENT,
  `name_dl` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`Id_R`)
) ENGINE=InnoDB AUTO_INCREMENT=31 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `datalake`
--

LOCK TABLES `datalake` WRITE;
/*!40000 ALTER TABLE `datalake` DISABLE KEYS */;
INSERT INTO `datalake` (`Id_R`, `name_dl`) VALUES (11,'Your Data Lake'),(20,'Data Lake'),(22,'hahaha '),(23,'Data Lake'),(24,'Data Lake'),(25,'Your Data Lake'),(26,'Data Lake'),(27,'Data Lake'),(28,'Data Lake'),(29,'Data Lake'),(30,'Data Lake');
/*!40000 ALTER TABLE `datalake` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `datasource`
--

DROP TABLE IF EXISTS `datasource`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `datasource` (
  `id_datasource` int NOT NULL AUTO_INCREMENT,
  `name_datasource` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`id_datasource`)
) ENGINE=InnoDB AUTO_INCREMENT=8 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `datasource`
--

LOCK TABLES `datasource` WRITE;
/*!40000 ALTER TABLE `datasource` DISABLE KEYS */;
INSERT INTO `datasource` (`id_datasource`, `name_datasource`) VALUES (1,'Http API'),(2,'Relational Database'),(3,'NoSQL Database'),(4,'Dataset(demi-structured)'),(5,'Files(Unstructured)'),(6,'Logs'),(7,'IoT');
/*!40000 ALTER TABLE `datasource` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `ecosystem`
--

DROP TABLE IF EXISTS `ecosystem`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `ecosystem` (
  `Id_eco` int NOT NULL AUTO_INCREMENT,
  `Name_eco` varchar(50) DEFAULT NULL,
  `logo_eco` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`Id_eco`)
) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `ecosystem`
--

LOCK TABLES `ecosystem` WRITE;
/*!40000 ALTER TABLE `ecosystem` DISABLE KEYS */;
INSERT INTO `ecosystem` (`Id_eco`, `Name_eco`, `logo_eco`) VALUES (1,'Hadoop',NULL),(2,'Spark',NULL),(3,'AWS',NULL),(4,'Azure',NULL),(5,'Google Cloud',NULL),(6,'Elastic',NULL),(7,'Alibaba',NULL),(8,'ELK',NULL);
/*!40000 ALTER TABLE `ecosystem` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `implementation`
--

DROP TABLE IF EXISTS `implementation`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `implementation` (
  `Id_t` int NOT NULL,
  `Id_sto_Output` int NOT NULL,
  `Id_sto_Input` int NOT NULL,
  `Id_R` int NOT NULL,
  `Id_zone` int NOT NULL,
  `Rank_tool` int DEFAULT NULL,
  `Type_preparation_zone` enum('Batch','Streaming') DEFAULT NULL,
  PRIMARY KEY (`Id_t`,`Id_sto_Output`,`Id_sto_Input`,`Id_R`,`Id_zone`),
  KEY `Id_sto_Output` (`Id_sto_Output`),
  KEY `Id_sto_Input` (`Id_sto_Input`),
  KEY `Id_R` (`Id_R`),
  KEY `Id_zone` (`Id_zone`),
  CONSTRAINT `implementation_ibfk_1` FOREIGN KEY (`Id_t`) REFERENCES `tools` (`Id_t`),
  CONSTRAINT `implementation_ibfk_2` FOREIGN KEY (`Id_sto_Output`) REFERENCES `storage` (`Id_sto`),
  CONSTRAINT `implementation_ibfk_3` FOREIGN KEY (`Id_sto_Input`) REFERENCES `storage` (`Id_sto`),
  CONSTRAINT `implementation_ibfk_4` FOREIGN KEY (`Id_R`) REFERENCES `datalake` (`Id_R`),
  CONSTRAINT `implementation_ibfk_5` FOREIGN KEY (`Id_zone`) REFERENCES `zone` (`Id_zone`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `implementation`
--

LOCK TABLES `implementation` WRITE;
/*!40000 ALTER TABLE `implementation` DISABLE KEYS */;
/*!40000 ALTER TABLE `implementation` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `ingestfrom`
--

DROP TABLE IF EXISTS `ingestfrom`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `ingestfrom` (
  `id_ingest` int NOT NULL AUTO_INCREMENT,
  `id_datasource` int DEFAULT NULL,
  `Id_t` int DEFAULT NULL,
  PRIMARY KEY (`id_ingest`),
  KEY `id_datasource` (`id_datasource`),
  KEY `Id_t` (`Id_t`),
  CONSTRAINT `ingestfrom_ibfk_1` FOREIGN KEY (`id_datasource`) REFERENCES `datasource` (`id_datasource`),
  CONSTRAINT `ingestfrom_ibfk_2` FOREIGN KEY (`Id_t`) REFERENCES `tools` (`Id_t`)
) ENGINE=InnoDB AUTO_INCREMENT=92 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `ingestfrom`
--

LOCK TABLES `ingestfrom` WRITE;
/*!40000 ALTER TABLE `ingestfrom` DISABLE KEYS */;
INSERT INTO `ingestfrom` (`id_ingest`, `id_datasource`, `Id_t`) VALUES (1,1,1),(2,2,1),(3,3,1),(4,4,1),(5,5,1),(6,6,1),(7,7,1),(8,1,2),(9,4,2),(10,5,2),(11,6,2),(12,7,2),(13,1,3),(14,2,3),(15,3,3),(16,4,3),(17,5,3),(18,6,3),(19,7,3),(20,1,4),(21,2,4),(22,3,4),(23,4,4),(24,5,4),(25,6,4),(26,7,4),(27,1,5),(28,2,5),(29,4,5),(30,5,5),(31,6,5),(32,7,5),(33,4,6),(34,5,6),(35,6,6),(36,7,6),(37,4,7),(38,5,7),(39,6,7),(40,7,7),(41,1,8),(42,2,8),(43,3,8),(44,4,8),(45,5,8),(46,6,8),(47,7,8),(48,2,9),(49,3,9),(50,2,10),(51,2,11),(52,1,12),(53,2,12),(54,3,12),(55,4,12),(56,5,12),(57,6,12),(58,7,12),(59,1,13),(60,2,13),(61,3,13),(62,4,13),(63,5,13),(64,6,13),(65,7,13),(66,1,14),(67,2,14),(68,3,14),(69,4,14),(70,5,14),(71,6,14),(72,7,14),(73,1,15),(74,2,15),(75,3,15),(76,4,15),(77,5,15),(78,6,15),(79,7,15),(80,1,24),(81,6,24),(82,7,24),(83,1,25),(84,6,25),(85,7,25),(86,1,27),(87,6,27),(88,7,27),(89,1,28),(90,6,28),(91,7,28);
/*!40000 ALTER TABLE `ingestfrom` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `input`
--

DROP TABLE IF EXISTS `input`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `input` (
  `Id_t` int NOT NULL,
  `Id_sto` int NOT NULL,
  `dplymt_archi_input` varchar(50) DEFAULT NULL,
  `dplymt_mode_sto_input` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`Id_t`,`Id_sto`),
  KEY `Id_sto` (`Id_sto`),
  CONSTRAINT `input_ibfk_1` FOREIGN KEY (`Id_t`) REFERENCES `tools` (`Id_t`),
  CONSTRAINT `input_ibfk_2` FOREIGN KEY (`Id_sto`) REFERENCES `storage` (`Id_sto`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `input`
--

LOCK TABLES `input` WRITE;
/*!40000 ALTER TABLE `input` DISABLE KEYS */;
INSERT INTO `input` (`Id_t`, `Id_sto`, `dplymt_archi_input`, `dplymt_mode_sto_input`) VALUES (1,10001,'Dis','On-p'),(1,10002,'Dis','Cloud'),(1,10003,'Dis','Cloud'),(1,10004,'Dis','Cloud'),(1,10005,'Dis','Cloud'),(1,10006,'Dis','Cloud'),(1,10007,'Cen','On-p'),(1,10008,'Cen','On-p'),(1,10009,'Cen','On-p'),(1,10010,'Cen','On-p'),(1,10011,'Cen','On-p'),(1,10012,'Cen','Cloud'),(1,10013,'Cen','Cloud'),(1,10014,'Cen','Cloud'),(1,10015,'Cen','Cloud'),(1,10016,'Cen','Cloud'),(1,10017,'Cen','Cloud'),(1,10018,'Cen','Cloud'),(1,10019,'Cen','On-p'),(1,10020,'Cen','On-p'),(1,10021,'Cen','On-p'),(1,10022,'Cen','On-p'),(1,10023,'Dis','On-p'),(1,10024,'Dis','On-p'),(1,10025,'Dis','On-p'),(1,10026,'Dis','Cloud'),(1,10027,'Dis','Cloud'),(1,10028,'Dis','Cloud'),(1,10029,'Dis','Cloud'),(1,10030,'Dis','Cloud'),(1,10031,'Dis','Cloud'),(1,10032,'Dis','On-p'),(1,10033,'Dis','On-p'),(1,10034,'Dis','On-p'),(1,10035,'Dis','On-p'),(1,10036,'Dis','On-p'),(1,10037,'Dis','Cloud'),(1,10038,'Dis','Cloud'),(1,10039,'Dis','Cloud'),(1,10040,'Dis','Cloud'),(1,10041,'Dis','Cloud'),(1,10042,'Dis','On-p'),(1,10043,'Dis','Cloud'),(1,10044,'Dis','Cloud'),(1,10045,'Dis','Cloud'),(1,10046,'Cen','On-p'),(1,10047,'Cen','On-p'),(1,10048,'Cen','On-p'),(1,10049,'Cen','On-p'),(1,10050,'Dis','On-p'),(1,10051,'Dis','On-p'),(1,10052,'Dis','Cloud'),(1,10053,'Dis','Cloud'),(1,10054,'Dis','Cloud'),(2,10007,'Cen','On-p'),(2,10011,'Cen','On-p'),(2,10025,'Dis','On-p'),(2,10042,'Dis','On-p'),(2,10043,'Dis','Cloud'),(2,10044,'Dis','Cloud'),(2,10045,'Dis','Cloud'),(2,10046,'Cen','On-p'),(2,10047,'Cen','On-p'),(2,10048,'Cen','On-p'),(2,10049,'Cen','On-p'),(3,10001,'Dis','On-p'),(3,10002,'Dis','Cloud'),(3,10003,'Dis','Cloud'),(3,10004,'Dis','Cloud'),(3,10005,'Dis','Cloud'),(3,10006,'Dis','Cloud'),(3,10007,'Cen','On-p'),(3,10008,'Cen','On-p'),(3,10009,'Cen','On-p'),(3,10010,'Cen','On-p'),(3,10011,'Cen','On-p'),(3,10012,'Cen','Cloud'),(3,10013,'Cen','Cloud'),(3,10014,'Cen','Cloud'),(3,10015,'Cen','Cloud'),(3,10016,'Cen','Cloud'),(3,10017,'Cen','Cloud'),(3,10018,'Cen','Cloud'),(3,10019,'Cen','On-p'),(3,10020,'Cen','On-p'),(3,10021,'Cen','On-p'),(3,10022,'Cen','On-p'),(3,10023,'Dis','On-p'),(3,10024,'Dis','On-p'),(3,10025,'Dis','On-p'),(3,10026,'Dis','Cloud'),(3,10027,'Dis','Cloud'),(3,10028,'Dis','Cloud'),(3,10029,'Dis','Cloud'),(3,10030,'Dis','Cloud'),(3,10031,'Dis','Cloud'),(3,10032,'Dis','On-p'),(3,10033,'Dis','On-p'),(3,10034,'Dis','On-p'),(3,10035,'Dis','On-p'),(3,10036,'Dis','On-p'),(3,10037,'Dis','Cloud'),(3,10038,'Dis','Cloud'),(3,10039,'Dis','Cloud'),(3,10040,'Dis','Cloud'),(3,10041,'Dis','Cloud'),(3,10042,'Dis','On-p'),(3,10043,'Dis','Cloud'),(3,10044,'Dis','Cloud'),(3,10045,'Dis','Cloud'),(3,10046,'Cen','On-p'),(3,10047,'Cen','On-p'),(3,10048,'Cen','On-p'),(3,10049,'Cen','On-p'),(3,10050,'Dis','On-p'),(3,10051,'Dis','On-p'),(3,10052,'Dis','Cloud'),(3,10053,'Dis','Cloud'),(3,10054,'Dis','Cloud'),(4,10001,'Dis','On-p'),(4,10002,'Dis','Cloud'),(4,10003,'Dis','Cloud'),(4,10004,'Dis','Cloud'),(4,10005,'Dis','Cloud'),(4,10006,'Dis','Cloud'),(4,10007,'Cen','On-p'),(4,10008,'Cen','On-p'),(4,10009,'Cen','On-p'),(4,10010,'Cen','On-p'),(4,10011,'Cen','On-p'),(4,10012,'Cen','Cloud'),(4,10013,'Cen','Cloud'),(4,10014,'Cen','Cloud'),(4,10015,'Cen','Cloud'),(4,10016,'Cen','Cloud'),(4,10017,'Cen','Cloud'),(4,10018,'Cen','Cloud'),(4,10020,'Cen','On-p'),(4,10023,'Dis','On-p'),(4,10024,'Dis','On-p'),(4,10025,'Dis','On-p'),(4,10026,'Dis','Cloud'),(4,10027,'Dis','Cloud'),(4,10028,'Dis','Cloud'),(4,10029,'Dis','Cloud'),(4,10030,'Dis','Cloud'),(4,10031,'Dis','Cloud'),(4,10032,'Dis','On-p'),(4,10033,'Dis','On-p'),(4,10034,'Dis','On-p'),(4,10042,'Dis','On-p'),(4,10043,'Dis','Cloud'),(4,10044,'Dis','Cloud'),(4,10045,'Dis','Cloud'),(4,10046,'Cen','On-p'),(4,10047,'Cen','On-p'),(4,10048,'Cen','On-p'),(4,10049,'Cen','On-p'),(4,10050,'Dis','On-p'),(4,10052,'Dis','Cloud'),(4,10053,'Dis','Cloud'),(4,10054,'Dis','Cloud'),(5,10007,'Cen','On-p'),(5,10008,'Cen','On-p'),(5,10009,'Cen','On-p'),(5,10010,'Cen','On-p'),(5,10011,'Cen','On-p'),(5,10012,'Cen','Cloud'),(5,10013,'Cen','Cloud'),(5,10014,'Cen','Cloud'),(5,10015,'Cen','Cloud'),(5,10016,'Cen','Cloud'),(5,10017,'Cen','Cloud'),(5,10018,'Cen','Cloud'),(5,10019,'Cen','On-p'),(5,10020,'Cen','On-p'),(5,10023,'Dis','On-p'),(5,10024,'Dis','On-p'),(5,10025,'Dis','On-p'),(5,10026,'Dis','Cloud'),(5,10027,'Dis','Cloud'),(5,10028,'Dis','Cloud'),(5,10029,'Dis','Cloud'),(5,10030,'Dis','Cloud'),(5,10031,'Dis','Cloud'),(5,10042,'Dis','On-p'),(5,10043,'Dis','Cloud'),(5,10044,'Dis','Cloud'),(5,10045,'Dis','Cloud'),(5,10046,'Cen','On-p'),(5,10047,'Cen','On-p'),(5,10048,'Cen','On-p'),(5,10049,'Cen','On-p'),(5,10050,'Dis','On-p'),(5,10051,'Dis','On-p'),(5,10052,'Dis','Cloud'),(5,10053,'Dis','Cloud'),(5,10054,'Dis','Cloud'),(6,10007,'Cen','On-p'),(6,10008,'Cen','On-p'),(6,10009,'Cen','On-p'),(6,10010,'Cen','On-p'),(6,10011,'Cen','On-p'),(6,10012,'Cen','Cloud'),(6,10013,'Cen','Cloud'),(6,10014,'Cen','Cloud'),(6,10015,'Cen','Cloud'),(6,10016,'Cen','Cloud'),(6,10017,'Cen','Cloud'),(6,10018,'Cen','Cloud'),(6,10020,'Cen','On-p'),(6,10023,'Dis','On-p'),(6,10024,'Dis','On-p'),(6,10025,'Dis','On-p'),(6,10026,'Dis','Cloud'),(6,10027,'Dis','Cloud'),(6,10028,'Dis','Cloud'),(6,10029,'Dis','Cloud'),(6,10030,'Dis','Cloud'),(6,10031,'Dis','Cloud'),(6,10034,'Dis','On-p'),(6,10037,'Dis','Cloud'),(7,10019,'Cen','On-p'),(9,10007,'Cen','On-p'),(9,10008,'Cen','On-p'),(9,10010,'Cen','On-p'),(9,10011,'Cen','On-p'),(9,10020,'Cen','On-p'),(9,10023,'Dis','On-p'),(9,10025,'Dis','On-p'),(9,10033,'Dis','On-p'),(9,10034,'Dis','On-p'),(10,10007,'Cen','On-p'),(10,10025,'Dis','On-p'),(11,10010,'Cen','On-p'),(12,10001,'Dis','On-p'),(12,10002,'Dis','Cloud'),(12,10003,'Dis','Cloud'),(12,10004,'Dis','Cloud'),(12,10005,'Dis','Cloud'),(12,10006,'Dis','Cloud'),(12,10007,'Cen','On-p'),(12,10008,'Cen','On-p'),(12,10009,'Cen','On-p'),(12,10010,'Cen','On-p'),(12,10011,'Cen','On-p'),(12,10012,'Cen','Cloud'),(12,10013,'Cen','Cloud'),(12,10014,'Cen','Cloud'),(12,10015,'Cen','Cloud'),(12,10016,'Cen','Cloud'),(12,10017,'Cen','Cloud'),(12,10018,'Cen','Cloud'),(12,10019,'Cen','On-p'),(12,10020,'Cen','On-p'),(12,10021,'Cen','On-p'),(12,10022,'Cen','On-p'),(12,10023,'Dis','On-p'),(12,10024,'Dis','On-p'),(12,10025,'Dis','On-p'),(12,10026,'Dis','Cloud'),(12,10027,'Dis','Cloud'),(12,10028,'Dis','Cloud'),(12,10029,'Dis','Cloud'),(12,10030,'Dis','Cloud'),(12,10031,'Dis','Cloud'),(12,10032,'Dis','On-p'),(12,10033,'Dis','On-p'),(12,10034,'Dis','On-p'),(12,10035,'Dis','On-p'),(12,10036,'Dis','On-p'),(12,10037,'Dis','Cloud'),(12,10038,'Dis','Cloud'),(12,10039,'Dis','Cloud'),(12,10040,'Dis','Cloud'),(12,10041,'Dis','Cloud'),(12,10042,'Dis','On-p'),(12,10043,'Dis','Cloud'),(12,10044,'Dis','Cloud'),(12,10045,'Dis','Cloud'),(12,10046,'Cen','On-p'),(12,10047,'Cen','On-p'),(12,10048,'Cen','On-p'),(12,10049,'Cen','On-p'),(12,10050,'Dis','On-p'),(12,10051,'Dis','On-p'),(12,10052,'Dis','Cloud'),(12,10053,'Dis','Cloud'),(12,10054,'Dis','Cloud'),(13,10001,'Dis','On-p'),(13,10002,'Dis','Cloud'),(13,10003,'Dis','Cloud'),(13,10004,'Dis','Cloud'),(13,10005,'Dis','Cloud'),(13,10006,'Dis','Cloud'),(13,10007,'Cen','On-p'),(13,10008,'Cen','On-p'),(13,10009,'Cen','On-p'),(13,10010,'Cen','On-p'),(13,10011,'Cen','On-p'),(13,10012,'Cen','Cloud'),(13,10013,'Cen','Cloud'),(13,10014,'Cen','Cloud'),(13,10015,'Cen','Cloud'),(13,10016,'Cen','Cloud'),(13,10017,'Cen','Cloud'),(13,10018,'Cen','Cloud'),(13,10019,'Cen','On-p'),(13,10020,'Cen','On-p'),(13,10021,'Cen','On-p'),(13,10022,'Cen','On-p'),(13,10023,'Dis','On-p'),(13,10024,'Dis','On-p'),(13,10025,'Dis','On-p'),(13,10026,'Dis','Cloud'),(13,10027,'Dis','Cloud'),(13,10028,'Dis','Cloud'),(13,10029,'Dis','Cloud'),(13,10030,'Dis','Cloud'),(13,10031,'Dis','Cloud'),(13,10032,'Dis','On-p'),(13,10033,'Dis','On-p'),(13,10034,'Dis','On-p'),(13,10035,'Dis','On-p'),(13,10036,'Dis','On-p'),(13,10037,'Dis','Cloud'),(13,10038,'Dis','Cloud'),(13,10039,'Dis','Cloud'),(13,10040,'Dis','Cloud'),(13,10041,'Dis','Cloud'),(13,10042,'Dis','On-p'),(13,10043,'Dis','Cloud'),(13,10044,'Dis','Cloud'),(13,10045,'Dis','Cloud'),(13,10046,'Cen','On-p'),(13,10047,'Cen','On-p'),(13,10048,'Cen','On-p'),(13,10049,'Cen','On-p'),(13,10050,'Dis','On-p'),(13,10051,'Dis','On-p'),(13,10052,'Dis','Cloud'),(13,10053,'Dis','Cloud'),(13,10054,'Dis','Cloud'),(14,10001,'Dis','On-p'),(14,10002,'Dis','Cloud'),(14,10003,'Dis','Cloud'),(14,10004,'Dis','Cloud'),(14,10005,'Dis','Cloud'),(14,10006,'Dis','Cloud'),(14,10007,'Cen','On-p'),(14,10008,'Cen','On-p'),(14,10009,'Cen','On-p'),(14,10010,'Cen','On-p'),(14,10011,'Cen','On-p'),(14,10012,'Cen','Cloud'),(14,10013,'Cen','Cloud'),(14,10014,'Cen','Cloud'),(14,10015,'Cen','Cloud'),(14,10016,'Cen','Cloud'),(14,10017,'Cen','Cloud'),(14,10018,'Cen','Cloud'),(14,10019,'Cen','On-p'),(14,10020,'Cen','On-p'),(14,10021,'Cen','On-p'),(14,10022,'Cen','On-p'),(14,10023,'Dis','On-p'),(14,10024,'Dis','On-p'),(14,10025,'Dis','On-p'),(14,10026,'Dis','Cloud'),(14,10027,'Dis','Cloud'),(14,10028,'Dis','Cloud'),(14,10029,'Dis','Cloud'),(14,10030,'Dis','Cloud'),(14,10031,'Dis','Cloud'),(14,10032,'Dis','On-p'),(14,10033,'Dis','On-p'),(14,10034,'Dis','On-p'),(14,10035,'Dis','On-p'),(14,10036,'Dis','On-p'),(14,10037,'Dis','Cloud'),(14,10038,'Dis','Cloud'),(14,10039,'Dis','Cloud'),(14,10040,'Dis','Cloud'),(14,10041,'Dis','Cloud'),(14,10042,'Dis','On-p'),(14,10043,'Dis','Cloud'),(14,10044,'Dis','Cloud'),(14,10045,'Dis','Cloud'),(14,10046,'Cen','On-p'),(14,10047,'Cen','On-p'),(14,10048,'Cen','On-p'),(14,10049,'Cen','On-p'),(14,10050,'Dis','On-p'),(14,10051,'Dis','On-p'),(14,10052,'Dis','Cloud'),(14,10053,'Dis','Cloud'),(14,10054,'Dis','Cloud'),(15,10001,'Dis','On-p'),(15,10002,'Dis','Cloud'),(15,10003,'Dis','Cloud'),(15,10004,'Dis','Cloud'),(15,10005,'Dis','Cloud'),(15,10006,'Dis','Cloud'),(15,10007,'Cen','On-p'),(15,10008,'Cen','On-p'),(15,10009,'Cen','On-p'),(15,10010,'Cen','On-p'),(15,10011,'Cen','On-p'),(15,10012,'Cen','Cloud'),(15,10013,'Cen','Cloud'),(15,10014,'Cen','Cloud'),(15,10015,'Cen','Cloud'),(15,10016,'Cen','Cloud'),(15,10017,'Cen','Cloud'),(15,10018,'Cen','Cloud'),(15,10019,'Cen','On-p'),(15,10020,'Cen','On-p'),(15,10021,'Cen','On-p'),(15,10022,'Cen','On-p'),(15,10023,'Dis','On-p'),(15,10024,'Dis','On-p'),(15,10025,'Dis','On-p'),(15,10026,'Dis','Cloud'),(15,10027,'Dis','Cloud'),(15,10028,'Dis','Cloud'),(15,10029,'Dis','Cloud'),(15,10030,'Dis','Cloud'),(15,10031,'Dis','Cloud'),(15,10032,'Dis','On-p'),(15,10033,'Dis','On-p'),(15,10034,'Dis','On-p'),(15,10035,'Dis','On-p'),(15,10036,'Dis','On-p'),(15,10037,'Dis','Cloud'),(15,10038,'Dis','Cloud'),(15,10039,'Dis','Cloud'),(15,10040,'Dis','Cloud'),(15,10041,'Dis','Cloud'),(15,10042,'Dis','On-p'),(15,10043,'Dis','Cloud'),(15,10044,'Dis','Cloud'),(15,10045,'Dis','Cloud'),(15,10046,'Cen','On-p'),(15,10047,'Cen','On-p'),(15,10048,'Cen','On-p'),(15,10049,'Cen','On-p'),(15,10050,'Dis','On-p'),(15,10051,'Dis','On-p'),(15,10052,'Dis','Cloud'),(15,10053,'Dis','Cloud'),(15,10054,'Dis','Cloud'),(24,10001,'Dis','On-p'),(24,10002,'Dis','Cloud'),(24,10003,'Dis','Cloud'),(24,10004,'Dis','Cloud'),(24,10005,'Dis','Cloud'),(24,10006,'Dis','Cloud'),(24,10007,'Cen','On-p'),(24,10008,'Cen','On-p'),(24,10009,'Cen','On-p'),(24,10010,'Cen','On-p'),(24,10011,'Cen','On-p'),(24,10012,'Cen','Cloud'),(24,10013,'Cen','Cloud'),(24,10014,'Cen','Cloud'),(24,10015,'Cen','Cloud'),(24,10016,'Cen','Cloud'),(24,10017,'Cen','Cloud'),(24,10018,'Cen','Cloud'),(24,10019,'Cen','On-p'),(24,10020,'Cen','On-p'),(24,10021,'Cen','On-p'),(24,10022,'Cen','On-p'),(24,10023,'Dis','On-p'),(24,10024,'Dis','On-p'),(24,10025,'Dis','On-p'),(24,10026,'Dis','Cloud'),(24,10027,'Dis','Cloud'),(24,10028,'Dis','Cloud'),(24,10029,'Dis','Cloud'),(24,10030,'Dis','Cloud'),(24,10031,'Dis','Cloud'),(24,10032,'Dis','On-p'),(24,10033,'Dis','On-p'),(24,10034,'Dis','On-p'),(24,10035,'Dis','On-p'),(24,10036,'Dis','On-p'),(24,10037,'Dis','Cloud'),(24,10038,'Dis','Cloud'),(24,10039,'Dis','Cloud'),(24,10040,'Dis','Cloud'),(24,10041,'Dis','Cloud'),(24,10042,'Dis','On-p'),(24,10043,'Dis','Cloud'),(24,10044,'Dis','Cloud'),(24,10045,'Dis','Cloud'),(24,10046,'Cen','On-p'),(24,10047,'Cen','On-p'),(24,10048,'Cen','On-p'),(24,10049,'Cen','On-p'),(24,10050,'Dis','On-p'),(24,10051,'Dis','On-p'),(24,10052,'Dis','Cloud'),(24,10053,'Dis','Cloud'),(24,10054,'Dis','Cloud'),(25,10001,'Dis','On-p'),(25,10002,'Dis','Cloud'),(25,10003,'Dis','Cloud'),(25,10004,'Dis','Cloud'),(25,10005,'Dis','Cloud'),(25,10006,'Dis','Cloud'),(25,10007,'Cen','On-p'),(25,10008,'Cen','On-p'),(25,10009,'Cen','On-p'),(25,10010,'Cen','On-p'),(25,10011,'Cen','On-p'),(25,10012,'Cen','Cloud'),(25,10013,'Cen','Cloud'),(25,10014,'Cen','Cloud'),(25,10015,'Cen','Cloud'),(25,10016,'Cen','Cloud'),(25,10017,'Cen','Cloud'),(25,10018,'Cen','Cloud'),(25,10020,'Cen','On-p'),(25,10021,'Cen','On-p'),(25,10022,'Cen','On-p'),(25,10023,'Dis','On-p'),(25,10024,'Dis','On-p'),(25,10025,'Dis','On-p'),(25,10026,'Dis','Cloud'),(25,10027,'Dis','Cloud'),(25,10028,'Dis','Cloud'),(25,10029,'Dis','Cloud'),(25,10030,'Dis','Cloud'),(25,10031,'Dis','Cloud'),(25,10032,'Dis','On-p'),(25,10034,'Dis','On-p'),(25,10035,'Dis','On-p'),(25,10041,'Dis','Cloud'),(25,10042,'Dis','On-p'),(25,10043,'Dis','Cloud'),(25,10044,'Dis','Cloud'),(25,10045,'Dis','Cloud'),(25,10046,'Cen','On-p'),(25,10047,'Cen','On-p'),(25,10048,'Cen','On-p'),(25,10049,'Cen','On-p'),(25,10050,'Dis','On-p'),(25,10051,'Dis','On-p'),(25,10052,'Dis','Cloud'),(25,10053,'Dis','Cloud'),(25,10054,'Dis','Cloud'),(26,10001,'Dis','On-p'),(26,10002,'Dis','Cloud'),(26,10003,'Dis','Cloud'),(26,10004,'Dis','Cloud'),(26,10005,'Dis','Cloud'),(26,10006,'Dis','Cloud'),(26,10007,'Cen','On-p'),(26,10008,'Cen','On-p'),(26,10009,'Cen','On-p'),(26,10010,'Cen','On-p'),(26,10011,'Cen','On-p'),(26,10012,'Cen','Cloud'),(26,10013,'Cen','Cloud'),(26,10014,'Cen','Cloud'),(26,10015,'Cen','Cloud'),(26,10016,'Cen','Cloud'),(26,10017,'Cen','Cloud'),(26,10018,'Cen','Cloud'),(26,10019,'Cen','On-p'),(26,10020,'Cen','On-p'),(26,10021,'Cen','On-p'),(26,10022,'Cen','On-p'),(26,10023,'Dis','On-p'),(26,10024,'Dis','On-p'),(26,10025,'Dis','On-p'),(26,10026,'Dis','Cloud'),(26,10027,'Dis','Cloud'),(26,10028,'Dis','Cloud'),(26,10029,'Dis','Cloud'),(26,10030,'Dis','Cloud'),(26,10031,'Dis','Cloud'),(26,10032,'Dis','On-p'),(26,10033,'Dis','On-p'),(26,10034,'Dis','On-p'),(26,10035,'Dis','On-p'),(26,10036,'Dis','On-p'),(26,10042,'Dis','On-p'),(26,10043,'Dis','Cloud'),(26,10044,'Dis','Cloud'),(26,10045,'Dis','Cloud'),(26,10046,'Cen','On-p'),(26,10047,'Cen','On-p'),(26,10048,'Cen','On-p'),(26,10049,'Cen','On-p'),(26,10050,'Dis','On-p'),(26,10051,'Dis','On-p'),(26,10052,'Dis','Cloud'),(26,10053,'Dis','Cloud'),(26,10054,'Dis','Cloud'),(34,10001,'Dis','On-p'),(34,10002,'Dis','Cloud'),(34,10003,'Dis','Cloud'),(34,10004,'Dis','Cloud'),(34,10005,'Dis','Cloud'),(34,10006,'Dis','Cloud'),(34,10007,'Cen','On-p'),(34,10008,'Cen','On-p'),(34,10009,'Cen','On-p'),(34,10010,'Cen','On-p'),(34,10011,'Cen','On-p'),(34,10012,'Cen','Cloud'),(34,10013,'Cen','Cloud'),(34,10014,'Cen','Cloud'),(34,10015,'Cen','Cloud'),(34,10016,'Cen','Cloud'),(34,10017,'Cen','Cloud'),(34,10018,'Cen','Cloud'),(34,10019,'Cen','On-p'),(34,10020,'Cen','On-p'),(34,10023,'Dis','On-p'),(34,10025,'Dis','On-p'),(34,10026,'Dis','Cloud'),(34,10027,'Dis','Cloud'),(34,10028,'Dis','Cloud'),(34,10029,'Dis','Cloud'),(34,10030,'Dis','Cloud'),(34,10031,'Dis','Cloud'),(34,10033,'Dis','On-p'),(34,10034,'Dis','On-p'),(34,10042,'Dis','On-p'),(34,10043,'Dis','Cloud'),(34,10044,'Dis','Cloud'),(34,10045,'Dis','Cloud'),(34,10046,'Cen','On-p'),(34,10047,'Cen','On-p'),(34,10048,'Cen','On-p'),(34,10049,'Cen','On-p'),(34,10050,'Dis','On-p'),(34,10051,'Dis','On-p'),(34,10052,'Dis','Cloud'),(34,10053,'Dis','Cloud'),(34,10054,'Dis','Cloud'),(35,10001,'Dis','On-p'),(35,10002,'Dis','Cloud'),(35,10003,'Dis','Cloud'),(35,10004,'Dis','Cloud'),(35,10005,'Dis','Cloud'),(35,10006,'Dis','Cloud'),(35,10007,'Cen','On-p'),(35,10008,'Cen','On-p'),(35,10009,'Cen','On-p'),(35,10010,'Cen','On-p'),(35,10011,'Cen','On-p'),(35,10012,'Cen','Cloud'),(35,10013,'Cen','Cloud'),(35,10014,'Cen','Cloud'),(35,10015,'Cen','Cloud'),(35,10016,'Cen','Cloud'),(35,10017,'Cen','Cloud'),(35,10018,'Cen','Cloud'),(35,10020,'Cen','On-p'),(35,10023,'Dis','On-p'),(35,10024,'Dis','On-p'),(35,10025,'Dis','On-p'),(35,10026,'Dis','Cloud'),(35,10027,'Dis','Cloud'),(35,10028,'Dis','Cloud'),(35,10029,'Dis','Cloud'),(35,10030,'Dis','Cloud'),(35,10031,'Dis','Cloud'),(35,10033,'Dis','On-p'),(35,10034,'Dis','On-p'),(35,10042,'Dis','On-p'),(35,10043,'Dis','Cloud'),(35,10044,'Dis','Cloud'),(35,10045,'Dis','Cloud'),(35,10046,'Cen','On-p'),(35,10047,'Cen','On-p'),(35,10048,'Cen','On-p'),(35,10049,'Cen','On-p'),(35,10050,'Dis','On-p'),(35,10051,'Dis','On-p'),(35,10052,'Dis','Cloud'),(35,10053,'Dis','Cloud'),(35,10054,'Dis','Cloud'),(36,10007,'Cen','On-p'),(36,10008,'Cen','On-p'),(36,10009,'Cen','On-p'),(36,10010,'Cen','On-p'),(36,10011,'Cen','On-p'),(36,10012,'Cen','Cloud'),(36,10013,'Cen','Cloud'),(36,10014,'Cen','Cloud'),(36,10015,'Cen','Cloud'),(36,10016,'Cen','Cloud'),(36,10017,'Cen','Cloud'),(36,10018,'Cen','Cloud'),(36,10023,'Dis','On-p'),(36,10024,'Dis','On-p'),(36,10025,'Dis','On-p'),(36,10026,'Dis','Cloud'),(36,10027,'Dis','Cloud'),(36,10028,'Dis','Cloud'),(36,10029,'Dis','Cloud'),(36,10030,'Dis','Cloud'),(36,10031,'Dis','Cloud'),(36,10032,'Dis','On-p'),(36,10042,'Dis','On-p'),(36,10043,'Dis','Cloud'),(36,10044,'Dis','Cloud'),(36,10045,'Dis','Cloud'),(36,10046,'Cen','On-p'),(36,10047,'Cen','On-p'),(36,10048,'Cen','On-p'),(36,10049,'Cen','On-p'),(36,10050,'Dis','On-p'),(36,10051,'Dis','On-p'),(36,10052,'Dis','Cloud'),(36,10053,'Dis','Cloud'),(36,10054,'Dis','Cloud'),(37,10007,'Cen','On-p'),(37,10008,'Cen','On-p'),(37,10009,'Cen','On-p'),(37,10010,'Cen','On-p'),(37,10011,'Cen','On-p'),(37,10012,'Cen','Cloud'),(37,10013,'Cen','Cloud'),(37,10014,'Cen','Cloud'),(37,10015,'Cen','Cloud'),(37,10016,'Cen','Cloud'),(37,10017,'Cen','Cloud'),(37,10018,'Cen','Cloud'),(37,10023,'Dis','On-p'),(37,10025,'Dis','On-p'),(37,10026,'Dis','Cloud'),(37,10027,'Dis','Cloud'),(37,10028,'Dis','Cloud'),(37,10029,'Dis','Cloud'),(37,10030,'Dis','Cloud'),(37,10031,'Dis','Cloud'),(37,10032,'Dis','On-p'),(37,10042,'Dis','On-p'),(37,10043,'Dis','Cloud'),(37,10044,'Dis','Cloud'),(37,10045,'Dis','Cloud'),(37,10046,'Cen','On-p'),(37,10047,'Cen','On-p'),(37,10048,'Cen','On-p'),(37,10049,'Cen','On-p'),(37,10050,'Dis','On-p'),(37,10051,'Dis','On-p'),(37,10052,'Dis','Cloud');
/*!40000 ALTER TABLE `input` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `output`
--

DROP TABLE IF EXISTS `output`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `output` (
  `Id_t` int NOT NULL,
  `Id_sto` int NOT NULL,
  `dplymt_archi_output` varchar(50) DEFAULT NULL,
  `dplymt_mode_sto_output` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`Id_t`,`Id_sto`),
  KEY `Id_sto` (`Id_sto`),
  CONSTRAINT `output_ibfk_1` FOREIGN KEY (`Id_t`) REFERENCES `tools` (`Id_t`),
  CONSTRAINT `output_ibfk_2` FOREIGN KEY (`Id_sto`) REFERENCES `storage` (`Id_sto`)
) ENGINE=InnoDB DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `output`
--

LOCK TABLES `output` WRITE;
/*!40000 ALTER TABLE `output` DISABLE KEYS */;
INSERT INTO `output` (`Id_t`, `Id_sto`, `dplymt_archi_output`, `dplymt_mode_sto_output`) VALUES (1,10001,'Dis','On-p'),(1,10002,'Dis','Cloud'),(1,10003,'Dis','Cloud'),(1,10004,'Dis','Cloud'),(1,10005,'Dis','Cloud'),(1,10006,'Dis','Cloud'),(1,10007,'Cen','On-p'),(1,10008,'Cen','On-p'),(1,10009,'Cen','On-p'),(1,10010,'Cen','On-p'),(1,10011,'Cen','On-p'),(1,10012,'Cen','Cloud'),(1,10013,'Cen','Cloud'),(1,10014,'Cen','Cloud'),(1,10015,'Cen','Cloud'),(1,10016,'Cen','Cloud'),(1,10017,'Cen','Cloud'),(1,10018,'Cen','Cloud'),(1,10019,'Cen','On-p'),(1,10020,'Cen','On-p'),(1,10021,'Cen','On-p'),(1,10022,'Cen','On-p'),(1,10023,'Dis','On-p'),(1,10024,'Dis','On-p'),(1,10025,'Dis','On-p'),(1,10026,'Dis','Cloud'),(1,10027,'Dis','Cloud'),(1,10028,'Dis','Cloud'),(1,10029,'Dis','Cloud'),(1,10030,'Dis','Cloud'),(1,10031,'Dis','Cloud'),(1,10032,'Dis','On-p'),(1,10033,'Dis','On-p'),(1,10034,'Dis','On-p'),(1,10035,'Dis','On-p'),(1,10036,'Dis','On-p'),(1,10037,'Dis','Cloud'),(1,10038,'Dis','Cloud'),(1,10039,'Dis','Cloud'),(1,10040,'Dis','Cloud'),(1,10041,'Dis','Cloud'),(1,10042,'Dis','On-p'),(1,10043,'Dis','Cloud'),(1,10044,'Dis','Cloud'),(1,10045,'Dis','Cloud'),(1,10046,'Cen','On-p'),(1,10047,'Cen','On-p'),(1,10048,'Cen','On-p'),(1,10049,'Cen','On-p'),(1,10050,'Dis','On-p'),(1,10051,'Dis','On-p'),(1,10052,'Dis','Cloud'),(1,10053,'Dis','Cloud'),(1,10054,'Dis','Cloud'),(2,10001,'Dis','On-p'),(2,10002,'Dis','Cloud'),(2,10003,'Dis','Cloud'),(2,10004,'Dis','Cloud'),(2,10005,'Dis','Cloud'),(2,10006,'Dis','Cloud'),(2,10032,'Dis','On-p'),(2,10033,'Dis','On-p'),(2,10034,'Dis','On-p'),(2,10036,'Dis','On-p'),(2,10042,'Dis','On-p'),(2,10043,'Dis','Cloud'),(2,10044,'Dis','Cloud'),(2,10045,'Dis','Cloud'),(2,10046,'Cen','On-p'),(2,10047,'Cen','On-p'),(2,10048,'Cen','On-p'),(2,10049,'Cen','On-p'),(2,10052,'Dis','Cloud'),(3,10001,'Dis','On-p'),(3,10002,'Dis','Cloud'),(3,10003,'Dis','Cloud'),(3,10004,'Dis','Cloud'),(3,10005,'Dis','Cloud'),(3,10006,'Dis','Cloud'),(3,10007,'Cen','On-p'),(3,10008,'Cen','On-p'),(3,10009,'Cen','On-p'),(3,10010,'Cen','On-p'),(3,10011,'Cen','On-p'),(3,10012,'Cen','Cloud'),(3,10013,'Cen','Cloud'),(3,10014,'Cen','Cloud'),(3,10015,'Cen','Cloud'),(3,10016,'Cen','Cloud'),(3,10017,'Cen','Cloud'),(3,10018,'Cen','Cloud'),(3,10019,'Cen','On-p'),(3,10020,'Cen','On-p'),(3,10021,'Cen','On-p'),(3,10022,'Cen','On-p'),(3,10023,'Dis','On-p'),(3,10024,'Dis','On-p'),(3,10025,'Dis','On-p'),(3,10026,'Dis','Cloud'),(3,10027,'Dis','Cloud'),(3,10028,'Dis','Cloud'),(3,10029,'Dis','Cloud'),(3,10030,'Dis','Cloud'),(3,10031,'Dis','Cloud'),(3,10032,'Dis','On-p'),(3,10033,'Dis','On-p'),(3,10034,'Dis','On-p'),(3,10035,'Dis','On-p'),(3,10036,'Dis','On-p'),(3,10037,'Dis','Cloud'),(3,10038,'Dis','Cloud'),(3,10039,'Dis','Cloud'),(3,10040,'Dis','Cloud'),(3,10041,'Dis','Cloud'),(3,10042,'Dis','On-p'),(3,10043,'Dis','Cloud'),(3,10044,'Dis','Cloud'),(3,10045,'Dis','Cloud'),(3,10046,'Cen','On-p'),(3,10047,'Cen','On-p'),(3,10048,'Cen','On-p'),(3,10049,'Cen','On-p'),(3,10050,'Dis','On-p'),(3,10051,'Dis','On-p'),(3,10052,'Dis','Cloud'),(3,10053,'Dis','Cloud'),(3,10054,'Dis','Cloud'),(4,10001,'Dis','On-p'),(4,10002,'Dis','Cloud'),(4,10003,'Dis','Cloud'),(4,10004,'Dis','Cloud'),(4,10005,'Dis','Cloud'),(4,10006,'Dis','Cloud'),(4,10007,'Cen','On-p'),(4,10008,'Cen','On-p'),(4,10009,'Cen','On-p'),(4,10010,'Cen','On-p'),(4,10011,'Cen','On-p'),(4,10012,'Cen','Cloud'),(4,10013,'Cen','Cloud'),(4,10014,'Cen','Cloud'),(4,10015,'Cen','Cloud'),(4,10016,'Cen','Cloud'),(4,10017,'Cen','Cloud'),(4,10018,'Cen','Cloud'),(4,10020,'Cen','On-p'),(4,10023,'Dis','On-p'),(4,10024,'Dis','On-p'),(4,10025,'Dis','On-p'),(4,10026,'Dis','Cloud'),(4,10027,'Dis','Cloud'),(4,10028,'Dis','Cloud'),(4,10029,'Dis','Cloud'),(4,10030,'Dis','Cloud'),(4,10031,'Dis','Cloud'),(4,10032,'Dis','On-p'),(4,10033,'Dis','On-p'),(4,10034,'Dis','On-p'),(4,10042,'Dis','On-p'),(4,10043,'Dis','Cloud'),(4,10044,'Dis','Cloud'),(4,10045,'Dis','Cloud'),(4,10046,'Cen','On-p'),(4,10047,'Cen','On-p'),(4,10048,'Cen','On-p'),(4,10049,'Cen','On-p'),(4,10050,'Dis','On-p'),(4,10052,'Dis','Cloud'),(4,10053,'Dis','Cloud'),(4,10054,'Dis','Cloud'),(5,10001,'Dis','On-p'),(5,10002,'Dis','Cloud'),(5,10003,'Dis','Cloud'),(5,10004,'Dis','Cloud'),(5,10005,'Dis','Cloud'),(5,10006,'Dis','Cloud'),(5,10007,'Cen','On-p'),(5,10008,'Cen','On-p'),(5,10009,'Cen','On-p'),(5,10010,'Cen','On-p'),(5,10011,'Cen','On-p'),(5,10012,'Cen','Cloud'),(5,10013,'Cen','Cloud'),(5,10014,'Cen','Cloud'),(5,10015,'Cen','Cloud'),(5,10016,'Cen','Cloud'),(5,10017,'Cen','Cloud'),(5,10018,'Cen','Cloud'),(5,10019,'Cen','On-p'),(5,10020,'Cen','On-p'),(5,10021,'Cen','On-p'),(5,10023,'Dis','On-p'),(5,10024,'Dis','On-p'),(5,10025,'Dis','On-p'),(5,10026,'Dis','Cloud'),(5,10027,'Dis','Cloud'),(5,10028,'Dis','Cloud'),(5,10029,'Dis','Cloud'),(5,10030,'Dis','Cloud'),(5,10031,'Dis','Cloud'),(5,10034,'Dis','On-p'),(5,10036,'Dis','On-p'),(5,10042,'Dis','On-p'),(5,10043,'Dis','Cloud'),(5,10044,'Dis','Cloud'),(5,10045,'Dis','Cloud'),(5,10046,'Cen','On-p'),(5,10047,'Cen','On-p'),(5,10048,'Cen','On-p'),(5,10049,'Cen','On-p'),(5,10050,'Dis','On-p'),(5,10051,'Dis','On-p'),(5,10052,'Dis','Cloud'),(5,10053,'Dis','Cloud'),(5,10054,'Dis','Cloud'),(6,10001,'Dis','On-p'),(6,10002,'Dis','Cloud'),(6,10003,'Dis','Cloud'),(6,10004,'Dis','Cloud'),(6,10005,'Dis','Cloud'),(6,10006,'Dis','Cloud'),(6,10007,'Cen','On-p'),(6,10008,'Cen','On-p'),(6,10009,'Cen','On-p'),(6,10010,'Cen','On-p'),(6,10011,'Cen','On-p'),(6,10012,'Cen','Cloud'),(6,10013,'Cen','Cloud'),(6,10014,'Cen','Cloud'),(6,10015,'Cen','Cloud'),(6,10016,'Cen','Cloud'),(6,10017,'Cen','Cloud'),(6,10018,'Cen','Cloud'),(6,10019,'Cen','On-p'),(6,10020,'Cen','On-p'),(6,10021,'Cen','On-p'),(6,10023,'Dis','On-p'),(6,10024,'Dis','On-p'),(6,10025,'Dis','On-p'),(6,10026,'Dis','Cloud'),(6,10027,'Dis','Cloud'),(6,10028,'Dis','Cloud'),(6,10029,'Dis','Cloud'),(6,10030,'Dis','Cloud'),(6,10031,'Dis','Cloud'),(6,10032,'Dis','On-p'),(6,10034,'Dis','On-p'),(6,10036,'Dis','On-p'),(6,10037,'Dis','Cloud'),(6,10042,'Dis','On-p'),(6,10043,'Dis','Cloud'),(6,10044,'Dis','Cloud'),(6,10045,'Dis','Cloud'),(6,10046,'Cen','On-p'),(6,10047,'Cen','On-p'),(6,10048,'Cen','On-p'),(6,10049,'Cen','On-p'),(6,10050,'Dis','On-p'),(6,10051,'Dis','On-p'),(6,10052,'Dis','Cloud'),(6,10053,'Dis','Cloud'),(6,10054,'Dis','Cloud'),(7,10001,'Dis','On-p'),(7,10002,'Dis','Cloud'),(7,10003,'Dis','Cloud'),(7,10004,'Dis','Cloud'),(7,10005,'Dis','Cloud'),(7,10006,'Dis','Cloud'),(7,10019,'Cen','On-p'),(7,10043,'Dis','Cloud'),(7,10044,'Dis','Cloud'),(7,10045,'Dis','Cloud'),(7,10046,'Cen','On-p'),(7,10047,'Cen','On-p'),(7,10048,'Cen','On-p'),(7,10049,'Cen','On-p'),(8,10001,'Dis','On-p'),(8,10002,'Dis','Cloud'),(8,10003,'Dis','Cloud'),(8,10004,'Dis','Cloud'),(8,10005,'Dis','Cloud'),(8,10006,'Dis','Cloud'),(8,10007,'Cen','On-p'),(8,10008,'Cen','On-p'),(8,10009,'Cen','On-p'),(8,10010,'Cen','On-p'),(8,10011,'Cen','On-p'),(8,10012,'Cen','Cloud'),(8,10013,'Cen','Cloud'),(8,10014,'Cen','Cloud'),(8,10015,'Cen','Cloud'),(8,10016,'Cen','Cloud'),(8,10017,'Cen','Cloud'),(8,10018,'Cen','Cloud'),(8,10021,'Cen','On-p'),(8,10023,'Dis','On-p'),(8,10025,'Dis','On-p'),(8,10026,'Dis','Cloud'),(8,10027,'Dis','Cloud'),(8,10028,'Dis','Cloud'),(8,10029,'Dis','Cloud'),(8,10030,'Dis','Cloud'),(8,10031,'Dis','Cloud'),(8,10033,'Dis','On-p'),(8,10034,'Dis','On-p'),(8,10036,'Dis','On-p'),(8,10037,'Dis','Cloud'),(8,10038,'Dis','Cloud'),(8,10039,'Dis','Cloud'),(8,10040,'Dis','Cloud'),(8,10041,'Dis','Cloud'),(8,10043,'Dis','Cloud'),(8,10044,'Dis','Cloud'),(8,10045,'Dis','Cloud'),(8,10046,'Cen','On-p'),(8,10047,'Cen','On-p'),(8,10048,'Cen','On-p'),(8,10049,'Cen','On-p'),(12,10001,'Dis','On-p'),(12,10002,'Dis','Cloud'),(12,10003,'Dis','Cloud'),(12,10004,'Dis','Cloud'),(12,10005,'Dis','Cloud'),(12,10006,'Dis','Cloud'),(12,10007,'Cen','On-p'),(12,10008,'Cen','On-p'),(12,10009,'Cen','On-p'),(12,10010,'Cen','On-p'),(12,10011,'Cen','On-p'),(12,10012,'Cen','Cloud'),(12,10013,'Cen','Cloud'),(12,10014,'Cen','Cloud'),(12,10015,'Cen','Cloud'),(12,10016,'Cen','Cloud'),(12,10017,'Cen','Cloud'),(12,10018,'Cen','Cloud'),(12,10019,'Cen','On-p'),(12,10020,'Cen','On-p'),(12,10021,'Cen','On-p'),(12,10022,'Cen','On-p'),(12,10023,'Dis','On-p'),(12,10024,'Dis','On-p'),(12,10025,'Dis','On-p'),(12,10026,'Dis','Cloud'),(12,10027,'Dis','Cloud'),(12,10028,'Dis','Cloud'),(12,10029,'Dis','Cloud'),(12,10030,'Dis','Cloud'),(12,10031,'Dis','Cloud'),(12,10032,'Dis','On-p'),(12,10033,'Dis','On-p'),(12,10034,'Dis','On-p'),(12,10035,'Dis','On-p'),(12,10036,'Dis','On-p'),(12,10037,'Dis','Cloud'),(12,10038,'Dis','Cloud'),(12,10039,'Dis','Cloud'),(12,10040,'Dis','Cloud'),(12,10041,'Dis','Cloud'),(12,10042,'Dis','On-p'),(12,10043,'Dis','Cloud'),(12,10044,'Dis','Cloud'),(12,10045,'Dis','Cloud'),(12,10046,'Cen','On-p'),(12,10047,'Cen','On-p'),(12,10048,'Cen','On-p'),(12,10049,'Cen','On-p'),(12,10050,'Dis','On-p'),(12,10051,'Dis','On-p'),(12,10052,'Dis','Cloud'),(12,10053,'Dis','Cloud'),(12,10054,'Dis','Cloud'),(13,10001,'Dis','On-p'),(13,10002,'Dis','Cloud'),(13,10003,'Dis','Cloud'),(13,10004,'Dis','Cloud'),(13,10005,'Dis','Cloud'),(13,10006,'Dis','Cloud'),(13,10007,'Cen','On-p'),(13,10008,'Cen','On-p'),(13,10009,'Cen','On-p'),(13,10010,'Cen','On-p'),(13,10011,'Cen','On-p'),(13,10012,'Cen','Cloud'),(13,10013,'Cen','Cloud'),(13,10014,'Cen','Cloud'),(13,10015,'Cen','Cloud'),(13,10016,'Cen','Cloud'),(13,10017,'Cen','Cloud'),(13,10018,'Cen','Cloud'),(13,10019,'Cen','On-p'),(13,10020,'Cen','On-p'),(13,10021,'Cen','On-p'),(13,10022,'Cen','On-p'),(13,10023,'Dis','On-p'),(13,10024,'Dis','On-p'),(13,10025,'Dis','On-p'),(13,10026,'Dis','Cloud'),(13,10027,'Dis','Cloud'),(13,10028,'Dis','Cloud'),(13,10029,'Dis','Cloud'),(13,10030,'Dis','Cloud'),(13,10031,'Dis','Cloud'),(13,10032,'Dis','On-p'),(13,10033,'Dis','On-p'),(13,10034,'Dis','On-p'),(13,10035,'Dis','On-p'),(13,10036,'Dis','On-p'),(13,10037,'Dis','Cloud'),(13,10038,'Dis','Cloud'),(13,10039,'Dis','Cloud'),(13,10040,'Dis','Cloud'),(13,10041,'Dis','Cloud'),(13,10042,'Dis','On-p'),(13,10043,'Dis','Cloud'),(13,10044,'Dis','Cloud'),(13,10045,'Dis','Cloud'),(13,10046,'Cen','On-p'),(13,10047,'Cen','On-p'),(13,10048,'Cen','On-p'),(13,10049,'Cen','On-p'),(13,10050,'Dis','On-p'),(13,10051,'Dis','On-p'),(13,10052,'Dis','Cloud'),(13,10053,'Dis','Cloud'),(13,10054,'Dis','Cloud'),(14,10001,'Dis','On-p'),(14,10002,'Dis','Cloud'),(14,10003,'Dis','Cloud'),(14,10004,'Dis','Cloud'),(14,10005,'Dis','Cloud'),(14,10006,'Dis','Cloud'),(14,10007,'Cen','On-p'),(14,10008,'Cen','On-p'),(14,10009,'Cen','On-p'),(14,10010,'Cen','On-p'),(14,10011,'Cen','On-p'),(14,10012,'Cen','Cloud'),(14,10013,'Cen','Cloud'),(14,10014,'Cen','Cloud'),(14,10015,'Cen','Cloud'),(14,10016,'Cen','Cloud'),(14,10017,'Cen','Cloud'),(14,10018,'Cen','Cloud'),(14,10019,'Cen','On-p'),(14,10020,'Cen','On-p'),(14,10021,'Cen','On-p'),(14,10022,'Cen','On-p'),(14,10023,'Dis','On-p'),(14,10024,'Dis','On-p'),(14,10025,'Dis','On-p'),(14,10026,'Dis','Cloud'),(14,10027,'Dis','Cloud'),(14,10028,'Dis','Cloud'),(14,10029,'Dis','Cloud'),(14,10030,'Dis','Cloud'),(14,10031,'Dis','Cloud'),(14,10032,'Dis','On-p'),(14,10033,'Dis','On-p'),(14,10034,'Dis','On-p'),(14,10035,'Dis','On-p'),(14,10036,'Dis','On-p'),(14,10037,'Dis','Cloud'),(14,10038,'Dis','Cloud'),(14,10039,'Dis','Cloud'),(14,10040,'Dis','Cloud'),(14,10041,'Dis','Cloud'),(14,10042,'Dis','On-p'),(14,10043,'Dis','Cloud'),(14,10044,'Dis','Cloud'),(14,10045,'Dis','Cloud'),(14,10046,'Cen','On-p'),(14,10047,'Cen','On-p'),(14,10048,'Cen','On-p'),(14,10049,'Cen','On-p'),(14,10050,'Dis','On-p'),(14,10051,'Dis','On-p'),(14,10052,'Dis','Cloud'),(14,10053,'Dis','Cloud'),(14,10054,'Dis','Cloud'),(15,10001,'Dis','On-p'),(15,10002,'Dis','Cloud'),(15,10003,'Dis','Cloud'),(15,10004,'Dis','Cloud'),(15,10005,'Dis','Cloud'),(15,10006,'Dis','Cloud'),(15,10007,'Cen','On-p'),(15,10008,'Cen','On-p'),(15,10009,'Cen','On-p'),(15,10010,'Cen','On-p'),(15,10011,'Cen','On-p'),(15,10012,'Cen','Cloud'),(15,10013,'Cen','Cloud'),(15,10014,'Cen','Cloud'),(15,10015,'Cen','Cloud'),(15,10016,'Cen','Cloud'),(15,10017,'Cen','Cloud'),(15,10018,'Cen','Cloud'),(15,10019,'Cen','On-p'),(15,10020,'Cen','On-p'),(15,10021,'Cen','On-p'),(15,10022,'Cen','On-p'),(15,10023,'Dis','On-p'),(15,10024,'Dis','On-p'),(15,10025,'Dis','On-p'),(15,10026,'Dis','Cloud'),(15,10027,'Dis','Cloud'),(15,10028,'Dis','Cloud'),(15,10029,'Dis','Cloud'),(15,10030,'Dis','Cloud'),(15,10031,'Dis','Cloud'),(15,10032,'Dis','On-p'),(15,10033,'Dis','On-p'),(15,10034,'Dis','On-p'),(15,10035,'Dis','On-p'),(15,10036,'Dis','On-p'),(15,10037,'Dis','Cloud'),(15,10038,'Dis','Cloud'),(15,10039,'Dis','Cloud'),(15,10040,'Dis','Cloud'),(15,10041,'Dis','Cloud'),(15,10042,'Dis','On-p'),(15,10043,'Dis','Cloud'),(15,10044,'Dis','Cloud'),(15,10045,'Dis','Cloud'),(15,10046,'Cen','On-p'),(15,10047,'Cen','On-p'),(15,10048,'Cen','On-p'),(15,10049,'Cen','On-p'),(15,10050,'Dis','On-p'),(15,10051,'Dis','On-p'),(15,10052,'Dis','Cloud'),(15,10053,'Dis','Cloud'),(15,10054,'Dis','Cloud'),(24,10001,'Dis','On-p'),(24,10002,'Dis','Cloud'),(24,10003,'Dis','Cloud'),(24,10004,'Dis','Cloud'),(24,10005,'Dis','Cloud'),(24,10006,'Dis','Cloud'),(24,10007,'Cen','On-p'),(24,10008,'Cen','On-p'),(24,10009,'Cen','On-p'),(24,10010,'Cen','On-p'),(24,10011,'Cen','On-p'),(24,10012,'Cen','Cloud'),(24,10013,'Cen','Cloud'),(24,10014,'Cen','Cloud'),(24,10015,'Cen','Cloud'),(24,10016,'Cen','Cloud'),(24,10017,'Cen','Cloud'),(24,10018,'Cen','Cloud'),(24,10019,'Cen','On-p'),(24,10020,'Cen','On-p'),(24,10021,'Cen','On-p'),(24,10022,'Cen','On-p'),(24,10023,'Dis','On-p'),(24,10024,'Dis','On-p'),(24,10025,'Dis','On-p'),(24,10026,'Dis','Cloud'),(24,10027,'Dis','Cloud'),(24,10028,'Dis','Cloud'),(24,10029,'Dis','Cloud'),(24,10030,'Dis','Cloud'),(24,10031,'Dis','Cloud'),(24,10032,'Dis','On-p'),(24,10033,'Dis','On-p'),(24,10034,'Dis','On-p'),(24,10035,'Dis','On-p'),(24,10036,'Dis','On-p'),(24,10037,'Dis','Cloud'),(24,10038,'Dis','Cloud'),(24,10039,'Dis','Cloud'),(24,10040,'Dis','Cloud'),(24,10041,'Dis','Cloud'),(24,10042,'Dis','On-p'),(24,10043,'Dis','Cloud'),(24,10044,'Dis','Cloud'),(24,10045,'Dis','Cloud'),(24,10046,'Cen','On-p'),(24,10047,'Cen','On-p'),(24,10048,'Cen','On-p'),(24,10049,'Cen','On-p'),(24,10050,'Dis','On-p'),(24,10051,'Dis','On-p'),(24,10052,'Dis','Cloud'),(24,10053,'Dis','Cloud'),(24,10054,'Dis','Cloud'),(25,10001,'Dis','On-p'),(25,10002,'Dis','Cloud'),(25,10003,'Dis','Cloud'),(25,10004,'Dis','Cloud'),(25,10005,'Dis','Cloud'),(25,10006,'Dis','Cloud'),(25,10007,'Cen','On-p'),(25,10008,'Cen','On-p'),(25,10009,'Cen','On-p'),(25,10010,'Cen','On-p'),(25,10011,'Cen','On-p'),(25,10012,'Cen','Cloud'),(25,10013,'Cen','Cloud'),(25,10014,'Cen','Cloud'),(25,10015,'Cen','Cloud'),(25,10016,'Cen','Cloud'),(25,10017,'Cen','Cloud'),(25,10018,'Cen','Cloud'),(25,10019,'Cen','On-p'),(25,10020,'Cen','On-p'),(25,10021,'Cen','On-p'),(25,10022,'Cen','On-p'),(25,10023,'Dis','On-p'),(25,10024,'Dis','On-p'),(25,10025,'Dis','On-p'),(25,10026,'Dis','Cloud'),(25,10027,'Dis','Cloud'),(25,10028,'Dis','Cloud'),(25,10029,'Dis','Cloud'),(25,10030,'Dis','Cloud'),(25,10031,'Dis','Cloud'),(25,10032,'Dis','On-p'),(25,10033,'Dis','On-p'),(25,10034,'Dis','On-p'),(25,10035,'Dis','On-p'),(25,10036,'Dis','On-p'),(25,10037,'Dis','Cloud'),(25,10041,'Dis','Cloud'),(25,10042,'Dis','On-p'),(25,10043,'Dis','Cloud'),(25,10044,'Dis','Cloud'),(25,10045,'Dis','Cloud'),(25,10046,'Cen','On-p'),(25,10047,'Cen','On-p'),(25,10048,'Cen','On-p'),(25,10049,'Cen','On-p'),(25,10050,'Dis','On-p'),(25,10051,'Dis','On-p'),(25,10052,'Dis','Cloud'),(25,10053,'Dis','Cloud'),(25,10054,'Dis','Cloud'),(26,10001,'Dis','On-p'),(26,10002,'Dis','Cloud'),(26,10003,'Dis','Cloud'),(26,10004,'Dis','Cloud'),(26,10005,'Dis','Cloud'),(26,10006,'Dis','Cloud'),(26,10007,'Cen','On-p'),(26,10008,'Cen','On-p'),(26,10009,'Cen','On-p'),(26,10010,'Cen','On-p'),(26,10011,'Cen','On-p'),(26,10012,'Cen','Cloud'),(26,10013,'Cen','Cloud'),(26,10014,'Cen','Cloud'),(26,10015,'Cen','Cloud'),(26,10016,'Cen','Cloud'),(26,10017,'Cen','Cloud'),(26,10018,'Cen','Cloud'),(26,10019,'Cen','On-p'),(26,10020,'Cen','On-p'),(26,10021,'Cen','On-p'),(26,10022,'Cen','On-p'),(26,10023,'Dis','On-p'),(26,10024,'Dis','On-p'),(26,10025,'Dis','On-p'),(26,10026,'Dis','Cloud'),(26,10027,'Dis','Cloud'),(26,10028,'Dis','Cloud'),(26,10029,'Dis','Cloud'),(26,10030,'Dis','Cloud'),(26,10031,'Dis','Cloud'),(26,10032,'Dis','On-p'),(26,10033,'Dis','On-p'),(26,10034,'Dis','On-p'),(26,10035,'Dis','On-p'),(26,10036,'Dis','On-p'),(26,10042,'Dis','On-p'),(26,10043,'Dis','Cloud'),(26,10044,'Dis','Cloud'),(26,10045,'Dis','Cloud'),(26,10046,'Cen','On-p'),(26,10047,'Cen','On-p'),(26,10048,'Cen','On-p'),(26,10049,'Cen','On-p'),(26,10050,'Dis','On-p'),(26,10051,'Dis','On-p'),(26,10052,'Dis','Cloud'),(26,10053,'Dis','Cloud'),(26,10054,'Dis','Cloud'),(27,10001,'Dis','On-p'),(27,10002,'Dis','Cloud'),(27,10003,'Dis','Cloud'),(27,10004,'Dis','Cloud'),(27,10005,'Dis','Cloud'),(27,10006,'Dis','Cloud'),(27,10007,'Cen','On-p'),(27,10008,'Cen','On-p'),(27,10009,'Cen','On-p'),(27,10010,'Cen','On-p'),(27,10011,'Cen','On-p'),(27,10012,'Cen','Cloud'),(27,10013,'Cen','Cloud'),(27,10014,'Cen','Cloud'),(27,10015,'Cen','Cloud'),(27,10016,'Cen','Cloud'),(27,10017,'Cen','Cloud'),(27,10018,'Cen','Cloud'),(27,10019,'Cen','On-p'),(27,10020,'Cen','On-p'),(27,10021,'Cen','On-p'),(27,10023,'Dis','On-p'),(27,10024,'Dis','On-p'),(27,10025,'Dis','On-p'),(27,10026,'Dis','Cloud'),(27,10027,'Dis','Cloud'),(27,10028,'Dis','Cloud'),(27,10029,'Dis','Cloud'),(27,10030,'Dis','Cloud'),(27,10031,'Dis','Cloud'),(27,10032,'Dis','On-p'),(27,10033,'Dis','On-p'),(27,10034,'Dis','On-p'),(27,10036,'Dis','On-p'),(27,10037,'Dis','Cloud'),(27,10038,'Dis','Cloud'),(27,10039,'Dis','Cloud'),(27,10040,'Dis','Cloud'),(27,10041,'Dis','Cloud'),(27,10042,'Dis','On-p'),(27,10043,'Dis','Cloud'),(27,10044,'Dis','Cloud'),(27,10045,'Dis','Cloud'),(27,10046,'Cen','On-p'),(27,10047,'Cen','On-p'),(27,10048,'Cen','On-p'),(27,10049,'Cen','On-p'),(27,10050,'Dis','On-p'),(27,10051,'Dis','On-p'),(27,10052,'Dis','Cloud'),(27,10053,'Dis','Cloud'),(27,10054,'Dis','Cloud'),(28,10001,'Dis','On-p'),(28,10002,'Dis','Cloud'),(28,10003,'Dis','Cloud'),(28,10004,'Dis','Cloud'),(28,10005,'Dis','Cloud'),(28,10006,'Dis','Cloud'),(28,10042,'Dis','On-p'),(28,10043,'Dis','Cloud'),(28,10044,'Dis','Cloud'),(28,10045,'Dis','Cloud'),(34,10007,'Cen','On-p'),(34,10008,'Cen','On-p'),(34,10009,'Cen','On-p'),(34,10010,'Cen','On-p'),(34,10011,'Cen','On-p'),(34,10012,'Cen','Cloud'),(34,10013,'Cen','Cloud'),(34,10014,'Cen','Cloud'),(34,10015,'Cen','Cloud'),(34,10016,'Cen','Cloud'),(34,10017,'Cen','Cloud'),(34,10018,'Cen','Cloud'),(34,10023,'Dis','On-p'),(34,10024,'Dis','On-p'),(34,10025,'Dis','On-p'),(34,10026,'Dis','Cloud'),(34,10027,'Dis','Cloud'),(34,10028,'Dis','Cloud'),(34,10029,'Dis','Cloud'),(34,10030,'Dis','Cloud'),(34,10031,'Dis','Cloud'),(34,10033,'Dis','On-p'),(34,10046,'Cen','On-p'),(34,10047,'Cen','On-p'),(34,10048,'Cen','On-p'),(34,10049,'Cen','On-p'),(35,10007,'Cen','On-p'),(35,10008,'Cen','On-p'),(35,10009,'Cen','On-p'),(35,10010,'Cen','On-p'),(35,10011,'Cen','On-p'),(35,10012,'Cen','Cloud'),(35,10013,'Cen','Cloud'),(35,10014,'Cen','Cloud'),(35,10015,'Cen','Cloud'),(35,10016,'Cen','Cloud'),(35,10017,'Cen','Cloud'),(35,10018,'Cen','Cloud'),(35,10023,'Dis','On-p'),(35,10024,'Dis','On-p'),(35,10025,'Dis','On-p'),(35,10026,'Dis','Cloud'),(35,10027,'Dis','Cloud'),(35,10028,'Dis','Cloud'),(35,10029,'Dis','Cloud'),(35,10030,'Dis','Cloud'),(35,10031,'Dis','Cloud'),(35,10033,'Dis','On-p'),(35,10042,'Dis','On-p'),(35,10043,'Dis','Cloud'),(35,10044,'Dis','Cloud'),(35,10045,'Dis','Cloud'),(35,10046,'Cen','On-p'),(35,10047,'Cen','On-p'),(35,10048,'Cen','On-p'),(35,10049,'Cen','On-p'),(35,10050,'Dis','On-p'),(35,10051,'Dis','On-p'),(35,10052,'Dis','Cloud'),(35,10053,'Dis','Cloud'),(35,10054,'Dis','Cloud'),(36,10007,'Cen','On-p'),(36,10008,'Cen','On-p'),(36,10009,'Cen','On-p'),(36,10010,'Cen','On-p'),(36,10011,'Cen','On-p'),(36,10012,'Cen','Cloud'),(36,10013,'Cen','Cloud'),(36,10014,'Cen','Cloud'),(36,10015,'Cen','Cloud'),(36,10016,'Cen','Cloud'),(36,10017,'Cen','Cloud'),(36,10018,'Cen','Cloud'),(36,10023,'Dis','On-p'),(36,10024,'Dis','On-p'),(36,10025,'Dis','On-p'),(36,10026,'Dis','Cloud'),(36,10027,'Dis','Cloud'),(36,10028,'Dis','Cloud'),(36,10029,'Dis','Cloud'),(36,10030,'Dis','Cloud'),(36,10031,'Dis','Cloud'),(36,10032,'Dis','On-p'),(36,10042,'Dis','On-p'),(36,10043,'Dis','Cloud'),(36,10044,'Dis','Cloud'),(36,10045,'Dis','Cloud'),(36,10046,'Cen','On-p'),(36,10047,'Cen','On-p'),(36,10048,'Cen','On-p'),(36,10049,'Cen','On-p'),(36,10050,'Dis','On-p'),(36,10051,'Dis','On-p'),(36,10052,'Dis','Cloud'),(36,10053,'Dis','Cloud'),(36,10054,'Dis','Cloud'),(37,10007,'Cen','On-p'),(37,10008,'Cen','On-p'),(37,10009,'Cen','On-p'),(37,10010,'Cen','On-p'),(37,10011,'Cen','On-p'),(37,10012,'Cen','Cloud'),(37,10013,'Cen','Cloud'),(37,10014,'Cen','Cloud'),(37,10015,'Cen','Cloud'),(37,10016,'Cen','Cloud'),(37,10017,'Cen','Cloud'),(37,10018,'Cen','Cloud'),(37,10023,'Dis','On-p'),(37,10024,'Dis','On-p'),(37,10025,'Dis','On-p'),(37,10026,'Dis','Cloud'),(37,10027,'Dis','Cloud'),(37,10028,'Dis','Cloud'),(37,10029,'Dis','Cloud'),(37,10030,'Dis','Cloud'),(37,10031,'Dis','Cloud'),(37,10032,'Dis','On-p'),(37,10042,'Dis','On-p'),(37,10043,'Dis','Cloud'),(37,10044,'Dis','Cloud'),(37,10045,'Dis','Cloud'),(37,10046,'Cen','On-p'),(37,10047,'Cen','On-p'),(37,10048,'Cen','On-p'),(37,10049,'Cen','On-p'),(37,10050,'Dis','On-p'),(37,10051,'Dis','On-p'),(37,10052,'Dis','Cloud');
/*!40000 ALTER TABLE `output` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `questions_table`
--

DROP TABLE IF EXISTS `questions_table`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `questions_table` (
  `id` int NOT NULL AUTO_INCREMENT,
  `content` text NOT NULL,
  `type` enum('single_choice','multiple_choice','select') NOT NULL,
  `choices` json DEFAULT NULL,
  `is_required` tinyint(1) NOT NULL DEFAULT '1',
  `category` varchar(255) DEFAULT NULL,
  `help_text` text,
  `created_at` timestamp NULL DEFAULT CURRENT_TIMESTAMP,
  `updated_at` timestamp NULL DEFAULT CURRENT_TIMESTAMP ON UPDATE CURRENT_TIMESTAMP,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB AUTO_INCREMENT=48 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `questions_table`
--

LOCK TABLES `questions_table` WRITE;
/*!40000 ALTER TABLE `questions_table` DISABLE KEYS */;
INSERT INTO `questions_table` (`id`, `content`, `type`, `choices`, `is_required`, `category`, `help_text`, `created_at`, `updated_at`) VALUES (1,'Where do you want to deploy your data lake ?','single_choice','{\"c1\": \"On-premises\", \"c2\": \"On cloud\"}',1,'Architecture',NULL,'2024-08-22 14:13:00','2024-11-20 10:17:10'),(2,'Are you familiar with or have you used any of the following ecosystems or tools ? (Select all that apply)','multiple_choice','{\"c1\": \"Hadoop ecosystem (e.g. HDFS, Hive, HBase)\", \"c2\": \"Spark ecosystem\", \"c3\": \"ELK\", \"c4\": \"Not familiar with any of the above ecosystems\"}',0,'Architecture','If you are familiar with some tools, please tell us so that we can optimize our results.','2024-08-22 14:17:45','2024-08-22 14:17:45'),(3,'Do you want to build your data lake using an ecosystem you are familiar with?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No,I want try something new.\"}',1,'Architecture','If you select yes, it will increase the chances of the tools you are familiar with appearing.','2024-08-22 14:20:51','2024-08-22 14:20:51'),(4,'Do you want to use paid software?','single_choice','{\"c1\": \"No\", \"c2\": \"yes\"}',1,'Ingestion','This option only affects whether paid software appears in the rankings.','2024-08-22 14:24:44','2024-11-21 07:45:34'),(5,'How do you expect to ingest data?','single_choice','{\"c1\": \"Streaming\", \"c2\": \"Batch\", \"c3\": \"Hybrid\"}',1,'Ingestion',NULL,'2024-08-22 14:26:03','2024-08-22 14:47:24'),(6,'From which source do you plan to ingest data? (Select all that apply)','select','{\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}',1,'Source',NULL,'2024-08-22 14:47:24','2024-08-28 12:01:17'),(7,'What data lake storage unit do you want?','select','{\"Database\": {\"Centralized_db\": {\"Nosql\": [\"Redis\", \"MongoDB\", \"InfluxDB\", \"Neo4j\"], \"Relational\": [\"MySQL\", \"PostgreSQL\", \"MariaDB\", \"Oracle Database\", \"Microsoft SQL Server\"]}, \"Distributed_db\": {\"Nosql\": [\"Apache HBase\", \"Cassandra\", \"MongoDB\", \"Neo4j\", \"InfluxDB\"], \"Relational\": [\"PostgreSQL with Citus\", \"VoltDB\", \"MySQL Cluster (NDB Cluster)\"]}}, \"Filesystem\": {\"Centralized_fs\": [\"NAS\", \"SAN\", \"NTFS\", \"EXT4\"], \"Distributed_fs\": [\"HDFS\"]}}',1,'Target',NULL,'2024-08-22 14:59:11','2024-08-28 12:01:17'),(8,'Does the data need to be pre-processed when ingested?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Ingestion',NULL,'2024-08-22 15:00:19','2024-08-22 15:00:19'),(9,'Do you have other data sources and data stores to choose from?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',1,'Ingestion','You can cycle through the selections until all data sources and target sources are selected.','2024-08-22 15:01:38','2024-08-22 15:01:38'),(10,'Please select the data sources you want to process together or individually','multiple_choice','{}',1,'Preparation',NULL,'2024-08-22 15:09:41','2024-08-22 15:09:41'),(11,'Do you consider expanding to stream processing tasks in the future?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Preparation',NULL,'2024-08-22 15:42:30','2024-08-22 15:42:30'),(12,'From which data sources do you want to analyze data?','multiple_choice','{}',1,'Analysis',NULL,'2024-08-22 15:42:30','2024-08-22 15:42:30'),(13,'Do you want to use SQL-like analysis tools?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Analysis',NULL,'2024-08-22 15:42:30','2024-08-22 15:42:30'),(14,'Do you have requirements for the speed of data analysis?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Analysis',NULL,'2024-08-22 15:42:30','2024-08-22 15:42:30'),(15,'What type of data analysis do you want to perform?','single_choice','{\"c1\": \"OLAP\", \"c2\": \"Visualization\", \"c3\": \"ML/DL\"}',0,'Analysis',NULL,'2024-08-22 15:42:30','2024-08-22 15:42:30'),(16,'Do you want to perform offline analysis or real-time analysis?','single_choice','{\"c1\": \"Offline analysis\", \"c2\": \"Real-time analysis\"}',1,'Architecture',NULL,'2024-08-22 15:45:05','2024-09-19 13:40:57'),(18,'Do you want to integrate data sources at ingestion time?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Ingestion',NULL,'2024-08-22 15:45:05','2024-08-22 15:45:05'),(19,'Which data source needs to be integrated?','multiple_choice','{}',1,'Ingestion',NULL,'2024-08-22 15:47:59','2024-09-19 13:41:14'),(20,'Do you need real-time processing?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Preparation',NULL,'2024-08-22 15:47:59','2024-08-29 17:51:28'),(21,'Is low latency your primary concern?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Preparation',NULL,'2024-08-22 15:47:59','2024-08-22 15:47:59'),(22,'Will you be doing complex data analysis work in the future? (ML/DL)','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Preparation',NULL,'2024-08-22 15:47:59','2024-08-22 15:47:59'),(23,'Is the delivery guarantee important to you?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Preparation',NULL,'2024-08-22 15:47:59','2024-08-22 15:47:59'),(24,'Are stream processing tasks dominant in the future?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Preparation',NULL,'2024-08-22 16:33:41','2024-09-19 13:41:30'),(25,'Do you have any preference for cloud service providers?','single_choice','{\"c1\": \"top 4 (AWS,Azure,Alibaba,Google Cloud)\", \"c2\": \"Others\"}',0,'Architecture',NULL,'2024-08-22 16:33:41','2024-08-22 16:33:41'),(26,'What types of data do you want to ingest via batch processing?','select','{\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}',1,'Ingestion',NULL,'2024-08-22 16:36:24','2024-09-23 09:13:51'),(27,'What types of data do you want to ingest via streaming processing? ','select','{\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}',1,'Ingestion',NULL,'2024-08-22 16:36:24','2024-09-23 09:13:51'),(28,'Do you need complex data processing','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Preparation',NULL,'2024-08-22 16:36:24','2024-08-22 16:36:24'),(29,'Do you need event-driven data processing services?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',0,'Preparation',NULL,'2024-08-22 16:36:24','2024-08-22 16:36:24'),(30,'Please select the cloud service provider you would like to use?','single_choice','{\"c1\": \"AWS Services\", \"c2\": \"Microsoft Azure Services\", \"c3\": \"Google Cloud Services\"}',1,'Architecture',NULL,'2024-08-26 13:19:38','2024-11-20 13:13:22'),(31,'Since the current data ingestion tools provide data processing capabilities, is an additional data processing engine needed?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',1,'Ingestion',NULL,'2024-08-26 13:33:39','2024-08-26 13:33:39'),(32,'What data sources do you want for batch ingested data?','single_choice','{\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}',1,'Ingestion',NULL,'2024-09-08 14:24:04','2024-09-08 14:24:04'),(33,'What data sources do you want for streaming ingested data?','single_choice','{\"c1\": \"Http API\", \"c2\": {\"Database\": [\"Relational Database\", \"NoSQL Database\"]}, \"c3\": \"DataSet(Demi-structured)\", \"c4\": \"Files(Unstructured)\", \"c5\": \"Logs\", \"c6\": \"IoT\", \"c7\": \"ALL types\"}',1,'Ingestion',NULL,'2024-09-08 14:24:04','2024-09-08 14:24:04'),(34,'Which cloud storage service do you want to store your data in?','single_choice','{\"c1\": \"Relational Database\", \"c2\": \"NoSQL Database\", \"c3\": \"Document Storage\", \"c4\": \"Object Store\"}',1,'Ingestion',NULL,'2024-09-10 20:24:08','2024-09-10 20:47:59'),(35,'Do you need to stream and process data in real time in your data lake?','single_choice','{\"c1\": \"Yes\", \"c2\": \"No\"}',1,'Preparation',NULL,'2024-09-23 12:26:54','2024-09-23 12:26:54'),(36,'Where does your data lake data come from?','single_choice','{\"c1\": \"Database snapshots or static files (CSV/JSON/Parquet, etc.) - Batch\", \"c2\": \"Real-time event streams (sensor data, logs, etc.) - Streaming\", \"c3\": \"Both - Hybrid\"}',1,'Ingestion',NULL,'2024-11-20 10:24:22','2024-11-20 13:28:43'),(37,'What are your considerations on cost?','single_choice','{\"c1\": \"High\", \"c2\": \"Low\"}',1,'Architecture',NULL,'2024-11-20 13:42:10','2024-11-20 13:42:10'),(38,'What is your data volume?','single_choice','{\"c1\": \"High (PB level)\", \"c2\": \"Medium (<=TB level)\"}',1,'Ingestion',NULL,'2024-11-20 13:57:43','2024-11-20 13:57:43'),(39,'What is the complexity of your ETL?','single_choice','{\"c1\": \"High\", \"c2\": \"Low\"}',1,'Preparation',NULL,'2024-11-20 13:59:23','2024-11-20 13:59:23'),(40,'What are your streaming data processing requirements?','single_choice','{\"c1\": \"High latency tolerance (minutes to hours)\", \"c2\": \"Requires near real-time response (seconds)\"}',1,'Preparation',NULL,'2024-11-20 16:16:13','2024-11-20 16:16:33'),(41,'What is the demand for data processing complexity?','single_choice','{\"c1\": \"Mainly simple cleaning, transformation, and partitioning.\", \"c2\": \"Requires complex ETL logic and multi-stage calculations.\", \"c3\": \"Involves real-time calculations and complex analysis (such as aggregation, anomaly detection)\"}',1,'Preparation',NULL,'2024-11-20 16:16:13','2024-11-20 16:16:33'),(42,'What are the query frequency and real-time requirements?','single_choice','{\"c1\": \"The query frequency is low, mainly offline analysis (daily or weekly).\", \"c2\": \"Frequent queries, requiring quasi-real-time or real-time analysis results.\"}',1,'Analysis',NULL,'2024-11-20 16:16:13','2024-11-20 16:16:33'),(43,'What are the O&M and cost priorities of the data lake?','single_choice','{\"c1\": \"Prefer low cost, and the O&M complexity is acceptable\", \"c2\": \"Prefer easy maintenance, even if the cost is higher, it is acceptable.\"}',1,'Architecture',NULL,'2024-11-20 16:16:13','2024-11-20 16:16:33');
/*!40000 ALTER TABLE `questions_table` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `storage`
--

DROP TABLE IF EXISTS `storage`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `storage` (
  `Id_sto` int NOT NULL AUTO_INCREMENT,
  `name_sto` varchar(255) DEFAULT NULL,
  `Id_sto_class` int NOT NULL,
  `url_sto` varchar(255) CHARACTER SET utf8mb3 COLLATE utf8mb3_general_ci DEFAULT NULL,
  `description_sto` text,
  `logo_sto` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`Id_sto`),
  KEY `Id_sto_class` (`Id_sto_class`),
  CONSTRAINT `storage_ibfk_1` FOREIGN KEY (`Id_sto_class`) REFERENCES `storage_class` (`Id_sto_class`)
) ENGINE=InnoDB AUTO_INCREMENT=10056 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `storage`
--

LOCK TABLES `storage` WRITE;
/*!40000 ALTER TABLE `storage` DISABLE KEYS */;
INSERT INTO `storage` (`Id_sto`, `name_sto`, `Id_sto_class`, `url_sto`, `description_sto`, `logo_sto`) VALUES (10001,'Elasticsearch',1,'https://www.elastic.co/elasticsearch','<p>Elasticsearch is an open source distributed search and analytics engine first released by Elastic in 2010. Built on Apache Lucene, it was designed to provide an efficient solution for full-text search, and its performance and flexibility have quickly made it a popular tool in the industry. </p\n    <p>Elasticsearch\'s strengths include fast full-text search capabilities, a scalable distributed architecture, and powerful real-time data analytics. However, it has a high demand for hardware resources and is complex to manage, especially when there is a huge amount of data that may face cluster stability issues. </p>\n    <p>In Data Lake, Elasticsearch can be used for real-time querying and analysis of unstructured data such as log data, text data, etc. It is especially suitable for scenarios that require instant search and insights, such as application monitoring, user behavior analysis, and error log troubleshooting. </p>','/logo_storage/Elasticsearch.png'),(10002,'Amazon OpenSearch Service',1,'https://aws.amazon.com/cn/opensearch-service/','<p>Amazon OpenSearch Service (formerly Amazon Elasticsearch Service) is a fully managed Elasticsearch and OpenSearch solution from AWS. Launched in 2015, the service is designed to help users more easily deploy and manage search and analytics workloads. </p>\n <p>The benefits include seamless integration with the AWS ecosystem, high scalability, and a reduced maintenance burden for users. Disadvantages include relatively high cost and limited support for environments outside of AWS. </p>\n <p>In data lakes, Amazon OpenSearch Service is suitable for scenarios that require rapid deployment, and performs particularly well in AWS cloud environments when processing real-time logs, metrics data, and machine learning model output. </p>','/logo_storage/amazonOpenSearchService.jpg'),(10003,'Elastic on Microsoft Azure',1,'https://azuremarketplace.microsoft.com/en-us/marketplace/apps/elastic.ec-azure-pp','<p>Elastic on Microsoft Azure is a hosted version of Elasticsearch on the Azure cloud, provided by Elastic, Inc. in partnership with Microsoft. The service combines the power of Elasticsearch with the infrastructure capabilities of Azure and goes live in 2019. </p>\n    <p>Its strengths include integration with Azure data services such as Azure Blob Storage and Azure Event Hubs, as well as simplified deployment and monitoring processes. Disadvantages include limited support for fully customizable configurations and dependence on the Azure platform. </p>\n    <p>In Data Lake, Elastic on Microsoft Azure is a good fit for organizations using Azure data tools, especially when they need to work with diverse data and perform complex analytics, such as IoT data stream analysis and text mining. </p>\n','/logo_storage/elasticAzure.png'),(10004,'Elasticsearch Service on Google Cloud',1,'https://cloud.google.com/elastic?hl=en','<p>Elasticsearch Service on Google Cloud is a hosted service from Elastic, Inc. in partnership with Google, designed to provide users with the best experience running Elasticsearch on Google Cloud. The service launches in 2019 and is focused on supporting modern data analytics needs. </p>\n    <p>Pros include seamless integration with Google Cloud Storage and BigQuery, as well as support for Elastic\'s own security features. The main drawbacks are that the pricing model may not be flexible enough and is dependent on the Google Cloud environment. </p>\n    <p>In Data Lake, the service is particularly well suited for scenarios that require fast analytics with Google Cloud data tools, such as large-scale event data processing and cross-regional data analysis. </p>','/logo_storage/azure.jpg'),(10005,'Elastic Compute Service',1,'https://www.alibabacloud.com/help/en/es/product-overview/what-is-alibaba-cloud-elasticsearch','<p>Elastic Compute Service (ECS) is a cloud computing service provided by Aliyun, designed to provide users with on-demand scalable computing resources. The service was launched in 2009 and is one of the earliest core offerings from Aliyun. </p>\n    <p>The advantages of ECS include high-performance computing power, flexible billing models, and rich geographic coverage. The disadvantages are that it can be complicated for beginners and some of the advanced features may cost extra. </p>\n    <p>In a data lake, ECS is typically used as a base compute platform to support tasks such as data preprocessing, model training, and real-time data analysis. It is particularly suited to compute-intensive scenarios that require high availability and scalability. </p>','/logo_storage/alibaba.png'),(10006,'Elastic Cloud',1,'https://www.elastic.co/fr/cloud/','<p>Elastic Cloud is the official hosted service from Elastic that allows users to run Elasticsearch and Kibana on multiple cloud providers. it was launched in 2012 to give users access to the power of Elasticsearch with minimal management costs. </p>\n    <p>The benefits include an easy-to-use deployment process, flexible options for cross-cloud support, and optimization capabilities powered by Elastic. Disadvantages include dependence on Elastic\'s ecosystem and limited customization. </p>\n    <p>In a data lake, Elastic Cloud is suited for environments that require rapid deployment and centralized management, with particular benefits when working with log data, event monitoring, and multidimensional data analysis in multi-cloud architectures. </p>','/logo_storage/ElasticCloud.png'),(10007,'MySQL',10,'https://www.mysql.com/','<p>MySQL is an open source relational database management system developed by the Swedish company MySQL AB in 1995 and acquired by Oracle Corporation in 2008. As one of the most popular databases, MySQL is favored in the developer community for its simplicity, efficiency, and open source nature. </p>\n    <p>MySQL\'s strengths include fast read and write performance, a simple architecture, and broad community support. However, its transaction processing capabilities are limited, and it may underperform especially when dealing with complex queries and high concurrency scenarios. </p>\n    <p>In a data lake, MySQL can be used to store structured data, such as metadata and small datasets, and is suitable for applications that do not require high analytic speed or for use as a supporting database in a data lake. </p>','/logo_storage/mySQL.png'),(10008,'PostgreSQL',10,'https://www.postgresql.org/','<p>PostgreSQL is an open source object-relational database management system originally released in 1996. It evolved from the POSTGRES system developed at the University of California, Berkeley, and is known for its high scalability and support for complex data types. </p>\n    <p>PostgreSQL\'s strengths include robust transaction processing, native support for JSON and geospatial data, and a highly scalable plugin ecosystem. The downside is that performance may not be as fast as MySQL, especially when dealing with simple queries. </p>\n    <p>In Data Lake, PostgreSQL is particularly well suited for scenarios where complex data structures need to be stored and queried, such as geographic information systems (GIS), analytical applications, and metadata stores. </p>','/logo_storage/PostgreSQL.png'),(10009,'MariaDB',10,'https://mariadb.org/','<p>MariaDB is a fork of MySQL, created in 2009 by the original developers of MySQL to ensure open source compatibility.MariaDB is highly functionally compatible with MySQL, with many unique enhancements added over time. </p\n    <p>MariaDB\'s strengths include better performance optimization, support for more storage engines, and enhancements for distributed queries. The disadvantages are that the community is slightly smaller than MySQL and some of the features are not exactly the same as MySQL. </p>\n    <p>In a data lake, MariaDB can be used as an alternative to MySQL for storing structured data, and especially excels in scenarios that require higher performance optimizations or specific storage engines such as ColumnStore. </p>','/logo_storage/MariaDB.png'),(10010,'Oracle Database',10,'https://www.oracle.com/','<p>Oracle Database is a high-performance commercial relational database introduced by Oracle Corporation in 1977. It is the leader in enterprise-class databases and is widely used in a variety of business-critical systems for its powerful features and stability. </p>\n    <p>The strengths of Oracle Database include excellent performance and stability, powerful transaction processing, and support for massive concurrency. The drawbacks include high license fees and complex management requirements. </p>\n    <p>In Data Lake, Oracle Database is suited for scenarios that require the processing of mission-critical, large-scale structured data storage and analytics, and is particularly strong in applications in the financial, retail, and government sectors. </p>','/logo_ingestion/oracle.png'),(10011,'Microsoft SQL Server',10,'https://www.microsoft.com/en-us/sql-server/','<p>Microsoft SQL Server is a relational database management system developed by Microsoft and first released in 1989. It is one of the dominant database solutions in Windows environments and also supports cross-platform deployment. </p>\n    <p>The advantages of SQL Server include deep integration with Windows and the Microsoft ecosystem, powerful business intelligence (BI) capabilities, and intuitive management tools. Disadvantages include higher license costs and performance that may not be as good as open source databases in some complex distributed scenarios. </p>\n    <p>In a data lake, Microsoft SQL Server can be used as part of the data lake analytics layer, and is particularly suited to enterprise environments that need to integrate their databases with other Microsoft tools such as Power BI and Azure Data Factory. </p>','/logo_storage/microsoftSQLServer.png'),(10012,'Amazon RDS',10,'https://aws.amazon.com/cn/free/database/','<p>Amazon Relational Database Service (RDS) is a fully managed database service offered by AWS, launched in 2009. It supports various database engines such as MySQL, PostgreSQL, MariaDB, Oracle, and Microsoft SQL Server, allowing developers to deploy and manage databases with ease.</p>\n    <p>The advantages of Amazon RDS include reduced operational overhead, automated backups, and scalability. However, it comes with higher costs compared to self-managed databases, and there are limitations in customization options.</p>\n    <p>In data lakes, Amazon RDS is suitable for managing metadata, structured data, and as a transactional database for analytics pipelines or applications requiring reliable relational storage.</p>','/logo_storage/amazonAurora.jpg'),(10013,'Microsoft Azure SQL Database',10,'https://azure.microsoft.com/en-us/products/azure-sql/database/','<p>Microsoft Azure SQL Database is a fully managed relational database service on the Azure cloud platform, launched in 2010. It is built on SQL Server technology, offering high compatibility and seamless integration with the Microsoft ecosystem.</p>\n    <p>The benefits of Azure SQL Database include automated scalability, high availability, and integration with Azure tools like Power BI. Drawbacks include potentially higher costs and limited control over certain database-level configurations.</p>\n    <p>In data lakes, Azure SQL Database is ideal for managing structured data, serving analytics workloads, and providing scalable storage for applications that require low-latency access to relational data.</p>','/logo_storage/azure.jpg'),(10014,'Microsoft Azure Database for PostgreSQL',10,'https://azure.microsoft.com/en-us/products/postgresql','<p>Microsoft Azure Database for PostgreSQL is a managed PostgreSQL database service offered by Azure, launched in 2017. It provides enterprise-grade features for PostgreSQL users with full compatibility and integration with Azure services.</p>\n    <p>The advantages include ease of scaling, automated updates and backups, and native support for PostgreSQL extensions. However, users may face limitations in terms of advanced customization and dependency on Azure infrastructure.</p>\n    <p>In data lakes, Azure Database for PostgreSQL is suitable for storing and querying complex structured data, supporting geospatial analysis, and powering analytical applications that require robust transaction handling.</p>','/logo_storage/azure.jpg'),(10015,'Microsoft Azure Database for MySQL',10,'https://azure.microsoft.com/en-us/products/mysql','<p>Microsoft Azure Database for MySQL is a fully managed MySQL service, introduced by Azure in 2017. It simplifies MySQL database management with features like automated backups, scaling, and security patches.</p>\n    <p>The benefits include quick deployment, integration with Azure services, and reduced management overhead. Limitations include less flexibility for self-hosted setups and potentially higher costs for high-performance workloads.</p>\n    <p>In data lakes, Azure Database for MySQL can be used for managing structured data, metadata, and transactional data in scenarios requiring moderate performance and scalability.</p>','/logo_storage/azure.jpg'),(10016,'Microsoft Azure Database for MariaDB',10,'https://azure.microsoft.com/fr-fr/products/mariadb','<p>Microsoft Azure Database for MariaDB is a managed MariaDB service offered on Azure, launched in 2018. It is designed to provide MariaDB users with a scalable and secure database solution fully integrated with Azures ecosystem.</p>\n    <p>The advantages include ease of use, automated maintenance, and support for various MariaDB versions. Drawbacks include higher costs compared to self-hosted MariaDB instances and dependency on Azure infrastructure.</p>\n    <p>In data lakes, Azure Database for MariaDB is useful for structured data storage and applications needing a MariaDB backend, particularly when high availability and Azure-native integrations are required.</p>','/logo_storage/azure.jpg'),(10017,'Google Cloud SQL',10,'https://cloud.google.com/sql?hl=en','<p>Google Cloud SQL is a fully managed relational database service provided by Google Cloud, supporting MySQL, PostgreSQL, and SQL Server. It was launched in 2011 to simplify database management and scaling on Google Cloud.</p>\n    <p>Advantages include seamless integration with Google Cloud services, automated scaling, and backups. The drawbacks are higher costs for large-scale use and less flexibility compared to self-managed databases.</p>\n    <p>In data lakes, Google Cloud SQL is well-suited for managing transactional data, metadata, and supporting data processing pipelines that integrate with BigQuery and other Google Cloud tools.</p>','/logo_storage/googleCloudSQL.png'),(10018,'ApsaraDB for RDS',10,'https://www.alibabacloud.com/en/product/apsaradb-for-rds-mysql?_p_lc=1','<p>ApsaraDB for RDS is a managed relational database service offered by Alibaba Cloud. Supporting engines like MySQL, PostgreSQL, SQL Server, and MariaDB, it provides a reliable and scalable database solution for enterprise users.</p>\n    <p>The advantages of ApsaraDB for RDS include automated maintenance, high availability, and strong integration with Alibaba Cloud services. However, its ecosystem is primarily tailored for users already invested in Alibaba Cloud.</p>\n    <p>In data lakes, ApsaraDB for RDS is suitable for structured data storage, transactional workloads, and scenarios requiring high availability and scalability within the Alibaba Cloud ecosystem.</p>','/logo_storage/alibaba.png'),(10019,'Redis',11,'https://redis.io/','<p>Redis (Remote Dictionary Server) is an open-source, in-memory key-value store, first released in 2009. It is designed for high-performance use cases, such as caching, message brokering, and real-time analytics.</p>\n    <p>Redis excels in speed, simplicity, and support for complex data structures like lists, sets, and hashes. However, it is memory-dependent and not designed for handling large datasets that don\'t fit in memory.</p>\n    <p>In data lakes, Redis can be used for caching query results, session storage, and real-time analytics components to enhance performance in high-throughput scenarios.</p>','/logo_storage/Redis.png'),(10020,'MongoDB',11,'https://www.mongodb.com/','<p>MongoDB is an open-source, NoSQL database developed in 2009. It stores data in a JSON-like format, making it ideal for flexible, schema-less applications.</p>\n    <p>MongoDB\'s advantages include horizontal scalability, flexibility, and support for large, unstructured data. Its drawbacks include slower performance for complex transactions and higher storage overhead due to its schema-less nature.</p>\n    <p>In data lakes, MongoDB is well-suited for managing semi-structured or unstructured data, such as logs, documents, and application data that require high flexibility.</p>','/logo_storage/mongoDB.png'),(10021,'InfluxDB',11,'https://www.influxdata.com/','<p>InfluxDB is a time-series database optimized for high-performance storage and querying of time-stamped data, launched in 2013. It is widely used in monitoring, IoT, and analytics applications.</p>\n    <p>Its strengths include high write throughput, efficient storage of time-series data, and a rich query language. However, it may not be ideal for general-purpose relational workloads.</p>\n    <p>In data lakes, InfluxDB is ideal for time-series data like sensor readings, metrics, and event logs, providing powerful capabilities for real-time data analysis.</p>','/logo_storage/InfluxDB.png'),(10022,'Neo4j',11,'https://neo4j.com/fr/','<p>Neo4j is a graph database first released in 2007. It uses a node-relationship model, making it suitable for applications that involve complex relationships, such as social networks and recommendation systems.</p>\n    <p>Neo4j\'s strengths lie in its ability to handle highly interconnected data and execute graph queries efficiently. Its downside includes challenges in scaling horizontally for extremely large datasets.</p>\n    <p>In data lakes, Neo4j is perfect for scenarios involving relationship-driven analysis, such as fraud detection, network analysis, and knowledge graphs.</p>','/logo_storage/neo4j.png'),(10023,'PostgreSQL with Citus',12,'https://www.postgresql.org/','<p>PostgreSQL with Citus is a distributed database extension for PostgreSQL, introduced by Citus Data (now part of Microsoft) to enable horizontal scaling and parallel processing.</p>\n    <p>Advantages include the ability to scale out PostgreSQL for large datasets and improved query performance on distributed workloads. A downside is the complexity of managing a distributed setup.</p>\n    <p>In data lakes, PostgreSQL with Citus is ideal for analytical workloads requiring distributed query processing across large structured datasets.</p>','/logo_storage/PostgreSQL.png'),(10024,'VoltDB',12,'https://www.voltactivedata.com/','<p>VoltDB is an in-memory, high-performance relational database launched in 2010. It is designed for fast transactional processing and real-time analytics.</p>\n    <p>Its advantages include low-latency transaction processing and strong consistency. However, its memory-based nature limits it to applications where data fits in memory.</p>\n    <p>In data lakes, VoltDB can be used for real-time processing of high-velocity data streams and transactional data pipelines.</p>','/logo_storage/VoltDB.png'),(10025,'MySQL Cluster (NDB Cluster)',12,'https://www.mysql.com/','<p>MySQL Cluster, also known as NDB Cluster, is a distributed, high-availability database solution designed by MySQL for use cases requiring scalability and fault tolerance.</p>\n    <p>It offers high availability and distributed data processing. However, its complexity in setup and maintenance can be a challenge for beginners.</p>\n    <p>In data lakes, MySQL Cluster is suitable for applications requiring real-time data access and high fault tolerance, such as telecom and financial services.</p>','/logo_storage/mySQL.png'),(10026,'Amazon Aurora',12,'https://aws.amazon.com/fr/rds/aurora/','<p>Amazon Aurora is a fully managed relational database developed by AWS, launched in 2014. It is compatible with MySQL and PostgreSQL and provides high performance and availability.</p>\n    <p>Advantages include scalability, automated maintenance, and faster performance compared to traditional MySQL or PostgreSQL. Drawbacks include its dependency on AWS infrastructure and cost considerations.</p>\n    <p>In data lakes, Aurora is well-suited for transactional workloads, metadata storage, and analytical pipelines requiring high availability and performance.</p>\n</div>','/logo_storage/amazonAurora.jpg'),(10027,'Microsoft Azure SQL Database Hyperscale',12,'https://learn.microsoft.com/fr-fr/azure/azure-sql/database/service-tier-hyperscale?view=azuresql','<p>Hyperscale is a cloud-native solution offered by Azure for scaling SQL databases. It is built on Azure SQL Database to provide virtually unlimited storage and rapid scalability.</p>\n    <p>Its benefits include fast scaling, high availability, and support for very large databases. The downside is a higher cost compared to standard database offerings.</p>\n    <p>In data lakes, Hyperscale is ideal for managing structured data in analytical workloads requiring massive scalability and rapid response times.</p>\n</div>','/logo_storage/azure.jpg'),(10028,'Microsoft Azure Database for PostgreSQL',12,'https://azure.microsoft.com/en-us/products/postgresql','<p>Microsoft Azure Database for PostgreSQL is a managed database service for PostgreSQL users, launched in 2017. It simplifies database operations while maintaining PostgreSQL\'s robust capabilities.</p>\n    <p>Its strengths include ease of integration with Azure tools, scalability, and automated backups. Drawbacks include higher costs and less flexibility in on-premise-like customizations.</p>\n    <p>In data lakes, Azure Database for PostgreSQL is suitable for managing structured data and powering analytical applications that benefit from the flexibility of PostgreSQL.</p>','/logo_storage/azure.jpg'),(10029,'Google Cloud Spanner',12,'https://cloud.google.com/spanner/?hl=en','<p>Google Cloud Spanner is a globally distributed, horizontally scalable relational database, launched in 2017. It combines the consistency of relational databases with the scalability of NoSQL systems.</p>\n    <p>Advantages include global availability, strong consistency, and high scalability. Drawbacks are its cost and dependency on Google Cloud infrastructure.</p>\n    <p>In data lakes, Spanner is ideal for globally distributed datasets requiring consistent, real-time transactions and analytics.</p>','/logo_storage/googleCloudSpanner.png'),(10030,'ApsaraDB for PolarDB',12,'https://www.alibabacloud.com/en/products/polardb?_p_lc=1','<p>ApsaraDB for PolarDB is Alibaba Cloud\'s next-generation relational database, offering compatibility with MySQL and PostgreSQL and designed for high performance and scalability.</p>\n    <p>Its strengths include high availability, rapid scaling, and cost-effective storage. The downside is its tight coupling with Alibaba Cloud infrastructure.</p>\n    <p>In data lakes, PolarDB is ideal for managing structured data, powering real-time analytics, and supporting transactional workloads in Alibaba Cloud ecosystems.</p>','/logo_storage/apsaraDBforPolarDB.png'),(10031,'Alibaba Cloud DRDS',12,'https://www.alibabacloud.com/en/product/drds/pricing?_p_lc=1','<p>Distributed Relational Database Service (DRDS) is Alibaba Cloud\'s distributed database solution designed for high-throughput, horizontally scalable workloads.</p>\n    <p>DRDS offers strong scalability, high performance, and seamless integration with Alibaba Cloud services. However, it is best suited for users already in the Alibaba ecosystem.</p>\n    <p>In data lakes, DRDS is suitable for large-scale data processing tasks, such as online analytical processing (OLAP) and transactional workloads requiring scalability.</p>','/logo_storage/alibaba.png'),(10032,'Apache Hbase',13,'https://hbase.apache.org/','<p>Apache HBase is an open-source, distributed, NoSQL database modeled after Google\'s Bigtable. It was initially released in 2008 as part of the Apache Hadoop ecosystem, designed to handle large amounts of sparse data across clusters.</p>\n    <p>HBase\'s strengths include its ability to manage petabytes of data, high scalability, and real-time read/write access to large datasets. However, it requires significant expertise to configure and maintain, and it is optimized for specific use cases like time-series data and sparse data tables rather than general-purpose use.</p>\n    <p>In data lakes, HBase is ideal for scenarios requiring high throughput and real-time access, such as IoT data storage, logs, and analytical applications involving large-scale data aggregation and retrieval.</p>','/logo_storage/apacheHbase.png'),(10033,'Cassandra',13,'https://cassandra.apache.org/_/index.html','<p>Cassandra is an open-source, distributed NoSQL database initially developed at Facebook in 2008 and later released under the Apache Software Foundation. It is known for its high availability and decentralized architecture.</p>\n    <p>Advantages of Cassandra include linear scalability, fault tolerance, and a peer-to-peer architecture that ensures no single point of failure. However, it has a steeper learning curve, and its write-heavy architecture can make complex queries slower compared to relational databases.</p>\n    <p>In data lakes, Cassandra is well-suited for handling large-scale distributed datasets, such as sensor data, user activity logs, and other time-series or event-driven data.</p>','/logo_storage/cassandra.png'),(10034,'MongoDB',13,'https://www.mongodb.com/','<p>MongoDB is a NoSQL database designed for flexibility and scalability, first released in 2009. It stores data in BSON format, which is a binary version of JSON, enabling it to handle semi-structured and unstructured data effectively.</p>\n    <p>MongoDB\'s key advantages include its schema-less design, horizontal scalability, and support for rich data structures like arrays and nested objects. However, its lack of strong consistency in distributed setups and relatively high storage overhead can be limiting for some use cases.</p>\n    <p>In data lakes, MongoDB is an excellent choice for storing semi-structured data, such as logs, documents, or content from APIs, enabling flexible querying and integration with various analytical tools.</p>','/logo_storage/mongoDB.png'),(10035,'Neo4j',13,'https://neo4j.com/fr/','<p>Neo4j is a graph database first released in 2007, designed to store and manage data using a node-relationship model. It excels in representing and analyzing highly interconnected datasets.</p>\n    <p>Neo4j\'s strengths include its ability to efficiently query relationships in complex data, making it ideal for social networks, recommendation systems, and fraud detection. Its drawbacks include challenges in horizontal scaling and a narrower range of supported use cases compared to general-purpose databases.</p>\n    <p>In data lakes, Neo4j is ideal for use cases that require deep relationship analysis, such as customer relationship management, network analysis, or knowledge graph building.</p>\n','/logo_storage/neo4j.png'),(10036,'InfluxDB',13,'https://www.influxdata.com/','<p>InfluxDB is a high-performance time-series database optimized for storing and querying time-stamped data. Released in 2013, it has become a popular choice for monitoring, IoT, and event-based applications.</p>\n    <p>InfluxDB\'s strengths include its high write throughput, efficient data compression, and a query language designed specifically for time-series data. However, its scope is limited to time-series use cases, and it lacks the versatility of general-purpose databases.</p>\n    <p>In data lakes, InfluxDB is best suited for storing and analyzing metrics, sensor readings, and other time-based data, enabling real-time and historical insights.</p>','/logo_storage/InfluxDB.png'),(10037,'Amazon DynamoDB',13,'https://aws.amazon.com/fr/dynamodb/','<p>Amazon DynamoDB is a fully managed NoSQL database offered by AWS, launched in 2012. It provides a highly available and scalable solution for key-value and document-based workloads.</p>\n    <p>The key advantages of DynamoDB include automatic scaling, low-latency access, and deep integration with the AWS ecosystem. However, its pricing can become high for large-scale read/write operations, and its query capabilities are less flexible than traditional databases.</p>\n    <p>In data lakes, DynamoDB is an excellent choice for managing metadata, session storage, and other high-throughput, low-latency workloads requiring strong availability.</p>','/logo_storage/amazonDynamoDB.jpg'),(10038,'Microsoft Azure Cosmos DB',13,'https://azure.microsoft.com/fr-fr/products/cosmos-db/','<p>Azure Cosmos DB is a globally distributed, multi-model database service provided by Microsoft Azure. It was launched in 2017 to offer high performance and seamless global distribution for a variety of workloads.</p>\n    <p>Cosmos DB\'s advantages include support for multiple data models (key-value, document, graph, column-family), global replication, and millisecond response times. Its drawbacks include higher costs compared to traditional databases and complexity in query optimization.</p>\n    <p>In data lakes, Cosmos DB is well-suited for globally distributed datasets requiring low-latency access, such as IoT telemetry, personalized user experiences, and globally consistent metadata storage.</p>','/logo_storage/azureCosmosDB.jpg'),(10039,'Google Cloud Bigtable',13,'https://cloud.google.com/bigtable?hl=en','<p>Google Cloud Bigtable is a fully managed, NoSQL database designed for large-scale, low-latency workloads. It was first introduced in 2015 as the managed version of Google\'s proprietary Bigtable system.</p>\n    <p>Its strengths include massive scalability, high performance for time-series and analytical workloads, and seamless integration with Google Cloud tools like BigQuery. However, it is limited to column-family data models, which may not suit all use cases.</p>\n    <p>In data lakes, Bigtable is ideal for managing large-scale time-series data, clickstream data, and real-time analytics, particularly when integrated with other Google Cloud services.</p>','/logo_storage/googleCloudBigtable.png'),(10040,'Google Firestore',13,'https://firebase.google.com/docs/firestore?hl=fr','<p>Google Firestore is a serverless, NoSQL database launched in 2017 as a successor to Firebase Realtime Database. It is optimized for mobile, web, and server development with real-time syncing capabilities.</p>\n    <p>Firestore\'s advantages include real-time data synchronization, offline data access, and seamless integration with Firebase and Google Cloud. However, its scope is limited to document-based workloads, and it may not handle complex queries as efficiently as relational databases.</p>\n    <p>In data lakes, Firestore is suitable for managing semi-structured data, especially in applications requiring real-time updates and cross-platform synchronization, such as mobile apps and web dashboards.</p>','/logo_storage/googleFirestore.png'),(10041,'Alibaba Cloud Table Store (Tablestore)',13,'https://www.alibabacloud.com/en/product/table-store?_p_lc=1','<p>Alibaba Cloud Table Store, also known as Tablestore, is a distributed NoSQL database designed for high-performance and scalable data storage. It supports diverse data models, including time-series, document, and wide-column formats.</p>\n    <p>Its strengths include strong scalability, multi-model support, and integration with Alibaba Cloud\'s analytics and AI tools. The main limitation is its dependency on Alibaba Cloud\'s ecosystem, which may restrict flexibility for multi-cloud strategies.</p>\n    <p>In data lakes, Tablestore is ideal for storing time-series data, IoT data, and other high-throughput workloads, especially for users already leveraging Alibaba Cloud services for analytics and AI applications.</p>','/logo_storage/alibabaCloudTableStore.png'),(10042,'HDFS',7,'https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html','<p>The Hadoop Distributed File System (HDFS) is a distributed file system designed for large-scale data storage and processing. It is part of the Apache Hadoop ecosystem, launched in 2006, and is optimized for handling massive datasets across clusters of commodity hardware.</p>\n    <p>HDFS provides high throughput, fault tolerance, and scalability. However, it is not ideal for low-latency data access or small file storage. It requires significant expertise for configuration and management.</p>\n    <p>In data lakes, HDFS is widely used for storing unstructured and semi-structured data in distributed environments, serving as the foundation for big data processing frameworks like Apache Spark and Hive.</p>','/logo_storage/mapreduce.png'),(10043,'Amazon Elastic File System (EFS)',7,'https://aws.amazon.com/fr/efs/','<p>Amazon EFS is a fully managed, scalable, and elastic file storage service offered by AWS. It was launched in 2016 to provide a cloud-native solution for file-based workloads.</p>\n    <p>EFS\'s advantages include automatic scaling, high availability, and integration with AWS services. Its drawbacks are higher costs compared to block storage and potential performance limitations for high-throughput applications.</p>\n    <p>In data lakes, EFS is ideal for workloads requiring shared file storage across multiple instances, such as data processing, analytics, and application development in AWS environments.</p>','/logo_storage/amazonEFS.png'),(10044,'Google Filestore',7,'https://cloud.google.com/filestore?hl=fr','<p>Google Filestore is a fully managed file storage service that provides high-performance file shares for Google Cloud users. It was introduced in 2018 to address the needs of applications requiring shared storage.</p>\n    <p>Its strengths include seamless integration with Google Kubernetes Engine (GKE) and Compute Engine, as well as low-latency access to file data. However, it is relatively expensive for large-scale storage needs.</p>\n    <p>In data lakes, Google Filestore is suitable for storing structured and semi-structured data that require shared access, particularly in Google Cloud environments.</p>','/logo_storage/googleFilestore.png'),(10045,'Azure Files Storage',7,'https://learn.microsoft.com/fr-fr/azure/storage/files/storage-files-introduction','<p>Azure Files Storage is a managed file storage service offered by Microsoft Azure, providing SMB (Server Message Block) protocol support for seamless integration with Windows systems. It was launched in 2014.</p>\n    <p>The benefits of Azure Files include simplicity, compatibility with existing tools, and scalability. However, it may not be cost-effective for high-performance workloads compared to alternative storage types.</p>\n    <p>In data lakes, Azure Files is suitable for storing structured and semi-structured data, particularly for applications requiring shared file access across Azure-hosted services.</p>','/logo_storage/azureFilesStorage.png'),(10046,'Network Attached Storage(NAS)',6,'https://aws.amazon.com/what-is/nas/','<p>Network Attached Storage (NAS) is a file-based storage system that provides shared access to files over a network. It has been widely used in enterprise environments since its introduction in the late 1980s.</p>\n    <p>NAS offers simplicity, centralized management, and compatibility with various protocols. However, it is less suitable for high-performance workloads and can become a bottleneck in high-throughput scenarios.</p>\n    <p>In data lakes, NAS is useful for storing semi-structured and unstructured data, particularly in on-premises setups or hybrid environments.</p>','/logo_storage/nas.png'),(10047,'Storage Area Network(SAN)',6,'https://www.snia.org/education/storage_networking_primer/san/what_san','<p>Storage Area Network (SAN) is a high-speed network that provides access to consolidated block storage. It is commonly used in enterprise environments for mission-critical workloads.</p>\n    <p>SAN provides high performance, scalability, and fault tolerance. However, it is expensive to deploy and maintain, making it less suitable for small-scale setups.</p>\n    <p>In data lakes, SAN is ideal for handling high-performance transactional data storage, particularly for enterprise-level analytics and database applications.</p>','/logo_storage/san.png'),(10048,'New Technology File System(NTFS)',6,'https://en.wikipedia.org/wiki/NTFS','<p>NTFS is a proprietary file system developed by Microsoft for the Windows operating system. It was introduced in 1993 and is widely used for file storage and management.</p>\n    <p>NTFS supports large file sizes, robust security features, and file compression. However, it is primarily limited to Windows environments, with limited cross-platform compatibility.</p>\n    <p>In data lakes, NTFS can be used for local storage in Windows-based systems, particularly for temporary storage or processing of small datasets.</p>','/logo_storage/ntfs.png'),(10049,'Fourth Extended Filesystem(EXT4)',6,'https://en.wikipedia.org/wiki/Ext4','<p>EXT4 is a widely used Linux filesystem introduced in 2008 as an improvement over EXT3. It is optimized for performance, reliability, and large file support.</p>\n    <p>EXT4 provides fast read/write speeds, large volume support, and excellent journaling capabilities. However, it lacks the advanced features of modern distributed file systems.</p>\n    <p>In data lakes, EXT4 is suitable for local storage in Linux-based environments, particularly for intermediate data processing and temporary storage.</p>','/logo_storage/ext4.jpg'),(10050,'MinIO',8,'https://min.io/','<p>MinIO is an open-source, high-performance object storage system compatible with the Amazon S3 API. It was launched in 2015 and is designed for cloud-native environments.</p>\n    <p>MinIO\'s strengths include scalability, simplicity, and compatibility with various applications that support S3 APIs. Its drawback is that it may require more management effort compared to fully managed services.</p>\n    <p>In data lakes, MinIO is ideal for storing unstructured data, such as images, videos, and logs, particularly in hybrid and private cloud environments.</p>','/logo_storage/minIO.png\n'),(10051,'Ceph',8,'https://ceph.io/en/','<p>Ceph is an open-source, distributed storage platform designed for object, block, and file storage. It was released in 2006 and is widely used for scalable, fault-tolerant storage.</p>\n    <p>Ceph\'s advantages include flexibility, high scalability, and strong fault tolerance. However, it requires significant expertise to deploy and manage effectively.</p>\n    <p>In data lakes, Ceph is suitable for unified storage needs, including object storage for unstructured data and block storage for transactional data.</p>','/logo_storage/ceph.png'),(10052,'Amazon S3',8,'https://aws.amazon.com/fr/s3/','<p>Amazon Simple Storage Service (S3) is a highly scalable object storage service introduced by AWS in 2006. It is designed for storing and retrieving any amount of data at high availability and durability.</p>\n    <p>S3 provides strong security, cost-effective pricing, and seamless integration with AWS services. However, its performance can be limited for low-latency workloads compared to block storage.</p>\n    <p>In data lakes, Amazon S3 is a foundational service for storing unstructured data, such as logs, images, and backup files, enabling data processing and analytics workflows.</p>','/logo_storage/s3.png'),(10053,'Google Cloud Storage',8,'https://cloud.google.com/storage?hl=en','<p>Google Cloud Storage is a fully managed object storage service designed for high scalability and availability. It supports multiple storage classes to optimize cost and performance.</p>\n    <p>Advantages of Google Cloud Storage include integration with Google Cloud tools, global availability, and strong security features. Its drawback is dependency on the Google Cloud ecosystem for advanced integrations.</p>\n    <p>In data lakes, Google Cloud Storage is ideal for storing raw and processed data, enabling analytics workflows with tools like BigQuery and Dataproc.</p>','/logo_storage/googleCloudStorage.png'),(10054,'Microsoft Azure Blob Storage',8,'https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blobs-introduction','<p>Azure Blob Storage is a scalable object storage service offered by Microsoft Azure, designed for storing unstructured data like text, images, and videos.</p>\n    <p>Its benefits include strong integration with Azure tools, scalability, and tiered storage for cost optimization. However, it is limited to object storage, making it less suitable for block-based workloads.</p>\n    <p>In data lakes, Azure Blob Storage is commonly used to store raw data, providing a scalable foundation for analytics and machine learning workflows in Azure environments.</p>','/logo_storage/blobStorage.png'),(10055,'Google Memorystore(In-memory)',13,'https://cloud.google.com/memorystore?hl=en','<p>Google Memorystore is a fully managed in-memory data store that supports Redis and Memcached APIs. It was introduced in 2018 to provide high-speed caching and low-latency access to frequently used data.</p>\n    <p>Its strengths include simplicity, scalability, and low-latency performance. However, it is not suitable for persistent data storage, as it is primarily designed for caching and temporary data processing.</p>\n    <p>In data lakes, Google Memorystore is useful for caching intermediate data and accelerating query performance in analytics and machine learning applications.</p>','/logo_storage/memorystore.png');
/*!40000 ALTER TABLE `storage` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `storage_class`
--

DROP TABLE IF EXISTS `storage_class`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `storage_class` (
  `Id_sto_class` int NOT NULL AUTO_INCREMENT,
  `name_class` varchar(50) DEFAULT NULL,
  `Id_sto_parent` int DEFAULT NULL,
  PRIMARY KEY (`Id_sto_class`)
) ENGINE=InnoDB AUTO_INCREMENT=14 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `storage_class`
--

LOCK TABLES `storage_class` WRITE;
/*!40000 ALTER TABLE `storage_class` DISABLE KEYS */;
INSERT INTO `storage_class` (`Id_sto_class`, `name_class`, `Id_sto_parent`) VALUES (1,'Index based system',NULL),(2,'Database',NULL),(3,'Centralized Database',2),(4,'Distributed Database',2),(5,'File system',NULL),(6,'Centralized File system',5),(7,'Distributed File system',5),(8,'Object store',NULL),(9,'Polystore',NULL),(10,'Centralized Relational Database',3),(11,'Centralized NoSQL',3),(12,'Distributed Relational Database',4),(13,'Distributed NoSQL',4);
/*!40000 ALTER TABLE `storage_class` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `tools`
--

DROP TABLE IF EXISTS `tools`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `tools` (
  `Id_t` int NOT NULL AUTO_INCREMENT,
  `name_t` varchar(100) DEFAULT NULL,
  `description_t` text,
  `category_t` varchar(50) DEFAULT NULL,
  `procs_mode` varchar(50) DEFAULT NULL,
  `dplymt_mode_t` varchar(50) DEFAULT NULL,
  `isPay` tinyint(1) DEFAULT NULL,
  `popularity_t` decimal(15,2) DEFAULT NULL,
  `pre_processed` tinyint(1) DEFAULT NULL,
  `complex_data_processing` tinyint(1) DEFAULT NULL,
  `event_driven` tinyint(1) DEFAULT NULL,
  `short_description_t` text,
  `logo` varchar(255) DEFAULT NULL,
  `url` text,
  PRIMARY KEY (`Id_t`)
) ENGINE=InnoDB AUTO_INCREMENT=42 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `tools`
--

LOCK TABLES `tools` WRITE;
/*!40000 ALTER TABLE `tools` DISABLE KEYS */;
INSERT INTO `tools` (`Id_t`, `name_t`, `description_t`, `category_t`, `procs_mode`, `dplymt_mode_t`, `isPay`, `popularity_t`, `pre_processed`, `complex_data_processing`, `event_driven`, `short_description_t`, `logo`, `url`) VALUES (1,'Apache NIFI','<p>Apache NIFI, an open-source data automation tool originally developed by the National Security Agency (NSA) as part of the \"NiagaraFiles\" project, became open source under the Apache Software Foundation in 2014. NIFIs primary goal is to automate the movement of data between disparate systems with a focus on real-time data flows. It comes equipped with a user-friendly web-based interface, allowing even non-experts to design and monitor complex data flows with ease.</p>\n\n<p>One of Apache NIFIs biggest advantages is its intuitive drag-and-drop UI, which greatly simplifies data ingestion and transformation processes. It supports dynamic prioritization, back pressure, and built-in data provenance, making it reliable and efficient in handling both structured and unstructured data. However, it has its drawbacks: the performance of NIFI can sometimes be a concern when dealing with extremely high-throughput use cases. Additionally, the configuration can get complex as data flow scenarios increase in intricacy.</p>\n\n<p>In the context of data lakes, NIFIs robust features make it a strong contender for ingesting data from a multitude of sources. Its support for a wide range of processors, data formats, and protocols means that it can integrate seamlessly into a data lake architecture, ensuring real-time data processing and monitoring capabilities. Its data lineage tracking is especially valuable for data governance and auditing purposes.</p>','Ingestion','B/S','On-p',0,0.18,1,NULL,NULL,'An open-source tool for automating and managing data flows, supporting real-time data streaming and transformation with an easy-to-use UI.','/logo_ingestion/apache_nifi.svg','https://nifi.apache.org/'),(2,'Apache Flume','<p>Apache Flume was created to address the growing need for efficiently collecting, aggregating, and moving large volumes of log data. It emerged from Clouderas need to handle log and event data from various sources into the Hadoop Distributed File System (HDFS). Its simple, flexible, and robust architecture has allowed it to gain traction as a reliable solution for data ingestion, particularly in log-heavy environments.</p> <p>Flumes strengths lie in its reliability, scalability, and ability to handle data spikes gracefully. It provides a straightforward way to ingest large amounts of streaming data into systems like HDFS or even into a data lake environment. Flume uses a series of agents to collect and aggregate data, and it offers customizability through its extensible design. On the downside, it can be challenging to manage and monitor large Flume configurations, and it lacks some of the advanced features like data transformation and error handling that newer tools provide.</p> <p>When integrated into a data lake, Apache Flume shines in scenarios where large-scale log data ingestion is needed. Its particularly well-suited for environments with fluctuating data volumes, providing the ability to maintain high availability and reliability. This makes Flume a natural fit for big data ecosystems, where seamless data transport from distributed systems is crucial.</p>','Ingestion','B/S','On-p',0,0.02,1,NULL,NULL,'A distributed, reliable service for efficiently collecting and moving large amounts of log data to a centralized data store.','/logo_ingestion/flume-logo.png','https://flume.apache.org/'),(3,'Apache Kafka','<p>Apache Kafka was initially developed at LinkedIn and later became an open-source project under the Apache Software Foundation. It has rapidly grown to become one of the most popular distributed event streaming platforms, known for its ability to handle real-time data feeds with extreme reliability and scalability. Kafkas unique architecture, based on a distributed commit log, ensures data durability and high throughput, making it ideal for large-scale message streaming.</p> <p>Kafka\'s major advantage lies in its ability to ingest and process vast amounts of data in real time, thanks to its fault-tolerant and distributed design. Its built to scale horizontally, meaning you can add more brokers to handle increased workloads seamlessly. However, Kafka is not without its challenges. Managing and monitoring Kafka clusters can be complex, especially when scaling across multiple data centers. It also requires a solid understanding of the underlying architecture to optimize for specific use cases.</p> <p>For data lake ingestion, Apache Kafka excels in scenarios where streaming data from various sources needs to be aggregated and processed in real time. Its commonly used as a backbone for streaming architectures, where it can ingest, store, and distribute data to consumers like Apache Spark, Apache Flink, or directly to a data lake. Kafkas support for exactly-once semantics and its integration with a wide array of big data tools make it an excellent choice for building robust, scalable data lake architectures.</p>\n\n\n\n\n\n','Ingestion','B/S','On-p',0,0.97,1,NULL,NULL,'A distributed event streaming platform for high-throughput data pipelines, stream processing, and distributed log storage.\n\n','/logo_ingestion/apache_kafka.svg','https://kafka.apache.org/'),(4,'Pentaho Data Integration(a.k.a Kettle) - community','<p>Pentaho Data Integration, commonly known as Kettle, was first developed by Matt Casters in 2001 and later became part of the Pentaho suite. The community edition of Kettle provides a powerful, open-source ETL (Extract, Transform, Load) platform with a visual design interface. Kettles popularity grew because of its straightforward drag-and-drop interface that enables developers to design and automate complex data transformation workflows with ease.</p>\n\n<p>Kettle Community Edition has several advantages, such as being open source and having a large community of users and contributors. It supports a wide range of data formats and sources, from relational databases to flat files and big data ecosystems like Hadoop. However, the community edition lacks some of the advanced features, enterprise-level security, and support found in the commercial Pentaho Data Integration version, which could be a limitation for larger organizations.</p>\n\n<p>In the context of data lakes, Kettle provides a versatile and affordable option for data ingestion and transformation. Its seamless integration with Hadoop and support for real-time and batch data processing make it ideal for building ETL pipelines for data lakes. Its graphical interface lowers the barrier to entry, allowing organizations to quickly set up data flows and transform raw data into a usable format for analytics.</p>','Ingestion','B','On-p',0,0.17,1,NULL,NULL,'An open-source ETL tool for integrating, cleansing, and transforming data using an intuitive drag-and-drop interface.\n\n','/logo_ingestion/pentaho.png','https://pentaho.com/products/pentaho-data-integration/'),(5,'Logstash','<p>Logstash, part of the Elastic Stack, was developed by Jordan Sissel in 2013 and has since become a widely used tool for collecting, parsing, and storing logs for future use. Its a server-side data processing tool that ingests data from various sources, transforms it, and sends it to a chosen destination, such as Elasticsearch. The pipeline capabilities of Logstash make it highly customizable and powerful for complex data processing tasks.</p> <p>One of the significant advantages of Logstash is its ability to handle various data formats, thanks to its rich plugin ecosystem. It provides built-in support for data transformation and filtering, which allows for data cleaning and enrichment before sending it to a storage or analysis engine. However, Logstash can be resource-intensive and may require careful configuration to optimize performance, particularly when dealing with high data volumes.</p> <p>As a data ingestion tool for data lakes, Logstash is valuable for its ability to normalize and structure incoming data streams. Its compatibility with cloud environments and data lakes ensures that organizations can process and store data efficiently for analytics and reporting. Its real-time data processing and enrichment capabilities make it a key component in modern data architectures.</p>','Ingestion','B/S','On-p',0,0.33,1,NULL,NULL,'A server-side data processing tool that ingests, transforms, and sends logs or event data to a chosen output.','/logo_ingestion/elasticco_logstash.svg','https://www.elastic.co/cn/logstash'),(6,'Fluentd','<p>Fluentd was created by Treasure Data in 2011 as a unified logging layer designed to simplify log data collection and distribution. It has since gained popularity in both small and large enterprises, with a strong emphasis on reliability and extensibility. As a part of the Cloud Native Computing Foundation (CNCF), Fluentd is often praised for being lightweight, versatile, and capable of handling high volumes of log data efficiently.</p> <p>One of Fluentds key advantages is its flexibility. With over 500 plugins, it can integrate with various data sources and outputs, making it an ideal choice for projects that require comprehensive log management and data transport. Fluentd also ensures data consistency through its robust buffering and failover mechanisms. However, for very large-scale deployments, configuring Fluentd optimally can become complicated, and performance may need fine-tuning to avoid resource overuse.</p> <p>In data lake environments, Fluentd provides a streamlined approach to ingesting and transforming data from numerous sources, including logs, metrics, and events. Its ability to unify logs from different sources and transform them into structured data is crucial for effective data lake management. Fluentd\'s capability to efficiently route and process data in real time makes it an essential component in modern data architectures.</p>','Ingestion','B/S','On-p',0,0.19,1,NULL,NULL,'A data collector that unifies the logging layer, allowing for seamless data collection and forwarding to various destinations.','/logo_ingestion/fluentd-icon.svg','https://www.fluentd.org/'),(7,'Filebeat','<p>Filebeat, developed by Elastic, is a lightweight data shipper that was designed to send log data to Elasticsearch or Logstash for further processing and analysis. It is part of the Elastic Stack and is often used to monitor and ship log files from servers to a central repository. Filebeat is known for its simplicity, low resource consumption, and ease of deployment, making it an attractive option for organizations looking for efficient log collection solutions.</p> <p>One of the standout advantages of Filebeat is its minimal resource usage, which allows it to run on even low-powered systems without affecting performance. Its designed to handle and deliver logs efficiently, with built-in reliability features like load balancing and backpressure handling. However, Filebeat is limited in its data processing capabilities and is usually used in conjunction with Logstash or Elasticsearch for more complex data transformations.</p> <p>In data lake scenarios, Filebeat is particularly useful for ingesting log data from distributed sources. Its lightweight nature ensures that it can be deployed widely across an infrastructure without burdening resources. By efficiently forwarding logs to a data lake, Filebeat plays a crucial role in ensuring that log data is collected, stored, and ready for analysis in a timely manner.</p>','Ingestion','B/S','On-p',0,0.44,0,NULL,NULL,'A lightweight log shipper for forwarding and centralizing log data, often used as part of the Elastic Stack.\n\n','/logo_ingestion/filebeats.png','https://www.elastic.co/cn/beats/filebeat'),(8,'Telegraf','<p>Telegraf is an open-source, server-based agent for collecting and reporting metrics. Created by InfluxData, it has grown to become a vital component of the TICK stack (Telegraf, InfluxDB, Chronograf, and Kapacitor). Telegraf is highly extensible and supports over 300 plugins, allowing it to collect data from numerous sources, including databases, servers, and IoT devices, and then send it to a variety of outputs.</p> <p>The key strength of Telegraf lies in its lightweight and efficient architecture, which makes it suitable for real-time data collection in large-scale deployments. Its vast array of input and output plugins enables easy integration with different data ecosystems. However, while it is excellent at metric collection, Telegrafs data processing capabilities are relatively basic compared to more feature-rich ETL tools.</p> <p>Within a data lake environment, Telegraf can be used to ingest real-time metrics, making it ideal for monitoring and data observability tasks. It provides a seamless way to gather metrics and events, ensuring that operational data is readily available in the data lake for analysis and reporting. Telegrafs performance and flexibility make it a valuable addition to data lake architectures, especially for time-series data ingestion.</p>','Ingestion','B/S','On-p',0,0.60,0,NULL,NULL,'An open-source agent for collecting and sending metrics and events from databases, systems, and IoT sensors.','/logo_ingestion/telegraf.png','https://www.influxdata.com/time-series-platform/telegraf/'),(9,'Debezium','<p>Debezium was developed as an open-source distributed platform for change data capture (CDC), built on top of Apache Kafka. It tracks database changes and streams them to Kafka topics in real time, enabling applications to react to data changes instantly. Debezium is used extensively in scenarios that require reliable and scalable data synchronization between databases and other systems.</p> <p>One of the primary advantages of Debezium is its ability to deliver low-latency change data capture while maintaining high availability and data consistency. It supports various relational databases, including MySQL, PostgreSQL, and MongoDB, making it a flexible solution for different environments. However, it can be complex to set up and configure, especially in distributed systems with stringent performance and security requirements.</p> <p>Debeziums real-time data streaming capabilities are invaluable for data lakes, as they enable efficient data ingestion directly from databases. By capturing and streaming data changes, Debezium ensures that data lakes remain up-to-date, making them a reliable source for data analytics. Its integration with Kafka allows seamless data movement, making it suitable for modern data lake architectures that require real-time insights.</p>','Ingestion','S','On-p',0,0.27,0,NULL,NULL,'A distributed platform for change data capture (CDC) that tracks database changes and streams them to applications in real time.','/logo_ingestion/debeziumio.svg','https://debezium.io/'),(10,'Maxwell\'s Daemon','<p>Maxwell\'s Daemon, or Maxwell, is a lightweight change data capture (CDC) tool for MySQL databases. It reads MySQL binlogs and outputs row-level updates as JSON to Kafka, Kinesis, or other systems. Developed to simplify the CDC process, Maxwell is designed to be easy to deploy and operate, with minimal overhead compared to more comprehensive solutions.</p> <p>Maxwells strength lies in its simplicity and efficiency. It offers a straightforward way to stream MySQL database changes to external systems in near real time. However, Maxwell lacks some advanced features, like support for complex data transformations or multi-database compatibility, which may limit its use in more sophisticated environments.</p> <p>For data lakes, Maxwell provides a quick and efficient way to ingest change data from MySQL databases. Its ability to capture and stream data changes ensures that data lakes are always updated with the latest information. This makes Maxwell suitable for organizations looking to maintain a current and reliable data lake without investing in more complex CDC solutions.</p>','Ingestion','S','On-p',0,0.04,0,NULL,NULL,'A lightweight CDC tool that reads MySQL binlogs and outputs row updates as JSON to Kafka, Kinesis, or other systems.\n\n',NULL,'https://maxwells-daemon.io/'),(11,'Oracle GoldenGate Free','<p>Oracle GoldenGate is a comprehensive data replication and change data capture (CDC) solution developed by Oracle Corporation. The free version provides essential features for data replication and real-time data movement, making it a popular choice among Oracle database users. It enables organizations to replicate data between Oracle databases or from Oracle to non-Oracle systems efficiently.</p> <p>GoldenGate is known for its robustness, high performance, and ability to handle large-scale data replication scenarios. It provides advanced features like automatic conflict resolution and data transformation. However, the free version is limited in terms of supported platforms and advanced functionalities compared to the full enterprise edition. Additionally, GoldenGates setup and configuration can be complex for new users.</p> <p>In a data lake context, Oracle GoldenGate Free is valuable for replicating and ingesting data from Oracle databases. Its real-time data capture ensures that data lakes receive continuous updates, which is crucial for maintaining data accuracy. The tools integration capabilities make it an essential asset for organizations heavily reliant on Oracle ecosystems.</p>','Ingestion','S','On-p',0,0.00,0,NULL,NULL,'A free version of Oracle GoldenGate, providing data replication and real-time change data capture for Oracle databases.\n\n','/logo_ingestion/oracle.png','https://www.oracle.com/middleware/technologies/goldengate.html'),(12,'Pentaho Data Integration(a.k.a Kettle) - enterprise','<p>Pentaho Data Integration (Kettle) Enterprise Edition is the commercial version of the popular open-source ETL tool. It provides a comprehensive suite of features, including advanced data governance, security, and support. Developed by Hitachi Vantara, Pentaho has evolved to become a robust data integration platform, catering to the needs of large enterprises.</p> <p>The enterprise version offers several advantages, such as improved scalability, enhanced performance optimization, and dedicated customer support. It also provides integration with big data platforms like Hadoop and the ability to run ETL jobs natively within these environments. On the downside, the enterprise edition comes with licensing costs, which can be a consideration for budget-constrained organizations.</p> <p>In data lake environments, Pentaho Enterprise excels at automating complex ETL workflows and preparing data for analysis. Its integration capabilities with big data ecosystems ensure efficient data ingestion and transformation, while its user-friendly interface simplifies job design. The tool is ideal for organizations looking to manage large-scale data operations seamlessly.</p>','Ingestion','B/S','On-p',1,0.00,1,NULL,NULL,'A comprehensive, enterprise-grade ETL tool offering advanced data integration, governance, and security features.\n\n','/logo_ingestion/pentaho.png','https://pentaho.com/products/pentaho-data-integration/'),(13,'StreamSets Data Collector','<p>StreamSets Data Collector, developed by StreamSets, is an open-source data ingestion engine designed to simplify data integration across various environments. It was created to address the challenges of managing data flow pipelines in dynamic environments. With an intuitive UI and real-time monitoring capabilities, StreamSets has become a preferred choice for modern data operations.</p> <p>One of its key strengths is the ability to detect and handle data drift, making it highly reliable in environments where data structures change frequently. StreamSets supports a wide range of data sources and destinations, offering built-in connectors for popular data platforms. However, it may require significant resources for large-scale deployments, and performance tuning can be complex for high-volume data flows.</p> <p>As a data ingestion tool for data lakes, StreamSets shines with its ability to create and manage data pipelines efficiently. Its visual interface simplifies the process of data ingestion, transformation, and delivery. Real-time monitoring and error handling ensure data reliability, making StreamSets an excellent choice for dynamic data lake architectures.</p>','Ingestion','B/S','On-p',1,0.00,1,NULL,NULL,'A data ingestion engine that enables real-time data collection, transformation, and monitoring from multiple sources.','/logo_ingestion/streamSets.png','https://streamsets.com/products/dataops-platform/data-collector/'),(14,'Talend Data Fabric','<p>Talend Data Fabric is a comprehensive data integration and management platform developed by Talend. It offers a unified suite of tools for data integration, data quality, governance, and cloud data management. Talend\'s open-source roots, combined with its commercial offerings, have made it a leading choice for organizations looking to streamline their data operations.</p> <p>Talend Data Fabrics strengths include its intuitive design environment, extensive built-in connectors, and support for both batch and real-time data integration. It also provides robust data quality and governance features, ensuring that data remains clean and reliable. However, Talends licensing and costs can be prohibitive for smaller organizations, and the platform may require a learning curve for new users.</p> <p>In data lake architectures, Talend Data Fabrics ability to handle large volumes of data from various sources is a significant advantage. Its support for cloud and on-premises environments makes it flexible for diverse data lake implementations. By automating data ingestion and cleansing, Talend ensures that data lakes are populated with high-quality, analytics-ready data.</p>\n\n\n\n\n\n\n','Ingestion','B/S','On-p',1,0.00,1,NULL,NULL,'A comprehensive data integration platform offering real-time and batch data processing with data quality, governance, and cloud support.','/logo_ingestion/talend.png','https://www.talend.com/products/data-fabric/'),(15,'Informatica Data Integration & Engineering','<p>Informatica Data Integration & Engineering is a comprehensive data management platform designed to handle big data processing and integration at an enterprise scale. Informatica, founded in 1993, has long been a leader in data integration solutions, and its big data offerings have evolved to meet the demands of modern data environments. The platform is known for its sophisticated data governance, data quality, and real-time processing capabilities.</p> <p>One of the standout features of Informatica Data Integration & Engineering is its ability to process massive volumes of data seamlessly, whether on-premises or in the cloud. The platform\'s advanced data transformation tools and pre-built connectors simplify the integration of disparate data sources into a unified environment. However, Informatica can be resource-intensive, and the learning curve for its complex features may be steep, especially for new users or smaller teams.</p> <p>In the realm of data lakes, Informatica proves highly advantageous for its robust ETL and data quality management. Its ability to ingest data from various sources and ensure data integrity makes it ideal for organizations looking to populate data lakes with accurate and reliable data. Additionally, Informaticas scalability and integration with major cloud platforms make it a strong choice for hybrid or multi-cloud data lake architectures.</p>','Ingestion','B/S','On-p',1,0.00,1,NULL,NULL,'A powerful data integration tool providing advanced data management and ETL capabilities for big data environments.','/logo_ingestion/informatica-icon.svg','https://www.informatica.com/products/data-integration.html'),(16,'AWS Glue','<p>AWS Glue, introduced by Amazon Web Services in 2017, is a fully managed ETL (Extract, Transform, Load) service designed to simplify and automate data preparation for analytics. Built to work seamlessly with AWS data services, AWS Glue can automatically discover and catalog data, transform it, and make it queryable using Amazon Athena, Redshift, or other data lake services. Its serverless nature eliminates the need for infrastructure management, making it an attractive option for data engineers and analysts.</p> <p>The main advantage of AWS Glue lies in its integration with the AWS ecosystem, which simplifies data processing workflows and enables quick and efficient data transformations. The built-in Glue Data Catalog provides a centralized metadata repository, enhancing data governance and searchability. However, AWS Glues dependency on the AWS ecosystem may be a limitation for organizations using a multi-cloud strategy, and its pricing model could become costly for large-scale data processing tasks.</p> <p>In a data lake environment, AWS Glue excels by automating data ingestion and transformation tasks. Its serverless design ensures scalability and cost-efficiency, while features like job scheduling and event-driven triggers make it suitable for real-time data lakes. AWS Glues ability to seamlessly connect with other AWS data services makes it a core component in modern data lake architectures, ensuring that data is ready for analysis as soon as its ingested.</p>','Ingestion','B','Cloud',1,0.00,NULL,0,0,'A fully managed ETL service that simplifies the process of discovering, preparing, and integrating data for analytics and machine learning.','/logo_ingestion/aws_Glue.png','https://aws.amazon.com/cn/glue/'),(18,'Microsoft Azure Data Factory','<p>Microsoft Azure Data Factory (ADF) is a fully managed, cloud-based data integration service developed by Microsoft. Launched in 2015, Azure Data Factory is designed to orchestrate and automate data movement and transformation workflows across on-premises and cloud-based systems. With its visual interface and rich set of data connectors, ADF simplifies the process of building and managing ETL and ELT pipelines.</p> <p>Azure Data Factorys strengths lie in its native integration with the Microsoft Azure ecosystem and its ability to handle complex data workflows. It supports hybrid data integration, which is crucial for organizations with both on-premises and cloud data. The visual interface makes designing data pipelines more accessible, even for those without extensive coding experience. However, ADF can become complex when dealing with highly customized data transformations, and its pricing model may not be cost-effective for smaller projects.</p> <p>In data lake scenarios, Azure Data Factory provides a seamless way to ingest and transform data from diverse sources. Its flexibility to work with structured, semi-structured, and unstructured data ensures that data lakes are populated with a wide variety of data formats. Furthermore, its ability to trigger data flows based on events or schedules makes it a powerful tool for maintaining an up-to-date and reliable data lake environment.</p>\n\n\n\n\n\n','Ingestion','B','Cloud',1,0.00,NULL,NULL,NULL,'A cloud-based data integration service for orchestrating and automating data movement and transformation workflows.','/logo_ingestion/microsoft_Azure_Data_Factory.png','https://azure.microsoft.com/zh-cn/services/data-factory/'),(19,'Google Cloud Data Fusion','<p>Google Cloud Data Fusion, launched by Google Cloud, is a fully managed, cloud-native data integration service that simplifies ETL and ELT processes with a visual interface. It is built on the open-source CDAP (Cask Data Application Platform) and provides an intuitive, drag-and-drop experience for designing complex data pipelines. Data Fusion is aimed at accelerating data-driven decision-making by reducing the time and complexity of data integration.</p> <p>One of the major benefits of Google Cloud Data Fusion is its seamless integration with Google Cloud services, such as BigQuery and Google Cloud Storage. It supports both batch and real-time data processing, making it versatile for various data ingestion scenarios. However, for organizations not using Google Cloud as their primary platform, Data Fusion\'s integration may be limited. Additionally, while the visual interface simplifies pipeline design, it may not be as customizable as code-based solutions for advanced use cases.</p> <p>In a data lake environment, Google Cloud Data Fusion shines with its ability to ingest and transform data from numerous sources efficiently. Its support for both real-time and batch data integration ensures that data lakes remain updated and ready for analytics. The platforms robust data transformation features and tight integration with Google Clouds data services make it a key player for organizations leveraging Google Cloud for their data lake infrastructure.</p>','Ingestion','B','Cloud',1,0.00,NULL,NULL,NULL,'A fully managed, cloud-native data integration service that makes ETL and ELT design and implementation easy with a visual interface.','/logo_ingestion/google_Cloud_Data_Fusion.png','https://cloud.google.com/data-fusion'),(20,'Alibaba Data Integration','<p>Alibaba Data Integration is part of Alibaba Clouds data processing suite, designed to facilitate seamless data migration and integration across multiple platforms. It supports both batch and real-time data processing and is particularly optimized for use within the Alibaba Cloud ecosystem. With built-in connectors for a wide range of data sources, it allows organizations to move and transform data efficiently.</p> <p>One of Alibaba Data Integrations advantages is its deep integration with other Alibaba Cloud services, making it highly effective for users already invested in the Alibaba ecosystem. The platform offers robust data transformation and scheduling features, suitable for both simple and complex data pipelines. However, its primary drawback is its dependency on Alibaba Cloud services, which may limit its adoption for organizations with a multi-cloud strategy or those based outside regions where Alibaba Cloud is prominent.</p> <p>For data lake architectures, Alibaba Data Integration provides a powerful solution for ingesting data from diverse sources. Its ability to handle both structured and unstructured data makes it ideal for populating data lakes with various data types. The services scalability and integration capabilities ensure that data lakes are fed continuously and efficiently, supporting advanced analytics and reporting needs.</p>\n\n\n\n\n\n','Ingestion','B/S','Cloud',1,0.00,NULL,NULL,NULL,'A tool for data migration and integration, supporting both batch and real-time data processing within Alibaba Cloud services.','/logo_ingestion/alibabacloud.svg','https://www.aliyun.com/product/di'),(21,'Amazon Kinesis','<p>Amazon Kinesis, part of the AWS suite of data services, was launched to enable real-time data streaming and processing at scale. It is designed to handle large streams of data, such as log events, IoT telemetry, and social media feeds, and can integrate seamlessly with other AWS services for data storage and analytics. With Amazon Kinesis, organizations can build applications that process and analyze data as it arrives, rather than waiting for batch processing.</p> <p>The strengths of Amazon Kinesis lie in its ability to scale easily and its support for real-time processing, which is crucial for time-sensitive data analytics. Kinesis Streams, Kinesis Firehose, and Kinesis Analytics provide a comprehensive set of tools to collect, process, and load streaming data. However, one of the limitations is the complexity involved in setting up and managing streaming applications, and costs can add up quickly for high-throughput use cases.</p> <p>In a data lake context, Amazon Kinesis is highly effective for real-time data ingestion. Its ability to stream data directly into data lakes, such as those built on Amazon S3, ensures that data is immediately available for analytics. This is particularly valuable for scenarios like monitoring, real-time reporting, and machine learning, where up-to-date data is critical.</p>\n\n\n\n\n\n','Ingestion','S','Cloud',1,0.00,NULL,NULL,NULL,'A real-time data streaming service that enables scalable data ingestion and processing for analytics and application monitoring.','/logo_ingestion/amazon_Kinesis.png','https://aws.amazon.com/cn/kinesis/'),(22,'Microsoft Azure Event Hubs','<p>Microsoft Azure Event Hubs is a real-time event ingestion service that can capture and process millions of events per second. It was developed to provide a scalable and reliable solution for event streaming in the Microsoft Azure ecosystem. Event Hubs can ingest data from a variety of sources, such as applications, sensors, and telemetry, and then process or store the data for further analysis.</p> <p>One of the major advantages of Azure Event Hubs is its scalability, which allows it to handle large volumes of event data effortlessly. Its integration with Azure services, such as Azure Stream Analytics and Azure Functions, provides a complete data processing pipeline. However, Event Hubs can become costly for sustained high-volume data streams, and integrating it with non-Azure services may require additional effort.</p> <p>In data lake architectures, Azure Event Hubs plays a vital role by providing real-time data ingestion capabilities. It is well-suited for scenarios where time-sensitive data, such as telemetry or log events, needs to be ingested quickly and efficiently. By streaming events into data lakes, Azure Event Hubs ensures that data is always fresh and ready for processing, supporting advanced analytics and machine learning use cases.</p>','Ingestion','S','Cloud',1,0.00,NULL,NULL,NULL,'A real-time event ingestion service that can process millions of events per second for analytics and data streaming scenarios.','/logo_ingestion/microsoft_Azure_Event_Hubs.png','https://azure.microsoft.com/zh-cn/services/event-hubs/'),(23,'Google Dataflow','<p>Google Dataflow is a fully managed service for real-time and batch data processing, based on Apache Beam. It was launched by Google Cloud to simplify the development and management of data pipelines. Dataflows unified programming model allows developers to write data processing jobs in Java or Python and run them without worrying about infrastructure management.</p> <p>Dataflows key advantages include its ability to autoscale and its integration with the Google Cloud ecosystem, which makes data processing seamless and efficient. It provides advanced features such as windowed computations, sessionization, and built-in data transformations, making it powerful for stream and batch processing. However, as with other managed services, there can be cost considerations, especially for long-running or high-throughput jobs.</p> <p>In the context of a data lake, Google Dataflow is ideal for ingesting and transforming data in real time. Its ability to process data as it arrives ensures that data lakes remain current and valuable for downstream analytics. The integration with Google Clouds storage and data analytics tools further enhances its effectiveness, making it a preferred choice for organizations relying on the Google Cloud Platform.</p>','Ingestion','B/S','Cloud',1,0.00,NULL,NULL,NULL,'A fully managed service for real-time and batch data processing, based on Apache Beam, ideal for scalable data transformation and analytics.','/logo_ingestion/google_Dataflow.png','https://cloud.google.com/dataflow'),(24,'Apache Spark','<p>Apache Spark was developed at UC Berkeley\'s AMPLab and later became an open-source project under the Apache Software Foundation. It is a fast and general-purpose cluster computing system designed for big data processing. Spark provides an interface for programming entire clusters with implicit data parallelism and fault tolerance.</p> <p>Spark\'s main strengths are its speed and ease of use. It can process data up to 100 times faster than Hadoop MapReduce in memory and up to 10 times faster on disk. Spark supports multiple programming languages like Java, Scala, Python, and R, making it accessible to a wide range of developers. However, Spark can consume significant memory and resources, which may lead to higher operational costs. It also requires a learning curve for those unfamiliar with distributed computing paradigms.</p> <p>In data lake environments, Apache Spark excels at processing large volumes of data for analytics, machine learning, and real-time stream processing. Its ability to handle both batch and streaming data makes it a versatile tool for data lakes, where diverse data types and processing requirements are common. Spark\'s integration with Hadoop ecosystems and cloud services enhances its utility in building scalable and efficient data lake architectures.</p>','Preparation','B/S','On-p',0,1.00,NULL,NULL,NULL,'An open-source distributed computing system optimized for big data processing, known for its in-memory data processing and support for batch and stream processing.','/logo_preparation/spark.png','https://spark.apache.org/'),(25,'Apache Flink','<p>Apache Flink is an open-source stream-processing framework developed by the Apache Software Foundation. It was designed to provide high-throughput and low-latency data processing, capable of handling both batch and real-time streaming data. Flink\'s stateful computations over data streams make it a powerful tool for complex event processing and real-time analytics.</p> <p>One of Flink\'s key strengths is its true streaming model, which processes data as unbounded streams, offering better performance and lower latency than micro-batch processing models. It provides exactly-once state consistency and fault tolerance, essential for critical data applications. However, Flink can be complex to set up and requires expertise to optimize and maintain, especially in large-scale deployments.</p> <p>In data lake scenarios, Apache Flink is valuable for ingesting and processing streaming data in real time. Its capabilities allow organizations to perform complex transformations and analytics on incoming data before it\'s stored in the data lake. This ensures that data lakes are populated with enriched and ready-to-use data, enhancing the effectiveness of downstream analytics and machine learning tasks.</p>','Preparation','B/S','On-p',0,0.54,NULL,NULL,NULL,'A powerful, open-source stream-processing framework for distributed, high-performing, and real-time data processing with fault-tolerance and scalability.','/logo_preparation/flink.png','https://flink.apache.org/'),(26,'Map Reduce','<p>MapReduce is a programming model and associated implementation developed by Google for processing large data sets with a distributed algorithm on a cluster. Introduced in 2004, it became the core component of Apache Hadoop. MapReduce simplifies data processing across massive clusters by breaking down tasks into map and reduce functions.</p> <p>The primary advantage of MapReduce is its scalability and simplicity in handling large-scale data processing tasks. It allows for parallel processing over distributed systems, making it effective for batch processing of big data. However, MapReduce has limitations in terms of processing speed and real-time capabilities. Its disk-based processing can lead to higher latency compared to in-memory processing frameworks like Spark.</p> <p>In data lake environments, MapReduce serves as a foundational tool for batch data processing and transformation. It can be used to preprocess large data sets before they are stored in the data lake or to perform analytics on data residing within the lake. While newer technologies offer faster processing, MapReduce remains a reliable choice for certain batch processing tasks in data lakes.</p>','Preparation','B','On-p',0,0.30,NULL,NULL,NULL,'A programming model and processing engine for large-scale data processing that distributes tasks across a cluster, used primarily in Hadoop ecosystems.','/logo_preparation/mapreduce.png','https://hadoop.apache.org/'),(27,'Apache Storm','<p>Apache Storm, originally developed by BackType and later acquired by Twitter, is a distributed real-time computation system for processing large streams of data. It was designed to be scalable, fault-tolerant, and easy to set up and operate. Storm allows developers to build applications that need to process data in real time, such as analytics, machine learning, and data transformation tasks.</p> <p>The main strength of Apache Storm is its capability to process data streams with low latency, making it suitable for time-sensitive applications. It supports multiple programming languages and integrates well with existing queuing and database technologies. However, Storm can be complex to manage, and its performance may not match newer stream-processing frameworks like Flink or Spark Streaming in terms of throughput and latency.</p> <p>In data lake architectures, Apache Storm can be utilized to ingest and process streaming data in real time before it enters the data lake. By performing transformations and analytics on the fly, Storm ensures that the data stored in the data lake is immediately useful for downstream applications. This real-time processing capability enhances the value of data lakes in scenarios where up-to-date information is critical.</p>','Preparation','S','On-p',0,0.13,NULL,NULL,NULL,'A distributed real-time computation system that processes unbounded streams of data quickly and reliably, often used for streaming analytics and complex event processing.','/logo_preparation/storm.png','https://storm.apache.org/'),(28,'Apache Samza','<p>Apache Samza was developed by LinkedIn and later became an Apache Software Foundation project. It is a distributed stream processing framework that uses Apache Kafka for messaging and Apache Hadoop YARN for resource management. Samza was designed to simplify the process of building stateful applications that process real-time data streams.</p> <p>Samza\'s strengths include its strong integration with Kafka, fault tolerance, and support for stateful stream processing. It allows developers to write scalable and resilient stream-processing applications with relative ease. However, Samza may not be as flexible or feature-rich as other stream-processing frameworks like Flink or Spark Streaming, and it relies heavily on the Kafka ecosystem.</p> <p>In the context of data lakes, Apache Samza can be used to process and transform streaming data before it is ingested. Its ability to handle stateful computations ensures that complex transformations and aggregations can be performed in real time. This enhances the quality and readiness of data entering the data lake, making it more valuable for analytics and reporting purposes.</p>','Preparation','S','On-p',0,0.00,NULL,NULL,NULL,'A distributed stream processing framework that provides real-time, asynchronous data processing, designed to handle large-scale data with integration to Apache Kafka.','/logo_preparation/samza.png','https://samza.apache.org/'),(29,'Amazon EMR','<p>Amazon EMR (Elastic MapReduce) is a cloud-based big data platform provided by Amazon Web Services. Launched in 2009, EMR simplifies running big data frameworks like Apache Hadoop and Apache Spark on AWS to process vast amounts of data. It provides a managed cluster platform that scales according to processing needs, reducing the operational burden of managing big data infrastructure.</p> <p>The key advantages of Amazon EMR are its scalability, flexibility, and integration with other AWS services. It allows users to spin up clusters quickly, pay only for what they use, and integrate with data stored in Amazon S3 or other AWS data stores. However, EMR can become costly if not managed properly, and there may be a learning curve associated with configuring and optimizing clusters for specific workloads.</p> <p>In data lake environments, Amazon EMR is instrumental for processing and analyzing large data sets stored in data lakes. It enables users to run complex analytics, machine learning models, and data transformations efficiently. By leveraging EMR, organizations can process data within their data lake without the need for on-premises infrastructure, benefiting from the scalability and flexibility of the cloud.</p>','Preparation','B/S','Cloud',1,0.00,NULL,1,0,'A cloud-based big data platform from AWS that simplifies running large-scale data processing frameworks like Hadoop, Spark, and Presto on Amazon\'s infrastructure.','/logo_preparation/amazon_emr.png','https://aws.amazon.com/cn/emr/'),(30,'AWS Lambda','<p>AWS Lambda is a serverless compute service provided by Amazon Web Services that lets you run code without provisioning or managing servers. Introduced in 2014, Lambda executes code only when needed and scales automatically, making it cost-effective for intermittent workloads. Developers can write functions in various languages, and Lambda handles the execution and resource management.</p> <p>The primary strength of AWS Lambda is its serverless architecture, which eliminates the need for infrastructure management and allows for rapid development and deployment. It is ideal for event-driven applications and can be triggered by various AWS services. However, Lambda has limitations on execution time and resource allocation, which may not be suitable for long-running or resource-intensive tasks.</p> <p>In data lake architectures, AWS Lambda can be used to process data in real time as it arrives in the data lake. For example, Lambda functions can be triggered by events in Amazon S3 to perform data validation, transformation, or indexing. This enables organizations to maintain an up-to-date and well-structured data lake without managing additional compute resources.</p>','Preparation','B/S','Cloud',1,0.00,NULL,0,1,'A serverless computing service by AWS that runs code in response to events, managing compute resources automatically, ideal for building scalable, event-driven applications.','/logo_preparation/amazon_lambda.png','https://aws.amazon.com/cn/lambda/'),(31,'Microsoft Azure Data Factory','<p>Microsoft Azure Data Factory is a fully managed, cloud-based data integration service developed by Microsoft. Launched in 2015, Azure Data Factory is designed to orchestrate and automate data movement and transformation workflows across on-premises and cloud-based systems. With its visual interface and rich set of data connectors, ADF simplifies the process of building and managing ETL and ELT pipelines.</p> <p>Azure Data Factorys strengths lie in its native integration with the Microsoft Azure ecosystem and its ability to handle complex data workflows. It supports hybrid data integration, which is crucial for organizations with both on-premises and cloud data. The visual interface makes designing data pipelines more accessible, even for those without extensive coding experience. However, ADF can become complex when dealing with highly customized data transformations, and its pricing model may not be cost-effective for smaller projects.</p> <p>In data lake scenarios, Azure Data Factory provides a seamless way to ingest and transform data from diverse sources. Its flexibility to work with structured, semi-structured, and unstructured data ensures that data lakes are populated with a wide variety of data formats. Furthermore, its ability to trigger data flows based on events or schedules makes it a powerful tool for maintaining an up-to-date and reliable data lake environment.</p>','Preparation','B','Cloud',1,0.00,NULL,0,0,'A cloud-based data integration service for creating ETL and ELT workflows, orchestrating data movement and transformation across diverse data stores.','/logo_preparation/microsoft_Azure_Data_Factory.png','https://azure.microsoft.com/zh-cn/services/data-factory/'),(32,'Microsoft Azure Databricks','<p>Microsoft Azure Databricks is a collaborative, Apache Spark-based analytics platform optimized for the Microsoft Azure cloud services platform. Developed in partnership between Microsoft and Databricks, it was designed to make big data and AI simple for organizations. Azure Databricks combines the best of Databricks and Azure to help customers accelerate innovation with one-click setup, streamlined workflows, and an interactive workspace.</p> <p>The key strengths of Azure Databricks include its high-performance Spark engine, collaborative notebooks, and seamless integration with Azure services like Azure Data Lake Storage, Azure Machine Learning, and Power BI. It simplifies the development of big data and AI solutions. However, the platform can be complex for users unfamiliar with Spark or Databricks, and costs can escalate with increased usage without proper management.</p> <p>In data lake environments, Azure Databricks is highly effective for processing and analyzing large volumes of data. It enables data engineers and scientists to build end-to-end data pipelines, from data ingestion to advanced analytics and machine learning, all within a unified workspace. Its integration with Azure Data Lake Storage ensures efficient data access and management, enhancing the overall utility of the data lake.</p>','Preparation','B/S','Cloud',1,0.00,NULL,1,0,'A fast, easy, and collaborative Apache Spark-based analytics service designed for data engineering, data science, and machine learning on Azure.','/logo_preparation/azure_databricks.svg','https://azure.microsoft.com/zh-cn/services/databricks/'),(33,'Microsoft Azure Functions','<p>Microsoft Azure Functions is a serverless compute service that allows developers to run code on-demand without provisioning infrastructure. Introduced by Microsoft Azure, it supports various programming languages and is designed for event-driven applications. Azure Functions scales automatically based on workload, making it cost-effective for intermittent tasks.</p> <p>The main advantages of Azure Functions include ease of development, automatic scaling, and tight integration with Azure services. It enables rapid development of small pieces of code that respond to cloud events. However, similar to other serverless platforms, it has limitations on execution time and resources, which may not be suitable for long-running or compute-intensive tasks.</p> <p>In the context of data lakes, Azure Functions can be used to process data as it arrives. For example, when a file is uploaded to Azure Data Lake Storage, an Azure Function can be triggered to validate, transform, or enrich the data before it\'s consumed by downstream applications. This serverless approach simplifies data processing workflows and reduces operational overhead.</p>','Preparation','B/S','Cloud',1,0.00,NULL,0,1,'A serverless compute service that enables event-driven code execution, allowing developers to run small pieces of code without managing infrastructure.','/logo_preparation/azure_functions.png','https://azure.microsoft.com/zh-cn/services/functions/'),(34,'Trino','<p>Trino, formerly known as PrestoSQL, is a distributed SQL query engine designed for fast analytics on large datasets. Initially developed by Facebook, it was created to run interactive analytic queries against data sources of all sizes. Trino allows users to query data where it resides, without needing to move it into a specialized analytics system.</p> <p>The strengths of Trino include its speed, scalability, and ability to query data from various sources, including Hadoop, NoSQL databases, and cloud storage. It supports standard SQL, making it accessible to users familiar with SQL querying. However, Trino can be complex to configure and optimize, and performance may vary depending on the data sources and query patterns.</p> <p>In data lake environments, Trino serves as a powerful query engine that allows users to perform ad-hoc queries across data stored in the lake. Its ability to query data in place reduces the need for data movement, accelerating time-to-insight. This makes Trino an essential tool for organizations seeking to analyze large datasets efficiently within their data lake.</p>','Analysis','B','On-p',0,1.00,NULL,NULL,NULL,'A distributed SQL query engine designed for fast analytics on large datasets across multiple data sources, formerly known as PrestoSQL.','/logo_analysis/trino.png','https://trino.io/'),(35,'Apache Drill','<p>Apache Drill is an open-source SQL query engine for big data exploration. Developed under the Apache Software Foundation, Drill is designed to handle large-scale data, including structured and semi-structured data, without the need for a traditional schema. It supports querying data directly from sources like Hadoop, NoSQL databases, and cloud storage services.</p> <p>The key advantage of Apache Drill is its schema-free JSON model, which allows for querying complex, nested data structures without predefined schemas. It offers flexibility and ease of use for data exploration tasks. However, Drill may not perform as well as other engines for certain types of queries, and its community support is smaller compared to more widely adopted tools.</p> <p>In data lake scenarios, Apache Drill provides a valuable means of querying diverse data types without extensive data preparation. Its ability to query data in place makes it suitable for exploratory analytics in data lakes, where data may come from various sources and formats. This accelerates the data discovery process and aids in deriving insights from raw data.</p>','Analysis','B','On-p',0,0.40,NULL,NULL,NULL,'A low-latency distributed query engine for large-scale datasets, supporting SQL queries on structured and semi-structured data without requiring schemas.','/logo_analysis/drill.png','https://drill.apache.org/'),(36,'Apache Hive','<p>Apache Hive is a data warehouse software project built on top of Apache Hadoop for providing data query and analysis. Developed by Facebook and later open-sourced, Hive allows users to write SQL-like queries called HiveQL to process large datasets stored in Hadoop\'s HDFS. It translates these queries into MapReduce jobs, simplifying big data analytics for users familiar with SQL.</p> <p>Hive\'s strengths lie in its scalability and ability to handle large datasets efficiently. It integrates well with the Hadoop ecosystem and supports complex analytics and data summarization tasks. However, Hive\'s reliance on MapReduce can result in higher query latency, making it less suitable for real-time analytics compared to newer technologies.</p> <p>In data lake environments, Apache Hive is often used as a metastore and query engine to manage and query data stored within the lake. It enables organizations to leverage SQL skills to perform analytics on big data, facilitating data warehousing capabilities within the data lake. Hive\'s compatibility with various data formats enhances its utility in diverse data lake architectures.</p>','Analysis','B','On-p',0,0.28,NULL,NULL,NULL,'A data warehouse infrastructure built on Hadoop, providing an SQL-like interface for querying and analyzing large datasets stored in the Hadoop ecosystem.','/logo_analysis/hive.png','https://hive.apache.org/'),(37,'Apache Pig','<p>Apache Pig is a high-level platform for creating programs that run on Apache Hadoop. Developed at Yahoo!, Pig uses a language called Pig Latin, which allows for the processing and analysis of large data sets with ease. Pig simplifies coding by providing operators for common data operations like join, sort, and filter, abstracting the underlying MapReduce jobs.</p> <p>The primary advantage of Apache Pig is its ability to simplify complex data transformations and processing tasks. It reduces the amount of code needed compared to writing raw MapReduce jobs. However, Pig has largely been superseded by more modern frameworks like Spark and Hive, which offer better performance and more features. Pig\'s usage has declined as these newer tools have gained popularity.</p> <p>In data lake contexts, Apache Pig can be used for batch processing and data transformation tasks. It helps in preparing data for analysis by performing ETL operations within the data lake. While it may not be the first choice for new projects, Pig can still be valuable in environments where it is already in use or where its specific capabilities are needed.</p>','Analysis','B','On-p',0,0.08,NULL,NULL,NULL,'A high-level platform for processing large data sets using a scripting language called Pig Latin, simplifying the coding required for MapReduce programming.','/logo_analysis/pig.png','https://pig.apache.org/'),(38,'Apache Flink','<p>Apache Flink is an open-source stream-processing framework developed by the Apache Software Foundation. It was designed to provide high-throughput and low-latency data processing, capable of handling both batch and real-time streaming data. Flink\'s stateful computations over data streams make it a powerful tool for complex event processing and real-time analytics.</p> <p>One of Flink\'s key strengths is its true streaming model, which processes data as unbounded streams, offering better performance and lower latency than micro-batch processing models. It provides exactly-once state consistency and fault tolerance, essential for critical data applications. However, Flink can be complex to set up and requires expertise to optimize and maintain, especially in large-scale deployments.</p> <p>In data lake scenarios, Apache Flink is valuable for ingesting and processing streaming data in real time. Its capabilities allow organizations to perform complex transformations and analytics on incoming data before it\'s stored in the data lake. This ensures that data lakes are populated with enriched and ready-to-use data, enhancing the effectiveness of downstream analytics and machine learning tasks.</p>','Analysis','S','On-p',0,0.00,NULL,NULL,NULL,'A robust, open-source stream-processing framework for distributed, high-performing, real-time, and batch data processing with low latency and scalability.','/logo_analysis/flink.png','https://flink.apache.org/'),(39,'AWS Athena','<p>AWS Athena is an interactive query service provided by Amazon Web Services that allows users to analyze data in Amazon S3 using standard SQL. Launched in 2016, Athena is serverless, meaning there is no infrastructure to manage, and users pay only for the queries they run. It is built on Presto and works with various data formats, including CSV, JSON, ORC, and Parquet.</p> <p>The strengths of AWS Athena include its ease of use, scalability, and cost-effectiveness for querying data stored in S3. It integrates seamlessly with AWS Glue Data Catalog, enhancing data discovery and management. However, Athena may have limitations with complex queries or very large datasets, where performance can be affected. Additionally, costs can increase with extensive querying.</p> <p>In data lake architectures, AWS Athena provides a straightforward way to query and analyze data without the need for setting up and managing query infrastructure. It enables users to perform ad-hoc analysis directly on data stored in the data lake, accelerating insights and supporting data-driven decision-making. Athena\'s serverless nature and SQL compatibility make it accessible to a wide range of users.</p>','Analysis','B/S','Cloud',1,0.00,NULL,NULL,NULL,'An interactive query service that uses standard SQL to analyze data directly in Amazon S3, serverless and easy to use for data analysis.','/logo_analysis/athena.png','https://aws.amazon.com/cn/athena/'),(40,'Google BigQuery','<p>Google BigQuery is a serverless, highly scalable, and cost-effective cloud data warehouse offered by Google Cloud. Launched in 2011, BigQuery allows users to run super-fast SQL queries on multi-terabyte datasets in seconds. It is designed to make data analysis accessible and straightforward, without the need for managing infrastructure.</p> <p>The key advantages of BigQuery include its speed, scalability, and integration with other Google Cloud services. It supports standard SQL and offers features like machine learning capabilities within the database. However, BigQuery\'s pricing model can be complex, and costs may escalate with large volumes of data and frequent querying. There may also be limitations in terms of real-time data processing compared to other streaming services.</p> <p>In data lake environments, Google BigQuery serves as a powerful analytics engine that can query data stored in Google Cloud Storage or within BigQuery itself. It allows organizations to analyze vast amounts of data quickly, supporting advanced analytics and business intelligence tasks. Its serverless architecture simplifies data management and accelerates time-to-insight.</p>','Analysis','B/S','Cloud',1,0.00,NULL,NULL,NULL,'A fully-managed, serverless data warehouse that enables super-fast SQL queries using Googles infrastructure, optimized for large-scale data analytics.','/logo_analysis/bigquery.png','https://cloud.google.com/bigquery'),(41,'Azure Synapse Analystics','<p>Azure Synapse Analytics is an integrated analytics service offered by Microsoft Azure that brings together data integration, enterprise data warehousing, and big data analytics. Formerly known as Azure SQL Data Warehouse, Synapse Analytics provides a unified experience to ingest, prepare, manage, and serve data for immediate business intelligence and machine learning needs.</p> <p>The strengths of Azure Synapse Analytics include its deep integration with the Azure ecosystem, scalability, and support for both SQL and Spark engines. It enables collaborative work between data engineers and data scientists, supporting various analytics workloads. However, the complexity of the platform may present a learning curve, and costs can increase with extensive use and storage requirements.</p> <p>In data lake architectures, Azure Synapse Analytics acts as both a data warehouse and a data lake, providing capabilities to query and analyze data from multiple sources. It allows organizations to perform advanced analytics on data stored in Azure Data Lake Storage, supporting real-time analytics, big data processing, and AI initiatives. Its unified platform enhances productivity and accelerates insights across the organization.</p>','Analysis','B/S','Cloud',1,0.00,NULL,NULL,NULL,'An integrated analytics service that combines enterprise data warehousing and big data analytics, enabling end-to-end data solutions in the Azure ecosystem.','/logo_analysis/synapse.png','https://azure.microsoft.com/zh-cn/services/synapse-analytics/');
/*!40000 ALTER TABLE `tools` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `users`
--

DROP TABLE IF EXISTS `users`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `users` (
  `UserID` int NOT NULL AUTO_INCREMENT,
  `name_U` varchar(255) DEFAULT NULL,
  `Pwd_U` varchar(255) DEFAULT NULL,
  `identity_U` varchar(50) DEFAULT NULL,
  `registration_time` date DEFAULT NULL,
  `email_U` varchar(255) DEFAULT NULL,
  PRIMARY KEY (`UserID`)
) ENGINE=InnoDB AUTO_INCREMENT=18 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `users`
--

LOCK TABLES `users` WRITE;
/*!40000 ALTER TABLE `users` DISABLE KEYS */;
INSERT INTO `users` (`UserID`, `name_U`, `Pwd_U`, `identity_U`, `registration_time`, `email_U`) VALUES (9,'test','$2b$10$lp9QDdA.qxbtTltp8.acrOQ665ry9nNG.NXnw2CZr0mdQPCyDMUou','No','2024-07-14','test4@gmail.com'),(10,'abc','$2b$10$hQ26KDReWOPZx4SgGc68I.1crxNKd29/rgOd/h572xaq4vL.pgAIq','No','2024-07-14','abc@gmail.com'),(11,'ph123','$2b$10$qA7HZfEMwZN91lb1n0.Ccu1K1ptfbQmH9Vf/RZNo4/K7E1kX4dnqa','Pro','2024-08-31','root@gmail.com'),(16,'aaa','$2b$10$lc3FtG2JwowNnAaN1RR9me61e455Q1okhNf/g5U4aUVQIh3RXXpdW','Pro','2024-10-24','aaa@gmail.com'),(17,'abcdefg','$2a$10$hj.lx7OltwlP1P4lP5VzhuaBbNxD0pYDkvbEN1MFma3rQ1/AhqecO','No','2024-11-16','root2@gmail.com');
/*!40000 ALTER TABLE `users` ENABLE KEYS */;
UNLOCK TABLES;

--
-- Table structure for table `zone`
--

DROP TABLE IF EXISTS `zone`;
/*!40101 SET @saved_cs_client     = @@character_set_client */;
/*!50503 SET character_set_client = utf8mb4 */;
CREATE TABLE `zone` (
  `Id_zone` int NOT NULL AUTO_INCREMENT,
  `name_zone` varchar(50) DEFAULT NULL,
  PRIMARY KEY (`Id_zone`)
) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=utf8mb4 COLLATE=utf8mb4_0900_ai_ci;
/*!40101 SET character_set_client = @saved_cs_client */;

--
-- Dumping data for table `zone`
--

LOCK TABLES `zone` WRITE;
/*!40000 ALTER TABLE `zone` DISABLE KEYS */;
INSERT INTO `zone` (`Id_zone`, `name_zone`) VALUES (1,'Ingestion zone'),(2,'Preparation zone'),(3,'Analysis zone'),(4,'Gouvernance zone');
/*!40000 ALTER TABLE `zone` ENABLE KEYS */;
UNLOCK TABLES;
/*!40103 SET TIME_ZONE=@OLD_TIME_ZONE */;

/*!40101 SET SQL_MODE=@OLD_SQL_MODE */;
/*!40014 SET FOREIGN_KEY_CHECKS=@OLD_FOREIGN_KEY_CHECKS */;
/*!40014 SET UNIQUE_CHECKS=@OLD_UNIQUE_CHECKS */;
/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
/*!40111 SET SQL_NOTES=@OLD_SQL_NOTES */;

-- Dump completed on 2024-11-22 19:09:44
